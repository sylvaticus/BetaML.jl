<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Imputation · BetaML.jl Documentation</title><script async src="https://www.googletagmanager.com/gtag/js?id=G-JYKX8QY5JW"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-JYKX8QY5JW', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">BetaML.jl Documentation</a></span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Index</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="tutorials/Betaml_tutorial_getting_started.html">Getting started</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Classification - cars</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Classification - cars/betaml_tutorial_classification_cars.html">A classification task when labels are known - determining the country of origin of cars given the cars characteristics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Regression - bike sharing</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Regression - bike sharing/betaml_tutorial_regression_sharingBikes.html">A regression task: the prediction of  bike  sharing demand</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Clustering - Iris</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Clustering - Iris/betaml_tutorial_cluster_iris.html">A clustering task: the prediction of  plant species from floreal measures (the iris dataset)</a></li></ul></li></ul></li><li><span class="tocitem">API (Reference manual)</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">API V2 (current)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Api_v2_user.html">Introduction for user</a></li><li><input class="collapse-toggle" id="menuitem-3-1-2" type="checkbox"/><label class="tocitem" for="menuitem-3-1-2"><span class="docs-label">For developers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Api_v2_developer.html">API implementation</a></li><li><a class="tocitem" href="StyleGuide_templates.html">Style guide</a></li></ul></li><li><a class="tocitem" href="Api.html">The Api module</a></li></ul></li><li><a class="tocitem" href="Perceptron.html">Perceptron</a></li><li><a class="tocitem" href="Trees.html">Trees</a></li><li><a class="tocitem" href="Nn.html">Nn</a></li><li><a class="tocitem" href="Clustering.html">Clustering</a></li><li><a class="tocitem" href="GMM.html">GMM</a></li><li class="is-active"><a class="tocitem" href="Imputation.html">Imputation</a><ul class="internal"><li><a class="tocitem" href="#Module-Index"><span>Module Index</span></a></li><li><a class="tocitem" href="#Detailed-API"><span>Detailed API</span></a></li></ul></li><li><a class="tocitem" href="Utils.html">Utils</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API (Reference manual)</a></li><li class="is-active"><a href="Imputation.html">Imputation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="Imputation.html">Imputation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/sylvaticus/BetaML.jl/blob/master/docs/src/Imputation.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="imputation_module"><a class="docs-heading-anchor" href="#imputation_module">The BetaML.Imputation Module</a><a id="imputation_module-1"></a><a class="docs-heading-anchor-permalink" href="#imputation_module" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation" href="#BetaML.Imputation"><code>BetaML.Imputation</code></a> — <span class="docstring-category">Module</span></header><section><div><pre><code class="language-julia hljs">Imputation module</code></pre><p>Provide various imputation methods for missing data. Note that the interpretation of &quot;missing&quot; can be very wide. For example, reccomendation systems / collaborative filtering (e.g. suggestion of the film to watch) can well be representated as a missing data to impute problem, often with better results than traditional algorithms as k-nearest neighbors (KNN)</p><p>Provided imputers:</p><ul><li><a href="Imputation.html#BetaML.Imputation.FeatureBasedImputer"><code>FeatureBasedImputer</code></a>: Impute data using the feature (column) mean, optionally normalised by l-norms of the records (rows) (fastest)</li><li><a href="Imputation.html#BetaML.Imputation.GMMImputer"><code>GMMImputer</code></a>: Impute data using a Generative (Gaussian) Mixture Model (good trade off)</li><li><a href="Imputation.html#BetaML.Imputation.RFImputer"><code>RFImputer</code></a>: Impute missing data using Random Forests, with optional replicable multiple imputations (most accurate).</li><li><a href="Imputation.html#BetaML.Imputation.UniversalImputer"><code>UniversalImputer</code></a>: Impute missing data using a vector (one per column) of arbitrary learning models (classifiers/regressors) that implement <code>m = Model([options])</code>, <code>fit!(m,X,Y)</code> and <code>predict(m,X)</code>.</li></ul><p>Imputations for all these models can be optained by running <code>mod = ImputatorModel([options])</code>, <code>fit!(mod,X)</code>. The data with the missing values imputed can then be obtained with <code>predict(mod)</code>. Use<code>info(m::Imputer)</code> to retrieve further information concerning the imputation. Trained models can be also used to impute missing values in new data with <code>predict(mox,xNew)</code>. Note that if multiple imputations are run (for the supporting imputators) <code>predict()</code> will return a vector of predictions rather than a single one`.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">julia&gt; using Statistics, BetaML

julia&gt; X            = [2 missing 10; 2000 4000 1000; 2000 4000 10000; 3 5 12 ; 4 8 20; 1 2 5]
6×3 Matrix{Union{Missing, Int64}}:
    2      missing     10
 2000  4000          1000
 2000  4000         10000
    3     5            12
    4     8            20
    1     2             5

julia&gt; mod          = RFImputer(multiple_imputations=10,  rng=copy(FIXEDRNG));

julia&gt; fit!(mod,X);

julia&gt; vals         = predict(mod)
10-element Vector{Matrix{Union{Missing, Int64}}}:
 [2 3 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 4 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 4 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 136 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 137 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 4 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 4 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 4 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 137 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]
 [2 137 10; 2000 4000 1000; … ; 4 8 20; 1 2 5]

julia&gt; nR,nC        = size(vals[1])
(6, 3)

julia&gt; medianValues = [median([v[r,c] for v in vals]) for r in 1:nR, c in 1:nC]
6×3 Matrix{Float64}:
    2.0     4.0     10.0
 2000.0  4000.0   1000.0
 2000.0  4000.0  10000.0
    3.0     5.0     12.0
    4.0     8.0     20.0
    1.0     2.0      5.0

julia&gt; infos        = info(mod);

julia&gt; infos[&quot;n_imputed_values&quot;]
1</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation.jl#L14-L80">source</a></section></article><h2 id="Module-Index"><a class="docs-heading-anchor" href="#Module-Index">Module Index</a><a id="Module-Index-1"></a><a class="docs-heading-anchor-permalink" href="#Module-Index" title="Permalink"></a></h2><ul><li><a href="Imputation.html#BetaML.Imputation.FeatureBasedImputer"><code>BetaML.Imputation.FeatureBasedImputer</code></a></li><li><a href="Imputation.html#BetaML.Imputation.FeatureBasedImputerHyperParametersSet"><code>BetaML.Imputation.FeatureBasedImputerHyperParametersSet</code></a></li><li><a href="Imputation.html#BetaML.Imputation.GMMImputer"><code>BetaML.Imputation.GMMImputer</code></a></li><li><a href="Imputation.html#BetaML.Imputation.GaussianMixtureImputer"><code>BetaML.Imputation.GaussianMixtureImputer</code></a></li><li><a href="Imputation.html#BetaML.Imputation.GeneralImputer"><code>BetaML.Imputation.GeneralImputer</code></a></li><li><a href="Imputation.html#BetaML.Imputation.RFImputer"><code>BetaML.Imputation.RFImputer</code></a></li><li><a href="Imputation.html#BetaML.Imputation.RFImputerHyperParametersSet"><code>BetaML.Imputation.RFImputerHyperParametersSet</code></a></li><li><a href="Imputation.html#BetaML.Imputation.RandomForestImputer"><code>BetaML.Imputation.RandomForestImputer</code></a></li><li><a href="Imputation.html#BetaML.Imputation.SimpleImputer"><code>BetaML.Imputation.SimpleImputer</code></a></li><li><a href="Imputation.html#BetaML.Imputation.UniversalImputer"><code>BetaML.Imputation.UniversalImputer</code></a></li><li><a href="Imputation.html#BetaML.Imputation.UniversalImputerHyperParametersSet"><code>BetaML.Imputation.UniversalImputerHyperParametersSet</code></a></li></ul><h2 id="Detailed-API"><a class="docs-heading-anchor" href="#Detailed-API">Detailed API</a><a id="Detailed-API-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.FeatureBasedImputer" href="#BetaML.Imputation.FeatureBasedImputer"><code>BetaML.Imputation.FeatureBasedImputer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct FeatureBasedImputer &lt;: Imputer</code></pre><p>Simple imputer using the missing data&#39;s feature (column) statistic (def: <code>mean</code>), optionally normalised by l-norms of the records (rows)</p><p><strong>Parameters:</strong></p><ul><li><code>statistics</code>: The descriptive statistic of the column (feature) to use as imputed value [def: <code>mean</code>]</li><li><code>norm</code>: Normalise the feature mean by l-<code>norm</code> norm of the records [default: <code>nothing</code>]. Use it (e.g. <code>norm=1</code> to use the l-1 norm) if the records are highly heterogeneus (e.g. quantity exports of different countries).  </li></ul><p><strong>Limitations:</strong></p><ul><li>data must be numerical</li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; X = [2.0 missing 10; 20 40 100]
2×3 Matrix{Union{Missing, Float64}}:
  2.0    missing   10.0
 20.0  40.0       100.0

julia&gt; mod = FeatureBasedImputer(norm=1)
FeatureBasedImputer - A simple feature-stat based imputer (unfitted)

julia&gt; X_full = fit!(mod,X)
2×3 Matrix{Float64}:
  2.0   4.04494   10.0
 20.0  40.0      100.0

julia&gt; info(mod)
Dict{String, Any} with 1 entry:
  &quot;n_imputed_values&quot; =&gt; 1

julia&gt; parameters(mod)
BetaML.Imputation.FeatureBasedImputerLearnableParameters (a BetaMLLearnableParametersSet struct)
- cStats: [11.0, 40.0, 55.0]
- norms: [6.0, 53.333333333333336]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation.jl#L126">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.FeatureBasedImputerHyperParametersSet" href="#BetaML.Imputation.FeatureBasedImputerHyperParametersSet"><code>BetaML.Imputation.FeatureBasedImputerHyperParametersSet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct FeatureBasedImputerHyperParametersSet &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for the <a href="Imputation.html#BetaML.Imputation.FeatureBasedImputer"><code>FeatureBasedImputer</code></a> model</p><p><strong>Parameters:</strong></p><ul><li><p><code>statistic::Function</code>: The descriptive statistic of the column (feature) to use as imputed value [def: <code>mean</code>]</p></li><li><p><code>norm::Union{Nothing, Int64}</code>: Normalise the feature mean by l-<code>norm</code> norm of the records [default: <code>nothing</code>]. Use it (e.g. <code>norm=1</code> to use the l-1 norm) if the records are highly heterogeneus (e.g. quantity exports of different countries).</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation.jl#L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.GMMImputer" href="#BetaML.Imputation.GMMImputer"><code>BetaML.Imputation.GMMImputer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct GMMImputer &lt;: Imputer</code></pre><p>Missing data imputer that uses a Generative (Gaussian) Mixture Model.</p><p>For the parameters (<code>n_classes</code>,<code>mixtures</code>,..) see  <a href="GMM.html#BetaML.GMM.GMMHyperParametersSet"><code>GMMHyperParametersSet</code></a>.</p><p><strong>Limitations:</strong></p><ul><li>data must be numerical</li><li>the resulted matrix is a Matrix{Float64}</li><li>currently the Mixtures available do not support random initialisation for missing imputation, and the rest of the algorithm (Expectation-Maximisation) is deterministic, so there is no random component involved (i.e. no multiple imputations)</li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; X = [1 2.5; missing 20.5; 0.8 18; 12 22.8; 0.4 missing; 1.6 3.7];

julia&gt; mod = GMMImputer(mixtures=[SphericalGaussian() for i in 1:2])
GMMImputer - A Gaussian Mixture Model based imputer (unfitted)

julia&gt; X_full = fit!(mod,X)
Iter. 1:        Var. of the post  2.373498171519511       Log-likelihood -29.111866299189792
6×2 Matrix{Float64}:
  1.0       2.5
  6.14905  20.5
  0.8      18.0
 12.0      22.8
  0.4       4.61314
  1.6       3.7

julia&gt; info(mod)
Dict{String, Any} with 7 entries:
  &quot;xndims&quot;           =&gt; 2
  &quot;error&quot;            =&gt; [2.3735, 0.17527, 0.0283747, 0.0053147, 0.000981885]
  &quot;AIC&quot;              =&gt; 57.798
  &quot;fitted_records&quot;   =&gt; 6
  &quot;lL&quot;               =&gt; -21.899
  &quot;n_imputed_values&quot; =&gt; 2
  &quot;BIC&quot;              =&gt; 56.3403

julia&gt; parameters(mod)
BetaML.Imputation.GMMImputerLearnableParameters (a BetaMLLearnableParametersSet struct)
- mixtures: AbstractMixture[SphericalGaussian{Float64}([1.0179819950570768, 3.0999990977255845], 0.2865287884295908), SphericalGaussian{Float64}([6.149053737674149, 20.43331198167713], 15.18664378248651)]
- initial_probmixtures: [0.48544987084082347, 0.5145501291591764]
- probRecords: [0.9999996039918224 3.9600817749531375e-7; 2.3866922376272767e-229 1.0; … ; 0.9127030246369684 0.08729697536303167; 0.9999965964161501 3.403583849794472e-6]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation.jl#L273">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.GaussianMixtureImputer" href="#BetaML.Imputation.GaussianMixtureImputer"><code>BetaML.Imputation.GaussianMixtureImputer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct GaussianMixtureImputer &lt;: MLJModelInterface.Unsupervised</code></pre><p>Impute missing values using a probabilistic approach (Gaussian Mixture Models) fitted using the Expectation-Maximisation algorithm, from the Beta Machine Learning Toolkit (BetaML).</p><p><strong>Hyperparameters:</strong></p><ul><li><p><code>n_classes::Int64</code>: Number of mixtures (latent classes) to consider [def: 3]</p></li><li><p><code>initial_probmixtures::Vector{Float64}</code>: Initial probabilities of the categorical distribution (n_classes x 1) [default: <code>[]</code>]</p></li><li><p><code>mixtures::Union{Type, Vector{var&quot;#s798&quot;} where var&quot;#s798&quot;&lt;:AbstractMixture}</code>: An array (of length <code>n_classes</code><code>) of the mixtures to employ (see the [</code>?GMM<code>](@ref GMM) module in BetaML). Each mixture object can be provided with or without its parameters (e.g. mean and variance for the gaussian ones). Fully qualified mixtures are useful only if the</code>initialisation<em>strategy<code>parameter is  set to &quot;gived&quot;</code> This parameter can also be given symply in term of a _type</em>. In this case it is automatically extended to a vector of <code>n_classes</code><code>mixtures of the specified type. Note that mixing of different mixture types is not currently supported and that currently implemented mixtures are</code>SphericalGaussian<code>,</code>DiagonalGaussian<code>and</code>FullGaussian<code>. [def:</code>DiagonalGaussian`]</p></li><li><p><code>tol::Float64</code>: Tolerance to stop the algorithm [default: 10^(-6)]</p></li><li><p><code>minimum_variance::Float64</code>: Minimum variance for the mixtures [default: 0.05]</p></li><li><p><code>minimum_covariance::Float64</code>: Minimum covariance for the mixtures with full covariance matrix [default: 0]. This should be set different than minimum_variance.</p></li><li><p><code>initialisation_strategy::String</code>: The computation method of the vector of the initial mixtures. One of the following:</p><ul><li>&quot;grid&quot;: using a grid approach</li><li>&quot;given&quot;: using the mixture provided in the fully qualified <code>mixtures</code> parameter</li><li>&quot;kmeans&quot;: use first kmeans (itself initialised with a &quot;grid&quot; strategy) to set the initial mixture centers [default]</li></ul><p>Note that currently &quot;random&quot; and &quot;shuffle&quot; initialisations are not supported in gmm-based algorithms.</p></li></ul><ul><li><code>rng::Random.AbstractRNG</code>: A Random Number Generator to be used in stochastic parts of the code [deafult: <code>Random.GLOBAL_RNG</code>]</li></ul><p><strong>Example :</strong></p><pre><code class="language-julia hljs">julia&gt; using MLJ

julia&gt; X = [1 10.5;1.5 missing; 1.8 8; 1.7 15; 3.2 40; missing missing; 3.3 38; missing -2.3; 5.2 -2.4] |&gt; table ;

julia&gt; modelType   = @load GaussianMixtureImputer  pkg = &quot;BetaML&quot; verbosity=0
BetaML.Imputation.GaussianMixtureImputer

julia&gt; model     = modelType(initialisation_strategy=&quot;grid&quot;)
GaussianMixtureImputer(
  n_classes = 3, 
  initial_probmixtures = Float64[], 
  mixtures = BetaML.GMM.DiagonalGaussian{Float64}[BetaML.GMM.DiagonalGaussian{Float64}(nothing, nothing), BetaML.GMM.DiagonalGaussian{Float64}(nothing, nothing), BetaML.GMM.DiagonalGaussian{Float64}(nothing, nothing)], 
  tol = 1.0e-6, 
  minimum_variance = 0.05, 
  minimum_covariance = 0.0, 
  initialisation_strategy = &quot;grid&quot;, 
  rng = Random._GLOBAL_RNG())

julia&gt; mach      = machine(model, X);

julia&gt; fit!(mach);
[ Info: Training machine(GaussianMixtureImputer(n_classes = 3, …), …).
Iter. 1:        Var. of the post  2.0225921341714286      Log-likelihood -42.96100103213314

julia&gt; X_full       = transform(mach) |&gt; MLJ.matrix
9×2 Matrix{Float64}:
 1.0      10.5
 1.5      14.7366
 1.8       8.0
 1.7      15.0
 3.2      40.0
 2.51842  15.1747
 3.3      38.0
 2.47412  -2.3
 5.2      -2.4</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation_MLJ.jl#L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.GeneralImputer" href="#BetaML.Imputation.GeneralImputer"><code>BetaML.Imputation.GeneralImputer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct GeneralImputer &lt;: MLJModelInterface.Unsupervised</code></pre><p>Impute missing values using arbitrary learning models, from the Beta Machine Learning Toolkit (BetaML).</p><p>Impute missing values using a vector (one per column) of arbitrary learning models (classifiers/regressors, not necessarily from BetaML) that:</p><ul><li>implement the interface <code>m = Model([options])</code>, <code>train!(m,X,Y)</code> and <code>predict(m,X)</code>;</li><li>accept missing data in the feature matrix.</li></ul><p>(default to Random Forests)</p><p><strong>Hyperparameters:</strong></p><ul><li><p><code>estimators::Union{Nothing, Vector{T} where T}</code>: A D-dimensions vector of regressor or classifier models (and eventually their respective options/hyper-parameters) to be used to impute the various columns of the matrix [default: <code>nothing</code>, i.e. use random forests].</p></li><li><p><code>recursive_passages::Int64</code>: Define the times to go trough the various columns to impute their data. Useful when there are data to impute on multiple columns. The order of the first passage is given by the decreasing number of missing values per column, the other passages are random [default: <code>1</code>].</p></li><li><p><code>rng::Random.AbstractRNG</code>: A Random Number Generator to be used in stochastic parts of the code [deafult: <code>Random.GLOBAL_RNG</code>]</p></li></ul><p><strong>Example :</strong></p><pre><code class="language-julia hljs">julia&gt; using MLJ

julia&gt; X = [&quot;a&quot; 10.5;&quot;a&quot; missing; &quot;b&quot; 8; &quot;b&quot; 15; &quot;c&quot; 40; missing missing; &quot;c&quot; 38; missing -2.3; &quot;c&quot; -2.4] |&gt; table ;

julia&gt; modelType   = @load GeneralImputer  pkg = &quot;BetaML&quot; verbosity=0
BetaML.Imputation.GeneralImputer

julia&gt; model     = modelType(estimators=[BetaML.DecisionTreeEstimator(),BetaML.RandomForestEstimator(n_trees=40)],recursive_passages=2)
GeneralImputer(
  estimators = BetaML.Api.BetaMLSupervisedModel[DecisionTreeEstimator - A Decision Tree model (unfitted), RandomForestEstimator - A 40 trees Random Forest model (unfitted)], 
  recursive_passages = 2, 
  rng = Random._GLOBAL_RNG())

julia&gt; mach      = machine(model, X);

julia&gt; fit!(mach);
[ Info: Training machine(GeneralImputer(estimators = BetaML.Api.BetaMLSupervisedModel[DecisionTreeEstimator - A Decision Tree model (unfitted), RandomForestEstimator - A 40 trees Random Forest model (unfitted)], …), …).

julia&gt; X_full       = transform(mach) |&gt; MLJ.matrix
9×2 Matrix{Any}:
 &quot;a&quot;  10.5
 &quot;a&quot;  10.9171
 &quot;b&quot;   8
 &quot;b&quot;  15
 &quot;c&quot;  40
 &quot;c&quot;  20.6587
 &quot;c&quot;  38
 &quot;c&quot;  -2.3
 &quot;c&quot;  -2.4</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation_MLJ.jl#L233">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.RFImputer" href="#BetaML.Imputation.RFImputer"><code>BetaML.Imputation.RFImputer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct RFImputer &lt;: Imputer</code></pre><p>Impute missing data using Random Forests, with optional replicable multiple imputations. </p><p>See <a href="Imputation.html#BetaML.Imputation.RFImputerHyperParametersSet"><code>RFImputerHyperParametersSet</code></a>, <a href="Trees.html#BetaML.Trees.RFHyperParametersSet"><code>RFHyperParametersSet</code></a> and <a href="Api.html#BetaML.Api.BetaMLDefaultOptionsSet"><code>BetaMLDefaultOptionsSet</code></a> for the parameters.</p><p><strong>Notes:</strong></p><ul><li>Given a certain RNG and its status (e.g. <code>RFImputer(...,rng=StableRNG(FIXEDSEED))</code>), the algorithm is completely deterministic, i.e. replicable. </li><li>The algorithm accepts virtually any kind of data, sortable or not</li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; X = [1.4 2.5 &quot;a&quot;; missing 20.5 &quot;b&quot;; 0.6 18 missing; 0.7 22.8 &quot;b&quot;; 0.4 missing &quot;b&quot;; 1.6 3.7 &quot;a&quot;]
6×3 Matrix{Any}:
 1.4        2.5       &quot;a&quot;
  missing  20.5       &quot;b&quot;
 0.6       18         missing
 0.7       22.8       &quot;b&quot;
 0.4         missing  &quot;b&quot;
 1.6        3.7       &quot;a&quot;

julia&gt; mod = RFImputer(n_trees=20,max_depth=10,recursive_passages=2)
RFImputer - A Random-Forests based imputer (unfitted)

julia&gt; X_full = fit!(mod,X)
** Processing imputation 1
6×3 Matrix{Any}:
 1.4        2.5     &quot;a&quot;
 0.504167  20.5     &quot;b&quot;
 0.6       18       &quot;b&quot;
 0.7       22.8     &quot;b&quot;
 0.4       20.0837  &quot;b&quot;
 1.6        3.7     &quot;a&quot;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation.jl#L497">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.RFImputerHyperParametersSet" href="#BetaML.Imputation.RFImputerHyperParametersSet"><code>BetaML.Imputation.RFImputerHyperParametersSet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct RFImputerHyperParametersSet &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for <a href="Imputation.html#BetaML.Imputation.RFImputer"><code>RFImputer</code></a></p><p><strong>Parameters:</strong></p><ul><li><p><code>rfhpar::Any</code>: For the underlying random forest algorithm parameters (<code>n_trees</code>,<code>max_depth</code>,<code>min_gain</code>,<code>min_records</code>,<code>max_features:</code>,<code>splitting_criterion</code>,<code>β</code>,<code>initialisation_strategy</code>, <code>oob</code> and <code>rng</code>) see <a href="Trees.html#BetaML.Trees.RFHyperParametersSet"><code>RFHyperParametersSet</code></a> for the specific RF algorithm parameters</p></li><li><p><code>forced_categorical_cols::Vector{Int64}</code>: Specify the positions of the integer columns to treat as categorical instead of cardinal. [Default: empty vector (all numerical cols are treated as cardinal by default and the others as categorical)]</p></li><li><p><code>recursive_passages::Int64</code>: Define the times to go trough the various columns to impute their data. Useful when there are data to impute on multiple columns. The order of the first passage is given by the decreasing number of missing values per column, the other passages are random [default: <code>1</code>].</p></li><li><p><code>multiple_imputations::Int64</code>: Determine the number of independent imputation of the whole dataset to make. Note that while independent, the imputations share the same random number generator (RNG).</p></li></ul><p><strong>Example:</strong></p><pre><code class="nohighlight hljs">julia&gt;mod = RFImputer(n_trees=20,max_depth=10,recursive_passages=3)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation.jl#L466">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.RandomForestImputer" href="#BetaML.Imputation.RandomForestImputer"><code>BetaML.Imputation.RandomForestImputer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct RandomForestImputer &lt;: MLJModelInterface.Unsupervised</code></pre><p>Impute missing values using Random Forests, from the Beta Machine Learning Toolkit (BetaML).</p><p><strong>Hyperparameters:</strong></p><ul><li><p><code>n_trees::Int64</code>: Number of (decision) trees in the forest [def: <code>30</code>]</p></li><li><p><code>max_depth::Union{Nothing, Int64}</code>: The maximum depth the tree is allowed to reach. When this is reached the node is forced to become a leaf [def: <code>nothing</code>, i.e. no limits]</p></li><li><p><code>min_gain::Float64</code>: The minimum information gain to allow for a node&#39;s partition [def: <code>0</code>]</p></li><li><p><code>min_records::Int64</code>: The minimum number of records a node must holds to consider for a partition of it [def: <code>2</code>]</p></li><li><p><code>max_features::Union{Nothing, Int64}</code>: The maximum number of (random) features to consider at each partitioning [def: <code>nothing</code>, i.e. square root of the data dimension]</p></li><li><p><code>forced_categorical_cols::Vector{Int64}</code>: Specify the positions of the integer columns to treat as categorical instead of cardinal. [Default: empty vector (all numerical cols are treated as cardinal by default and the others as categorical)]</p></li><li><p><code>splitting_criterion::Union{Nothing, Function}</code>: Either <code>gini</code>, <code>entropy</code> or <code>variance</code>. This is the name of the function to be used to compute the information gain of a specific partition. This is done by measuring the difference betwwen the &quot;impurity&quot; of the labels of the parent node with those of the two child nodes, weighted by the respective number of items. [def: <code>nothing</code>, i.e. <code>gini</code> for categorical labels (classification task) and <code>variance</code> for numerical labels(regression task)]. It can be an anonymous function.</p></li><li><p><code>recursive_passages::Int64</code>: Define the times to go trough the various columns to impute their data. Useful when there are data to impute on multiple columns. The order of the first passage is given by the decreasing number of missing values per column, the other passages are random [default: <code>1</code>].</p></li><li><p><code>rng::Random.AbstractRNG</code>: A Random Number Generator to be used in stochastic parts of the code [deafult: <code>Random.GLOBAL_RNG</code>]</p></li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using MLJ

julia&gt; X = [1 10.5;1.5 missing; 1.8 8; 1.7 15; 3.2 40; missing missing; 3.3 38; missing -2.3; 5.2 -2.4] |&gt; table ;

julia&gt; modelType   = @load RandomForestImputer  pkg = &quot;BetaML&quot; verbosity=0
BetaML.Imputation.RandomForestImputer

julia&gt; model     = modelType(n_trees=40)
RandomForestImputer(
  n_trees = 40, 
  max_depth = nothing, 
  min_gain = 0.0, 
  min_records = 2, 
  max_features = nothing, 
  forced_categorical_cols = Int64[], 
  splitting_criterion = nothing, 
  recursive_passages = 1, 
  rng = Random._GLOBAL_RNG())

julia&gt; mach      = machine(model, X);

julia&gt; fit!(mach);
[ Info: Training machine(RandomForestImputer(n_trees = 40, …), …).

julia&gt; X_full       = transform(mach) |&gt; MLJ.matrix
9×2 Matrix{Float64}:
 1.0      10.5
 1.5      10.3909
 1.8       8.0
 1.7      15.0
 3.2      40.0
 2.88375   8.66125
 3.3      38.0
 3.98125  -2.3
 5.2      -2.4</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation_MLJ.jl#L153">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.SimpleImputer" href="#BetaML.Imputation.SimpleImputer"><code>BetaML.Imputation.SimpleImputer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct SimpleImputer &lt;: MLJModelInterface.Unsupervised</code></pre><p>Impute missing values using feature (column) mean, with optional record normalisation (using l-<code>norm</code> norms), from the Beta Machine Learning Toolkit (BetaML).</p><p><strong>Hyperparameters:</strong></p><ul><li><p><code>statistic::Function</code>: The descriptive statistic of the column (feature) to use as imputed value [def: <code>mean</code>]</p></li><li><p><code>norm::Union{Nothing, Int64}</code>: Normalise the feature mean by l-<code>norm</code> norm of the records [default: <code>nothing</code>]. Use it (e.g. <code>norm=1</code> to use the l-1 norm) if the records are highly heterogeneus (e.g. quantity exports of different countries).</p></li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using MLJ

julia&gt; X = [1 10.5;1.5 missing; 1.8 8; 1.7 15; 3.2 40; missing missing; 3.3 38; missing -2.3; 5.2 -2.4] |&gt; table ;

julia&gt; modelType   = @load SimpleImputer  pkg = &quot;BetaML&quot; verbosity=0
BetaML.Imputation.SimpleImputer

julia&gt; model     = modelType(norm=1)
SimpleImputer(
  statistic = Statistics.mean, 
  norm = 1)

julia&gt; mach      = machine(model, X);

julia&gt; fit!(mach);
[ Info: Training machine(SimpleImputer(statistic = mean, …), …).

julia&gt; X_full       = transform(mach) |&gt; MLJ.matrix
9×2 Matrix{Float64}:
 1.0        10.5
 1.5         0.295466
 1.8         8.0
 1.7        15.0
 3.2        40.0
 0.280952    1.69524
 3.3        38.0
 0.0750839  -2.3
 5.2        -2.4</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation_MLJ.jl#L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.UniversalImputer" href="#BetaML.Imputation.UniversalImputer"><code>BetaML.Imputation.UniversalImputer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct UniversalImputer &lt;: Imputer</code></pre><p>Impute missing values using arbitrary learning models.</p><p>Impute missing values using a vector (one per column) of arbitrary learning models (classifiers/regressors, not necessarily from BetaML) that:</p><ul><li>implement the interface <code>m = Model([options])</code>, <code>train!(m,X,Y)</code> and <code>predict(m,X)</code>;</li><li>accept missing data in the feature matrix.</li></ul><p>(default to Random Forests)</p><p>See <a href="Imputation.html#BetaML.Imputation.UniversalImputerHyperParametersSet"><code>UniversalImputerHyperParametersSet</code></a> for the hyper-parameters.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; X = [1.4 2.5 &quot;a&quot;; missing 20.5 &quot;b&quot;; 0.6 18 missing; 0.7 22.8 &quot;b&quot;; 0.4 missing &quot;b&quot;; 1.6 3.7 &quot;a&quot;]
6×3 Matrix{Any}:
 1.4        2.5       &quot;a&quot;
  missing  20.5       &quot;b&quot;
 0.6       18         missing
 0.7       22.8       &quot;b&quot;
 0.4         missing  &quot;b&quot;
 1.6        3.7       &quot;a&quot;

julia&gt; mod = UniversalImputer(estimators=[DecisionTreeEstimator(),RandomForestEstimator(n_trees=40), RandomForestEstimator()],recursive_passages=2)
UniversalImputer - A imputer based on an arbitrary regressor/classifier(unfitted)

julia&gt; X_full = fit!(mod,X)
** Processing imputation 1
6×3 Matrix{Any}:
 1.4   2.5     &quot;a&quot;
 0.5  20.5     &quot;b&quot;
 0.6  18       &quot;a&quot;
 0.7  22.8     &quot;b&quot;
 0.4  19.9035  &quot;b&quot;
 1.6   3.7     &quot;a&quot;

julia&gt; info(mod)
Dict{String, Any} with 1 entry:
  &quot;n_imputed_values&quot; =&gt; 3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation.jl#L806">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Imputation.UniversalImputerHyperParametersSet" href="#BetaML.Imputation.UniversalImputerHyperParametersSet"><code>BetaML.Imputation.UniversalImputerHyperParametersSet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct UniversalImputerHyperParametersSet &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for <a href="Imputation.html#BetaML.Imputation.UniversalImputer"><code>UniversalImputer</code></a></p><p><strong>Parameters:</strong></p><ul><li><p><code>estimators</code>: A D-dimensions vector of regressor or classifier models (and eventually their respective options/hyper-parameters) to be used to impute the various columns of the matrix [default: <code>nothing</code>, i.e. use random forests].</p></li><li><p><code>recursive_passages</code>: Define the times to go trough the various columns to impute their data. Useful when there are data to impute on multiple columns. The order of the first passage is given by the decreasing number of missing values per column, the other passages are random [default: <code>1</code>].</p></li><li><p><code>multiple_imputations</code>: Determine the number of independent imputation of the whole dataset to make. Note that while independent, the imputations share the same random number generator (RNG).</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/fcd8d9854bf2679434045562e847ca2cccf8f12a/src/Imputation/Imputation.jl#L784">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="GMM.html">« GMM</a><a class="docs-footer-nextpage" href="Utils.html">Utils »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Friday 5 May 2023 07:40">Friday 5 May 2023</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
