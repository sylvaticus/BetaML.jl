<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>GMM · BetaML.jl Documentation</title><script async src="https://www.googletagmanager.com/gtag/js?id=G-JYKX8QY5JW"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-JYKX8QY5JW', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">BetaML.jl Documentation</a></span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Index</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="tutorials/Betaml_tutorial_getting_started.html">Getting started</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Regression - bike sharing</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Regression - bike sharing/betaml_tutorial_regression_sharingBikes.html">A regression task: the prediction of  bike  sharing demand</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Classification - cars</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Classification - cars/betaml_tutorial_classification_cars.html">A classification task when labels are known - determining the country of origin of cars given the cars characteristics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Clustering - Iris</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Clustering - Iris/betaml_tutorial_cluster_iris.html">A clustering task: the prediction of  plant species from floreal measures (the iris dataset)</a></li></ul></li></ul></li><li><span class="tocitem">API (Reference manual)</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">API V2 (current testing)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Api_v2_user.html">Introduction for user</a></li><li><a class="tocitem" href="Api_v2_developer.html">For developers</a></li></ul></li><li><a class="tocitem" href="Perceptron.html">Perceptron</a></li><li><a class="tocitem" href="Trees.html">Trees</a></li><li><a class="tocitem" href="Nn.html">Nn</a></li><li><a class="tocitem" href="Clustering.html">Clustering</a></li><li class="is-active"><a class="tocitem" href="GMM.html">GMM</a><ul class="internal"><li><a class="tocitem" href="#Module-Index"><span>Module Index</span></a></li><li><a class="tocitem" href="#Detailed-API"><span>Detailed API</span></a></li></ul></li><li><a class="tocitem" href="Imputation.html">Imputation</a></li><li><a class="tocitem" href="Utils.html">Utils</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API (Reference manual)</a></li><li class="is-active"><a href="GMM.html">GMM</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="GMM.html">GMM</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/sylvaticus/BetaML.jl/blob/master/docs/src/GMM.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="gmm_module"><a class="docs-heading-anchor" href="#gmm_module">The BetaML.GMM Module</a><a id="gmm_module-1"></a><a class="docs-heading-anchor-permalink" href="#gmm_module" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM" href="#BetaML.GMM"><code>BetaML.GMM</code></a> — <span class="docstring-category">Module</span></header><section><div><pre><code class="language-julia hljs">GMM module</code></pre><p>Generative (Gaussian) Mixed Model learners (supervised/unsupervised)</p><p>Provides clustering/collaborative filtering (via clustering) / missing values imputation / collaborative filtering / reccomendation systems, regressor and fitter using Generative Gaussiam Model (probabilistic). </p><p>The module provides the following functions. Use <code>?[function]</code> to access their full signature and detailed documentation:</p><ul><li><a href="GMM.html#BetaML.GMM.gmm-Tuple{Any, Any}"><code>gmm(X,K;p₀,mixtures,tol,verbosity,minVariance,minCovariance,initStrategy)</code></a>: gmm algorithm over GMM</li><li><a href="@ref predictMissing"><code>predictMissing(X,K;p₀,mixtures,tol,verbosity,minVariance,minCovariance)</code></a>: Impute mixing values (&quot;matrix completion&quot;) using gmm as backbone. Note that this can be used for collaborative filtering / reccomendation systems often with better results than traditional algorithms as k-nearest neighbors (KNN)</li></ul><p>{Spherical|Diagonal|Full} Gaussian mixtures are already provided. User defined mixtures can be used defining a struct as subtype of <code>AbstractMixture</code> and implementing for that mixture the following functions:</p><ul><li><code>initMixtures!(mixtures, X; minVariance, minCovariance, initStrategy)</code></li><li><code>lpdf(m,x,mask)</code> (for the e-step)</li><li><code>updateParameters!(mixtures, X, pₙₖ; minVariance, minCovariance)</code> (the m-step)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM.jl#L7-L24">source</a></section></article><h2 id="Module-Index"><a class="docs-heading-anchor" href="#Module-Index">Module Index</a><a id="Module-Index-1"></a><a class="docs-heading-anchor-permalink" href="#Module-Index" title="Permalink"></a></h2><ul><li><a href="GMM.html#BetaML.GMM.GMMClusterHyperParametersSet"><code>BetaML.GMM.GMMClusterHyperParametersSet</code></a></li><li><a href="GMM.html#BetaML.GMM.GMMRegressor1"><code>BetaML.GMM.GMMRegressor1</code></a></li><li><a href="GMM.html#BetaML.GMM.GMMRegressor2"><code>BetaML.GMM.GMMRegressor2</code></a></li><li><a href="GMM.html#BetaML.GMM.estep-Tuple{Any, Any, Any}"><code>BetaML.GMM.estep</code></a></li><li><a href="GMM.html#BetaML.GMM.gmm-Tuple{Any, Any}"><code>BetaML.GMM.gmm</code></a></li><li><a href="GMM.html#BetaML.GMM.initMixtures!-Union{Tuple{T}, Tuple{Vector{T}, Any}} where T&lt;:BetaML.GMM.AbstractGaussian"><code>BetaML.GMM.initMixtures!</code></a></li><li><a href="GMM.html#BetaML.GMM.lpdf-Tuple{DiagonalGaussian, Any, Any}"><code>BetaML.GMM.lpdf</code></a></li><li><a href="GMM.html#BetaML.GMM.lpdf-Tuple{FullGaussian, Any, Any}"><code>BetaML.GMM.lpdf</code></a></li><li><a href="GMM.html#BetaML.GMM.lpdf-Tuple{SphericalGaussian, Any, Any}"><code>BetaML.GMM.lpdf</code></a></li></ul><h2 id="Detailed-API"><a class="docs-heading-anchor" href="#Detailed-API">Detailed API</a><a id="Detailed-API-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.GMMClusterHyperParametersSet" href="#BetaML.GMM.GMMClusterHyperParametersSet"><code>BetaML.GMM.GMMClusterHyperParametersSet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct GMMClusterHyperParametersSet &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for GMM clusters and other GMM-related algorithms</p><p><strong>Parameters:</strong></p><ul><li><p><code>nClasses</code></p><p>Number of mixtures (latent classes) to consider [def: 3]</p></li><li><p><code>probMixtures</code></p><p>Initial probabilities of the categorical distribution (nClasses x 1) [default: <code>[]</code>]</p></li><li><p><code>mixtures</code></p><p>An array (of length K) of the mixture to employ (see notes) [def: <code>[DiagonalGaussian() for i in 1:K]</code>]</p></li><li><p><code>tol</code></p><p>Tolerance to stop the algorithm [default: 10^(-6)]</p></li><li><p><code>minVariance</code></p><p>Minimum variance for the mixtures [default: 0.05]</p></li><li><p><code>minCovariance</code></p><p>Minimum covariance for the mixtures with full covariance matrix [default: 0]. This should be set different than minVariance (see notes).</p></li><li><p><code>initStrategy</code></p><p>Mixture initialisation algorithm [def: <code>kmeans</code>]</p></li><li><p><code>maxIter</code></p><p>Maximum number of iterations [def: <code>typemax(Int64)</code>, i.e. ∞]</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM_clustering.jl#L164">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.GMMRegressor1" href="#BetaML.GMM.GMMRegressor1"><code>BetaML.GMM.GMMRegressor1</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GMMRegressor1</code></pre><p>A multi-dimensional, missing data friendly non-linear regressor based on Generative (Gaussian) Mixture Model (strategy &quot;1&quot;).</p><p>The training data is used to fit a probabilistic model with latent mixtures (Gaussian distributions with different covariances are already implemented) and then predictions of new data is obtained by fitting the new data to the mixtures.</p><p>For hyperparameters see <a href="GMM.html#BetaML.GMM.GMMClusterHyperParametersSet"><code>GMMClusterHyperParametersSet</code></a> and <a href="@ref"><code>GMMClusterOptionsSet</code></a>.</p><p>this strategy (GMMRegressor1) works by training the EM algorithm on the feature matrix X. Once the data has been probabilistically assigned to the various classes, a mean value of Y is computed for each cluster (using the probabilities as weigths). At predict time, the new data is first fitted to the learned mixtures using the e-step part of the EM algorithm to obtain the probabilistic assignment of each record to the various mixtures. Then these probabilities are multiplied to the mixture averages for the Y dimensions learned at training time to obtain the predicted value(s) for each record. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM_regression.jl#L13-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.GMMRegressor2" href="#BetaML.GMM.GMMRegressor2"><code>BetaML.GMM.GMMRegressor2</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GMMRegressor2</code></pre><p>A multi-dimensional, missing data friendly non-linear regressor based on Generative (Gaussian) Mixture Model.</p><p>The training data is used to fit a probabilistic model with latent mixtures (Gaussian distributions with different covariances are already implemented) and then predictions of new data is obtained by fitting the new data to the mixtures.</p><p>For hyperparameters see <a href="GMM.html#BetaML.GMM.GMMClusterHyperParametersSet"><code>GMMClusterHyperParametersSet</code></a> and <a href="@ref"><code>GMMClusterOptionsSet</code></a>.</p><p>Thsi strategy (GMMRegressor2) works by training the EM algorithm on a combined (hcat) matrix of X and Y. At predict time, the new data is first fitted to the learned mixtures using the e-step part of the EM algorithm (and using missing values for the dimensions belonging to Y) to obtain the probabilistic assignment of each record to the various mixtures. Thes these probabilities are multiplied to the mixture averages for the Y dimensions to obtain the predicted value(s) for each record. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM_regression.jl#L136-L148">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Api.fit!-Tuple{GMMClusterModel, Any}" href="#BetaML.Api.fit!-Tuple{GMMClusterModel, Any}"><code>BetaML.Api.fit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit!(m::GMMClusterModel,x)</code></pre><p><strong>Notes:</strong></p><p><code>fit!</code> caches as record probabilities only those of the last set of data used to train the model</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM_clustering.jl#L235-L240">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Api.fit!-Tuple{GMMRegressor1, Any, Any}" href="#BetaML.Api.fit!-Tuple{GMMRegressor1, Any, Any}"><code>BetaML.Api.fit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit!(m::GMMRegressor1,x)</code></pre><p><strong>Notes:</strong></p><p><code>fit!</code> caches as record probabilities only those of the last set of data used to train the model</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM_regression.jl#L56-L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Api.fit!-Tuple{GMMRegressor2, Any, Any}" href="#BetaML.Api.fit!-Tuple{GMMRegressor2, Any, Any}"><code>BetaML.Api.fit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit!(m::GMMRegressor2,x)</code></pre><p><strong>Notes:</strong></p><p><code>fit!</code> caches as record probabilities only those of the last set of data used to train the model</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM_regression.jl#L178-L183">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.estep-Tuple{Any, Any, Any}" href="#BetaML.GMM.estep-Tuple{Any, Any, Any}"><code>BetaML.GMM.estep</code></a> — <span class="docstring-category">Method</span></header><section><div><p>estep(X,pₖ,mixtures)</p><p>E-step: assign the posterior prob p(j|xi) and computing the log-Likelihood of the parameters given the set of data(this last one for informative purposes and terminating the algorithm only)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM_clustering.jl#L2-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.gmm-Tuple{Any, Any}" href="#BetaML.GMM.gmm-Tuple{Any, Any}"><code>BetaML.GMM.gmm</code></a> — <span class="docstring-category">Method</span></header><section><div><p>gmm(X,K;p₀,mixtures,tol,verbosity,minVariance,minCovariance,initStrategy)</p><p>Compute Expectation-Maximisation algorithm to identify K clusters of X data, i.e. employ a Generative Mixture Model as the underlying probabilistic model.</p><p>X can contain missing values in some or all of its dimensions. In such case the learning is done only with the available data. Implemented in the log-domain for better numerical accuracy with many dimensions.</p><p><strong>Parameters:</strong></p><ul><li><code>X</code>  :           A (n x d) data to clusterise</li><li><code>K</code>  :           Number of cluster wanted</li><li><code>p₀</code> :           Initial probabilities of the categorical distribution (K x 1) [default: <code>[]</code>]</li><li><code>mixtures</code>:      An array (of length K) of the mixture to employ (see notes) [def: <code>[DiagonalGaussian() for i in 1:K]</code>]</li><li><code>tol</code>:           Tolerance to stop the algorithm [default: 10^(-6)]</li><li><code>verbosity</code>:     A verbosity parameter regulating the information messages frequency [def: <code>STD</code>]</li><li><code>minVariance</code>:   Minimum variance for the mixtures [default: 0.05]</li><li><code>minCovariance</code>: Minimum covariance for the mixtures with full covariance matrix [default: 0]. This should be set different than minVariance (see notes).</li><li><code>initStrategy</code>:  Mixture initialisation algorithm [def: <code>kmeans</code>]</li><li><code>maxIter</code>:       Maximum number of iterations [def: <code>typemax(Int64)</code>, i.e. ∞]</li><li><code>rng</code>:           Random Number Generator (see <a href="@ref"><code>FIXEDSEED</code></a>) [deafult: <code>Random.GLOBAL_RNG</code>]</li></ul><p><strong>Returns:</strong></p><ul><li>A named touple of:</li><li><code>pₙₖ</code>:      Matrix of size (N x K) of the probabilities of each point i to belong to cluster j</li><li><code>pₖ</code>:       Probabilities of the categorical distribution (K x 1)</li><li><code>mixtures</code>: Vector (K x 1) of the estimated underlying distributions</li><li><code>ϵ</code>:        Vector of the discrepancy (matrix norm) between pⱼₓ and the lagged pⱼₓ at each iteration</li><li><code>lL</code>:       The log-likelihood (without considering the last mixture optimisation)</li><li><code>BIC</code>:      The Bayesian Information Criterion (lower is better)</li><li><code>AIC</code>:      The Akaike Information Criterion (lower is better)</li></ul><p><strong>Notes:</strong></p><ul><li>The mixtures currently implemented are <code>SphericalGaussian(μ,σ²)</code>,<code>DiagonalGaussian(μ,σ²)</code> and <code>FullGaussian(μ,σ²)</code></li><li>Reasonable choices for the minVariance/Covariance depends on the mixture. For example 0.25 seems a reasonable value for the SphericalGaussian, 0.05 seems better for the DiagonalGaussian, and FullGaussian seems to prefer either very low values of variance/covariance (e.g. <code>(0.05,0.05)</code> ) or very big but similar ones (e.g. <code>(100,100)</code> ).</li><li>For <code>initStrategy</code>, look at the documentation of <code>initMixtures!</code> for the mixture you want. The provided gaussian mixtures support <code>grid</code>, <code>kmeans</code> or <code>given</code>. <code>grid</code> is faster (expecially if X contains missing values), but <code>kmeans</code> often provides better results.</li></ul><p><strong>Resources:</strong></p><ul><li><a href="https://doi.org/10.1016/j.csda.2006.10.002">Paper describing gmm with missing values</a></li><li><a href="https://stackedit.io/viewer#!url=https://github.com/sylvaticus/MITx_6.86x/raw/master/Unit 04 - Unsupervised Learning/Unit 04 - Unsupervised Learning.md">Class notes from MITx 6.86x (Sec 15.9)</a></li><li><a href="https://www.r-craft.org/r-news/when-not-to-use-gaussian-mixture-model-gmm-clustering/">Limitations of gmm</a></li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; clusters = gmm([1 10.5;1.5 0; 1.8 8; 1.7 15; 3.2 40; 0 0; 3.3 38; 0 -2.3; 5.2 -2.4],3,verbosity=HIGH)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/GMM_clustering.jl#L36-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.initMixtures!-Union{Tuple{T}, Tuple{Vector{T}, Any}} where T&lt;:BetaML.GMM.AbstractGaussian" href="#BetaML.GMM.initMixtures!-Union{Tuple{T}, Tuple{Vector{T}, Any}} where T&lt;:BetaML.GMM.AbstractGaussian"><code>BetaML.GMM.initMixtures!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">initMixtures!(mixtures::Array{T,1}, X; minVariance=0.25, minCovariance=0.0, initStrategy=&quot;grid&quot;,rng=Random.GLOBAL_RNG)</code></pre><p>The parameter <code>initStrategy</code> can be <code>grid</code>, <code>kmeans</code> or <code>given</code>:</p><ul><li><code>grid</code>: Uniformly cover the space observed by the data</li><li><code>kmeans</code>: Use the kmeans algorithm. If the data contains missing values, a first run of <code>predictMissing</code> is done under init=<code>grid</code> to impute the missing values just to allow the kmeans algorithm. Then the em algorithm is used with the output of kmean as init values.</li><li><code>given</code>: Leave the provided set of initial mixtures</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/Mixtures.jl#L94-L103">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.lpdf-Tuple{DiagonalGaussian, Any, Any}" href="#BetaML.GMM.lpdf-Tuple{DiagonalGaussian, Any, Any}"><code>BetaML.GMM.lpdf</code></a> — <span class="docstring-category">Method</span></header><section><div><p>lpdf(m::DiagonalGaussian,x,mask) - Log PDF of the mixture given the observation <code>x</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/Mixtures.jl#L195">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.lpdf-Tuple{FullGaussian, Any, Any}" href="#BetaML.GMM.lpdf-Tuple{FullGaussian, Any, Any}"><code>BetaML.GMM.lpdf</code></a> — <span class="docstring-category">Method</span></header><section><div><p>lpdf(m::FullGaussian,x,mask) - Log PDF of the mixture given the observation <code>x</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/Mixtures.jl#L204">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.GMM.lpdf-Tuple{SphericalGaussian, Any, Any}" href="#BetaML.GMM.lpdf-Tuple{SphericalGaussian, Any, Any}"><code>BetaML.GMM.lpdf</code></a> — <span class="docstring-category">Method</span></header><section><div><p>lpdf(m::SphericalGaussian,x,mask) - Log PDF of the mixture given the observation <code>x</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/2258c27b75d88b45aeaa9884456d202edd656bb0/src/GMM/Mixtures.jl#L185">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="Clustering.html">« Clustering</a><a class="docs-footer-nextpage" href="Imputation.html">Imputation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Thursday 11 August 2022 13:49">Thursday 11 August 2022</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
