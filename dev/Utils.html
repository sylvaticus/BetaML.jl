<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Utils · BetaML.jl Documentation</title><script async src="https://www.googletagmanager.com/gtag/js?id=G-JYKX8QY5JW"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-JYKX8QY5JW', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">BetaML.jl Documentation</a></span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Index</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="tutorials/Betaml_tutorial_getting_started.html">Getting started</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Regression - bike sharing</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Regression - bike sharing/betaml_tutorial_regression_sharingBikes.html">A regression task: the prediction of  bike  sharing demand</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Classification - cars</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Classification - cars/betaml_tutorial_classification_cars.html">A classification task when labels are known - determining the country of origin of cars given the cars characteristics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Clustering - Iris</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Clustering - Iris/betaml_tutorial_cluster_iris.html">A clustering task: the prediction of  plant species from floreal measures (the iris dataset)</a></li></ul></li></ul></li><li><span class="tocitem">API (Reference manual)</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">API V2 (current testing)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Api_v2_user.html">Introduction for user</a></li><li><a class="tocitem" href="Api_v2_developer.html">For developers</a></li></ul></li><li><a class="tocitem" href="Perceptron.html">Perceptron</a></li><li><a class="tocitem" href="Trees.html">Trees</a></li><li><a class="tocitem" href="Nn.html">Nn</a></li><li><a class="tocitem" href="Clustering.html">Clustering</a></li><li><a class="tocitem" href="GMM.html">GMM</a></li><li><a class="tocitem" href="Imputation.html">Imputation</a></li><li class="is-active"><a class="tocitem" href="Utils.html">Utils</a><ul class="internal"><li><a class="tocitem" href="#Module-Index"><span>Module Index</span></a></li><li><a class="tocitem" href="#Detailed-API"><span>Detailed API</span></a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API (Reference manual)</a></li><li class="is-active"><a href="Utils.html">Utils</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="Utils.html">Utils</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/sylvaticus/BetaML.jl/blob/master/docs/src/Utils.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="utils_module"><a class="docs-heading-anchor" href="#utils_module">The BetaML.Utils Module</a><a id="utils_module-1"></a><a class="docs-heading-anchor-permalink" href="#utils_module" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils" href="#BetaML.Utils"><code>BetaML.Utils</code></a> — <span class="docstring-category">Module</span></header><section><div><pre><code class="language-julia hljs">Utils module</code></pre><p>Provide shared utility functions for various machine learning algorithms.</p><p>For the complete list of functions provided see below. The main ones are:</p><p><strong>Helper functions for logging</strong></p><ul><li>Most BetAML functions accept a parameter <code>verbosity</code> that expect one of the element in the <code>Verbosity</code> enoum (<code>NONE</code>, <code>LOW</code>, <code>STD</code>, <code>HIGH</code> or <code>FULL</code>)</li><li>Writing complex code and need to find where something is executed ? Use the macro <a href="Utils.html#BetaML.Utils.@codeLocation-Tuple{}"><code>@codeLocation</code></a></li></ul><p><strong>Stochasticity management</strong></p><ul><li>Utils provide [<code>FIXEDSEED</code>], [<code>FIXEDRNG</code>] and <a href="Utils.html#BetaML.Utils.generateParallelRngs-Tuple{Random.AbstractRNG, Integer}"><code>generateParallelRngs</code></a>. All stochastic functions accept a <code>rng</code> paraemter. See the &quot;Getting started&quot; section in the tutorial for details.</li></ul><p><strong>Data processing</strong></p><ul><li>Various small and large utilities for helping processing the data, expecially before running a ML algorithm</li><li>Includes <a href="Utils.html#BetaML.Utils.getPermutations-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T"><code>getPermutations</code></a>, <a href="Utils.html#BetaML.Utils.oneHotEncoder-Union{Tuple{Union{AbstractVector{T}, T}}, Tuple{T}} where T"><code>oneHotEncoder</code></a>, <a href="Utils.html#BetaML.Utils.integerEncoder-Tuple{AbstractVector{T} where T}"><code>integerEncoder</code></a> (and <a href="Utils.html#BetaML.Utils.integerDecoder-Union{Tuple{T}, Tuple{Any, AbstractVector{T}}} where T"><code>integerDecoder</code></a>), <a href="Trees.html#BetaML.Api.partition-Union{Tuple{Tx}, Tuple{BetaML.Trees.Question{Tx}, Any, Any}} where Tx"><code>partition</code></a>, <a href="Utils.html#BetaML.Utils.scale"><code>scale</code></a> (and <a href="Utils.html#BetaML.Utils.getScaleFactors-Tuple{Any}"><code>getScaleFactors</code></a>), <a href="Utils.html#BetaML.Utils.pca-Tuple{Any}"><code>pca</code></a>, <a href="Utils.html#BetaML.Utils.crossValidation"><code>crossValidation</code></a></li></ul><p><strong>Samplers</strong></p><ul><li>Utilities to sample from data (e.g. for neural network training or for cross-validation)</li><li>Include the &quot;generic&quot; type <a href="Utils.html#BetaML.Utils.SamplerWithData"><code>SamplerWithData</code></a>, together with the sampler implementation <a href="Utils.html#BetaML.Utils.KFold"><code>KFold</code></a> and the function <a href="Utils.html#BetaML.Utils.batch-Tuple{Integer, Integer}"><code>batch</code></a></li></ul><p><strong>Transformers</strong></p><ul><li>Funtions that &quot;transform&quot; a single input (that can be also a vector or a matrix)</li><li>Includes varios NN &quot;activation&quot; functions (<a href="Utils.html#BetaML.Utils.relu-Tuple{Any}"><code>relu</code></a>, <a href="Utils.html#BetaML.Utils.celu-Tuple{Any}"><code>celu</code></a>, <a href="Utils.html#BetaML.Utils.sigmoid-Tuple{Any}"><code>sigmoid</code></a>, <a href="Utils.html#BetaML.Utils.softmax-Tuple{Any}"><code>softmax</code></a>, <a href="Utils.html#BetaML.Utils.pool1d"><code>pool1d</code></a>) and their derivatives (<code>d[FunctionName]</code>), but also <a href="Utils.html#BetaML.Utils.gini-Tuple{Any}"><code>gini</code></a>, <a href="Utils.html#BetaML.Utils.entropy-Tuple{Any}"><code>entropy</code></a>, <a href="Utils.html#BetaML.Utils.variance-Tuple{Any}"><code>variance</code></a>, <a href="Utils.html#BetaML.Utils.bic-Tuple{Any, Any, Any}"><code>BIC</code></a>, <a href="Utils.html#BetaML.Utils.aic-Tuple{Any, Any}"><code>AIC</code></a></li></ul><p><strong>Measures</strong></p><ul><li>Several functions of a pair of parameters (often <code>y</code> and <code>ŷ</code>) to measure the goodness of <code>ŷ</code>, the distance between the two elements of the pair, ...</li><li>Includes &quot;classical&quot; distance functions (<a href="Utils.html#BetaML.Utils.l1_distance-Tuple{Any, Any}"><code>l1_distance</code></a>, <a href="Utils.html#BetaML.Utils.l2_distance-Tuple{Any, Any}"><code>l2_distance</code></a>, <a href="Utils.html#BetaML.Utils.l2²_distance-Tuple{Any, Any}"><code>l2²_distance</code></a> <a href="Utils.html#BetaML.Utils.cosine_distance-Tuple{Any, Any}"><code>cosine_distance</code></a>), &quot;cost&quot; functions for continuous variables (<a href="Utils.html#BetaML.Utils.squaredCost-Tuple{Any, Any}"><code>squaredCost</code></a>, <a href="Utils.html#BetaML.Utils.meanRelError-Tuple{Any, Any}"><code>meanRelError</code></a>) and comparision functions for multui-class variables (<a href="Utils.html#BetaML.Utils.crossEntropy-Tuple{Any, Any}"><code>crossEntropy</code></a>, <a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T"><code>accuracy</code></a>, <a href="Utils.html#BetaML.Utils.ConfusionMatrix"><code>ConfusionMatrix</code></a>).</li></ul><p><strong>Imputers</strong></p><ul><li>Imputers of missing values</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Utils.jl#L16-L49">source</a></section></article><h2 id="Module-Index"><a class="docs-heading-anchor" href="#Module-Index">Module Index</a><a id="Module-Index-1"></a><a class="docs-heading-anchor-permalink" href="#Module-Index" title="Permalink"></a></h2><ul><li><a href="Utils.html#BetaML.Utils.ConfusionMatrix"><code>BetaML.Utils.ConfusionMatrix</code></a></li><li><a href="Utils.html#BetaML.Utils.ConfusionMatrix-Union{Tuple{T}, Tuple{Any, AbstractArray{T, N} where N}} where T"><code>BetaML.Utils.ConfusionMatrix</code></a></li><li><a href="Utils.html#BetaML.Utils.KFold"><code>BetaML.Utils.KFold</code></a></li><li><a href="Utils.html#BetaML.Utils.SamplerWithData"><code>BetaML.Utils.SamplerWithData</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Array{Dict{T, Float64}, 1}, Vector{T}}} where T"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Matrix{T}, Vector{Int64}}} where T&lt;:Number"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T&lt;:Number"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Dict{T, Float64}, T}} where T"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.aic-Tuple{Any, Any}"><code>BetaML.Utils.aic</code></a></li><li><a href="Utils.html#BetaML.Utils.autoJacobian-Tuple{Any, Any}"><code>BetaML.Utils.autoJacobian</code></a></li><li><a href="Utils.html#BetaML.Utils.batch-Tuple{Integer, Integer}"><code>BetaML.Utils.batch</code></a></li><li><a href="Utils.html#BetaML.Utils.bic-Tuple{Any, Any, Any}"><code>BetaML.Utils.bic</code></a></li><li><a href="Utils.html#BetaML.Utils.celu-Tuple{Any}"><code>BetaML.Utils.celu</code></a></li><li><a href="Utils.html#BetaML.Utils.classCounts-Tuple{Any}"><code>BetaML.Utils.classCounts</code></a></li><li><a href="Utils.html#BetaML.Utils.classCountsWithLabels-Tuple{Any}"><code>BetaML.Utils.classCountsWithLabels</code></a></li><li><a href="Utils.html#BetaML.Utils.colsWithMissing-Tuple{Any}"><code>BetaML.Utils.colsWithMissing</code></a></li><li><a href="Utils.html#BetaML.Utils.cosine_distance-Tuple{Any, Any}"><code>BetaML.Utils.cosine_distance</code></a></li><li><a href="Utils.html#BetaML.Utils.crossEntropy-Tuple{Any, Any}"><code>BetaML.Utils.crossEntropy</code></a></li><li><a href="Utils.html#BetaML.Utils.crossValidation"><code>BetaML.Utils.crossValidation</code></a></li><li><a href="Utils.html#BetaML.Utils.dcelu-Tuple{Any}"><code>BetaML.Utils.dcelu</code></a></li><li><a href="Utils.html#BetaML.Utils.delu-Tuple{Any}"><code>BetaML.Utils.delu</code></a></li><li><a href="Utils.html#BetaML.Utils.dmish-Tuple{Any}"><code>BetaML.Utils.dmish</code></a></li><li><a href="Utils.html#BetaML.Utils.dplu-Tuple{Any}"><code>BetaML.Utils.dplu</code></a></li><li><a href="Utils.html#BetaML.Utils.drelu-Tuple{Any}"><code>BetaML.Utils.drelu</code></a></li><li><a href="Utils.html#BetaML.Utils.dsigmoid-Tuple{Any}"><code>BetaML.Utils.dsigmoid</code></a></li><li><a href="Utils.html#BetaML.Utils.dsoftmax-Tuple{Any}"><code>BetaML.Utils.dsoftmax</code></a></li><li><a href="Utils.html#BetaML.Utils.dsoftplus-Tuple{Any}"><code>BetaML.Utils.dsoftplus</code></a></li><li><a href="Utils.html#BetaML.Utils.dtanh-Tuple{Any}"><code>BetaML.Utils.dtanh</code></a></li><li><a href="Utils.html#BetaML.Utils.elu-Tuple{Any}"><code>BetaML.Utils.elu</code></a></li><li><a href="Utils.html#BetaML.Utils.entropy-Tuple{Any}"><code>BetaML.Utils.entropy</code></a></li><li><a href="Utils.html#BetaML.Utils.generateParallelRngs-Tuple{Random.AbstractRNG, Integer}"><code>BetaML.Utils.generateParallelRngs</code></a></li><li><a href="Utils.html#BetaML.Utils.getPermutations-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T"><code>BetaML.Utils.getPermutations</code></a></li><li><a href="Utils.html#BetaML.Utils.getScaleFactors-Tuple{Any}"><code>BetaML.Utils.getScaleFactors</code></a></li><li><a href="Utils.html#BetaML.Utils.gini-Tuple{Any}"><code>BetaML.Utils.gini</code></a></li><li><a href="Utils.html#BetaML.Utils.integerDecoder-Union{Tuple{T}, Tuple{Any, AbstractVector{T}}} where T"><code>BetaML.Utils.integerDecoder</code></a></li><li><a href="Utils.html#BetaML.Utils.integerEncoder-Tuple{AbstractVector{T} where T}"><code>BetaML.Utils.integerEncoder</code></a></li><li><a href="Utils.html#BetaML.Utils.issortable-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T, N}"><code>BetaML.Utils.issortable</code></a></li><li><a href="Utils.html#BetaML.Utils.l1_distance-Tuple{Any, Any}"><code>BetaML.Utils.l1_distance</code></a></li><li><a href="Utils.html#BetaML.Utils.l2_distance-Tuple{Any, Any}"><code>BetaML.Utils.l2_distance</code></a></li><li><a href="Utils.html#BetaML.Utils.l2²_distance-Tuple{Any, Any}"><code>BetaML.Utils.l2²_distance</code></a></li><li><a href="Utils.html#BetaML.Utils.lse-Tuple{Any}"><code>BetaML.Utils.lse</code></a></li><li><a href="Utils.html#BetaML.Utils.makeMatrix-Tuple{AbstractArray}"><code>BetaML.Utils.makeMatrix</code></a></li><li><a href="Utils.html#BetaML.Utils.meanDicts-Tuple{Any}"><code>BetaML.Utils.meanDicts</code></a></li><li><a href="Utils.html#BetaML.Utils.meanRelError-Tuple{Any, Any}"><code>BetaML.Utils.meanRelError</code></a></li><li><a href="Utils.html#BetaML.Utils.mish-Tuple{Any}"><code>BetaML.Utils.mish</code></a></li><li><a href="Utils.html#BetaML.Utils.mode-Union{Tuple{Dict{T, Float64}}, Tuple{T}} where T"><code>BetaML.Utils.mode</code></a></li><li><a href="Utils.html#BetaML.Utils.mode-Union{Tuple{AbstractArray{Dict{T, Float64}, N} where N}, Tuple{T}} where T"><code>BetaML.Utils.mode</code></a></li><li><a href="Utils.html#BetaML.Utils.mode-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Number"><code>BetaML.Utils.mode</code></a></li><li><a href="Utils.html#BetaML.Utils.mse-Tuple{Any, Any}"><code>BetaML.Utils.mse</code></a></li><li><a href="Utils.html#BetaML.Utils.oneHotDecoder-Tuple{Any}"><code>BetaML.Utils.oneHotDecoder</code></a></li><li><a href="Utils.html#BetaML.Utils.oneHotEncoder-Union{Tuple{Union{AbstractVector{T}, T}}, Tuple{T}} where T"><code>BetaML.Utils.oneHotEncoder</code></a></li><li><a href="Utils.html#BetaML.Utils.pca-Tuple{Any}"><code>BetaML.Utils.pca</code></a></li><li><a href="Utils.html#BetaML.Utils.plu-Tuple{Any}"><code>BetaML.Utils.plu</code></a></li><li><a href="Utils.html#BetaML.Utils.polynomialKernel-Tuple{Any, Any}"><code>BetaML.Utils.polynomialKernel</code></a></li><li><a href="Utils.html#BetaML.Utils.pool1d"><code>BetaML.Utils.pool1d</code></a></li><li><a href="Utils.html#BetaML.Utils.radialKernel-Tuple{Any, Any}"><code>BetaML.Utils.radialKernel</code></a></li><li><a href="Utils.html#BetaML.Utils.relu-Tuple{Any}"><code>BetaML.Utils.relu</code></a></li><li><a href="Utils.html#BetaML.Utils.scale"><code>BetaML.Utils.scale</code></a></li><li><a href="Utils.html#BetaML.Utils.sigmoid-Tuple{Any}"><code>BetaML.Utils.sigmoid</code></a></li><li><a href="Utils.html#BetaML.Utils.singleUnique-Union{Tuple{Union{AbstractArray{T, N} where N, T}}, Tuple{T}} where T"><code>BetaML.Utils.singleUnique</code></a></li><li><a href="Utils.html#BetaML.Utils.softmax-Tuple{Any}"><code>BetaML.Utils.softmax</code></a></li><li><a href="Utils.html#BetaML.Utils.softplus-Tuple{Any}"><code>BetaML.Utils.softplus</code></a></li><li><a href="Utils.html#BetaML.Utils.squaredCost-Tuple{Any, Any}"><code>BetaML.Utils.squaredCost</code></a></li><li><a href="Utils.html#BetaML.Utils.sterling-Tuple{BigInt, BigInt}"><code>BetaML.Utils.sterling</code></a></li><li><a href="Utils.html#BetaML.Utils.variance-Tuple{Any}"><code>BetaML.Utils.variance</code></a></li><li><a href="Utils.html#BetaML.Utils.@codeLocation-Tuple{}"><code>BetaML.Utils.@codeLocation</code></a></li></ul><h2 id="Detailed-API"><a class="docs-heading-anchor" href="#Detailed-API">Detailed API</a><a id="Detailed-API-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.ConfusionMatrix" href="#BetaML.Utils.ConfusionMatrix"><code>BetaML.Utils.ConfusionMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConfusionMatrix</code></pre><p>Scores and measures resulting from a comparation between true and predicted categorical variables</p><p>Use the function <code>ConfusionMatrix(ŷ,y;classes,labels,rng)</code> to build it and <code>report(cm::ConfusionMatrix;what)</code> to visualise it, or use the individual parts of interest, e.g. <code>display(cm.scores)</code>.</p><p><strong>Fields:</strong></p><ul><li><code>labels</code>: Array of categorical labels</li><li><code>accuracy</code>: Overall accuracy rate</li><li><code>misclassification</code>: Overall misclassification rate</li><li><code>actualCount</code>: Array of counts per lebel in the actual data</li><li><code>predictedCount</code>: Array of counts per label in the predicted data</li><li><code>scores</code>: Matrix actual (rows) vs predicted (columns)</li><li><code>normalisedScores</code>: Normalised scores</li><li><code>tp</code>: True positive (by class)</li><li><code>tn</code>: True negative (by class)</li><li><code>fp</code>: False positive (by class), aka &quot;type I error&quot; or &quot;false allarm&quot;</li><li><code>fn</code>: False negative (by class), aka &quot;type II error&quot; or &quot;miss&quot;</li><li><code>precision</code>: True class i over predicted class i (by class)</li><li><code>recall</code>: Predicted class i over true class i (by class), aka &quot;True Positive Rate (TPR)&quot;, &quot;Sensitivity&quot; or &quot;Probability of detection&quot;</li><li><code>specificity</code>: Predicted not class i over true not class i (by class), aka &quot;True Negative Rate (TNR)&quot;</li><li><code>f1Score</code>: Harmonic mean of precision and recall</li><li><code>meanPrecision</code>: Mean by class, respectively unweighted and weighted by actualCount</li><li><code>meanRecall</code>: Mean by class, respectively unweighted and weighted by actualCount</li><li><code>meanSpecificity</code>: Mean by class, respectively unweighted and weighted by actualCount</li><li><code>meanF1Score</code>: Mean by class, respectively unweighted and weighted by actualCount</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L152-L182">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.ConfusionMatrix-Union{Tuple{T}, Tuple{Any, AbstractArray{T, N} where N}} where T" href="#BetaML.Utils.ConfusionMatrix-Union{Tuple{T}, Tuple{Any, AbstractArray{T, N} where N}} where T"><code>BetaML.Utils.ConfusionMatrix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ConfusionMatrix(ŷ,y;classes,labels,rng)</code></pre><p>Build a &quot;confusion matrix&quot; between predicted (columns) vs actual (rows) categorical values</p><p><strong>Parameters:</strong></p><ul><li><code>ŷ</code>: Vector of predicted categorical data</li><li><code>y</code>: Vector of actual categorical data</li><li><code>classes</code>: The full set of possible classes (useful to give a specicif order or if not al lclasses are represented in <code>y</code>) [def: <code>unique(y)</code> ]</li><li><code>labels</code>: String representation of the classes [def: <code>string.(classes)</code>]</li><li><code>rng</code>: Random number generator. Used only if <code>ŷ</code> is given in terms of a PMF and there are multi-modal values, as these are assigned randomply [def: <code>Random.GLOBAL_RNG</code>]</li></ul><p><strong>Return:</strong></p><ul><li>a <code>ConfusionMatrix</code> object</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L212-L226">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.KFold" href="#BetaML.Utils.KFold"><code>BetaML.Utils.KFold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>KFold(nSplits=5,nRepeats=1,shuffle=true,rng=Random.GLOBAL_RNG)</p><p>Iterator for k-fold crossValidation strategy.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Samplers.jl#L33-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.SamplerWithData" href="#BetaML.Utils.SamplerWithData"><code>BetaML.Utils.SamplerWithData</code></a> — <span class="docstring-category">Type</span></header><section><div><p>SamplerWithData{Tsampler}</p><p>Associate an instance of an AbstractDataSampler with the actual data to sample.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Samplers.jl#L4-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.error-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T" href="#Base.error-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T"><code>Base.error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>error(ŷ,y;ignoreLabels=false) - Categorical error (T vs T)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.error-Union{Tuple{T}, Tuple{Array{Dict{T, Float64}, 1}, Vector{T}}} where T" href="#Base.error-Union{Tuple{T}, Tuple{Array{Dict{T, Float64}, 1}, Vector{T}}} where T"><code>Base.error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>error(ŷ,y) - Categorical error with with probabilistic predictions of a dataset given in terms of a dictionary of probabilities (Dict{T,Float64} vs T). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L149">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.error-Union{Tuple{T}, Tuple{Matrix{T}, Vector{Int64}}} where T&lt;:Number" href="#Base.error-Union{Tuple{T}, Tuple{Matrix{T}, Vector{Int64}}} where T&lt;:Number"><code>Base.error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>error(ŷ,y) - Categorical error with probabilistic predictions of a dataset (PMF vs Int). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L147">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.error-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T&lt;:Number" href="#Base.error-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T&lt;:Number"><code>Base.error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>error(ŷ,y) - Categorical error with probabilistic prediction of a single datapoint (PMF vs Int). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L145">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.print-Union{Tuple{T}, Tuple{IO, ConfusionMatrix{T}}, Tuple{IO, ConfusionMatrix{T}, Any}} where T" href="#Base.print-Union{Tuple{T}, Tuple{IO, ConfusionMatrix{T}}, Tuple{IO, ConfusionMatrix{T}, Any}} where T"><code>Base.print</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">print(cm,what)</code></pre><p>Print a <code>ConfusionMatrix</code> object</p><p>The <code>what</code> parameter is a string vector that can include &quot;all&quot;, &quot;scores&quot;, &quot;normalisedScores&quot; or &quot;report&quot; [def: <code>[&quot;all&quot;]</code>]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L258-L264">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.reshape-Union{Tuple{T}, Tuple{T, Vararg{Any, N} where N}} where T&lt;:Number" href="#Base.reshape-Union{Tuple{T}, Tuple{T, Vararg{Any, N} where N}} where T&lt;:Number"><code>Base.reshape</code></a> — <span class="docstring-category">Method</span></header><section><div><p>reshape(myNumber, dims..) - Reshape a number as a n dimensional Array </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Api.partition-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{Float64}}} where T&lt;:AbstractArray" href="#BetaML.Api.partition-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{Float64}}} where T&lt;:AbstractArray"><code>BetaML.Api.partition</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">partition(data,parts;shuffle,dims,rng)</code></pre><p>Partition (by rows) one or more matrices according to the shares in <code>parts</code>.</p><p><strong>Parameters</strong></p><ul><li><code>data</code>: A matrix/vector or a vector of matrices/vectors</li><li><code>parts</code>: A vector of the required shares (must sum to 1)</li><li><code>shufle</code>: Whether to randomly shuffle the matrices (preserving the relative order between matrices)</li><li><code>dims</code>: The dimension for which to partition [def: <code>1</code>]</li><li><code>copy</code>: Wheter to <em>copy</em> the actual data or only create a reference [def: <code>true</code>]</li><li><code>rng</code>: Random Number Generator (see <a href="@ref"><code>FIXEDSEED</code></a>) [deafult: <code>Random.GLOBAL_RNG</code>]</li></ul><p><strong>Notes:</strong></p><ul><li>The sum of parts must be equal to 1</li><li>The number of elements in the specified dimension must be the same for all the arrays in <code>data</code></li></ul><p><strong>Example:</strong></p><p><code>julia julia&gt; x = [1:10 11:20] julia&gt; y = collect(31:40) julia&gt; ((xtrain,xtest),(ytrain,ytest)) = partition([x,y],[0.7,0.3])</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L209-L232">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>accuracy(ŷ,y;ignoreLabels=false) - Categorical accuracy between two vectors (T vs T). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Array{Dict{T, Float64}, 1}, Vector{T}}} where T" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Array{Dict{T, Float64}, 1}, Vector{T}}} where T"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>accuracy(ŷ,y;tol)</p><p>Categorical accuracy with probabilistic predictions of a dataset given in terms of a dictionary of probabilities (Dict{T,Float64} vs T).</p><p><strong>Parameters:</strong></p><ul><li><code>ŷ</code>: An array where each item is the estimated probability mass function in terms of a Dictionary(Item1 =&gt; Prob1, Item2 =&gt; Prob2, ...)</li><li><code>y</code>: The N array with the correct category for each point <span>$n$</span>.</li><li><code>tol</code>: The tollerance to the prediction, i.e. if considering &quot;correct&quot; only a prediction where the value with highest probability is the true value (<code>tol</code> = 1), or consider instead the set of <code>tol</code> maximum values [def: <code>1</code>].</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L127-L137">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Dict{T, Float64}, T}} where T" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Dict{T, Float64}, T}} where T"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">accuracy(ŷ,y;tol)</code></pre><p>Categorical accuracy with probabilistic prediction of a single datapoint given in terms of a dictionary of probabilities (Dict{T,Float64} vs T).</p><p><strong>Parameters:</strong></p><ul><li><code>ŷ</code>: The returned probability mass function in terms of a Dictionary(Item1 =&gt; Prob1, Item2 =&gt; Prob2, ...)</li><li><code>tol</code>: The tollerance to the prediction, i.e. if considering &quot;correct&quot; only a prediction where the value with highest probability is the true value (<code>tol</code> = 1), or consider instead the set of <code>tol</code> maximum values [def: <code>1</code>].</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L84-L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Matrix{T}, Vector{Int64}}} where T&lt;:Number" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Matrix{T}, Vector{Int64}}} where T&lt;:Number"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>accuracy(ŷ,y;tol,ignoreLabels)</p><p>Categorical accuracy with probabilistic predictions of a dataset (PMF vs Int).</p><p><strong>Parameters:</strong></p><ul><li><code>ŷ</code>: An (N,K) matrix of probabilities that each <span>$\hat y_n$</span> record with <span>$n \in 1,....,N$</span>  being of category <span>$k$</span> with <span>$k \in 1,...,K$</span>.</li><li><code>y</code>: The N array with the correct category for each point <span>$n$</span>.</li><li><code>tol</code>: The tollerance to the prediction, i.e. if considering &quot;correct&quot; only a prediction where the value with highest probability is the true value (<code>tol</code> = 1), or consider instead the set of <code>tol</code> maximum values [def: <code>1</code>].</li><li><code>ignoreLabels</code>: Whether to ignore the specific label order in y. Useful for unsupervised learning algorithms where the specific label order don&#39;t make sense [def: false]</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L101-L112">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T&lt;:Number" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Vector{T}, Int64}} where T&lt;:Number"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">accuracy(ŷ,y;tol)</code></pre><p>Categorical accuracy with probabilistic prediction of a single datapoint (PMF vs Int).</p><p>Use the parameter tol [def: <code>1</code>] to determine the tollerance of the prediction, i.e. if considering &quot;correct&quot; only a prediction where the value with highest probability is the true value (<code>tol</code> = 1), or consider instead the set of <code>tol</code> maximum values.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L65-L70">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.aic-Tuple{Any, Any}" href="#BetaML.Utils.aic-Tuple{Any, Any}"><code>BetaML.Utils.aic</code></a> — <span class="docstring-category">Method</span></header><section><div><p>aic(lL,k) -  Akaike information criterion (lower is better)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L168">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.autoJacobian-Tuple{Any, Any}" href="#BetaML.Utils.autoJacobian-Tuple{Any, Any}"><code>BetaML.Utils.autoJacobian</code></a> — <span class="docstring-category">Method</span></header><section><div><p>autoJacobian(f,x;nY)</p><p>Evaluate the Jacobian using AD in the form of a (nY,nX) matrix of first derivatives</p><p><strong>Parameters:</strong></p><ul><li><code>f</code>: The function to compute the Jacobian</li><li><code>x</code>: The input to the function where the jacobian has to be computed</li><li><code>nY</code>: The number of outputs of the function <code>f</code> [def: <code>length(f(x))</code>]</li></ul><p><strong>Return values:</strong></p><ul><li>An <code>Array{Float64,2}</code> of the locally evaluated Jacobian</li></ul><p><strong>Notes:</strong></p><ul><li>The <code>nY</code> parameter is optional. If provided it avoids having to compute <code>f(x)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L79-L94">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.batch-Tuple{Integer, Integer}" href="#BetaML.Utils.batch-Tuple{Integer, Integer}"><code>BetaML.Utils.batch</code></a> — <span class="docstring-category">Method</span></header><section><div><p>batch(n,bSize;sequential=false,rng)</p><p>Return a vector of <code>bSize</code> vectors of indeces from <code>1</code> to <code>n</code>. Randomly unless the optional parameter <code>sequential</code> is used.</p><p><strong>Example:</strong></p><p><code>julia julia&gt; Utils.batch(6,2,sequential=true) 3-element Array{Array{Int64,1},1}:  [1, 2]  [3, 4]  [5, 6]</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Samplers.jl#L96-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.bic-Tuple{Any, Any, Any}" href="#BetaML.Utils.bic-Tuple{Any, Any, Any}"><code>BetaML.Utils.bic</code></a> — <span class="docstring-category">Method</span></header><section><div><p>bic(lL,k,n) -  Bayesian information criterion (lower is better)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L166">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.celu-Tuple{Any}" href="#BetaML.Utils.celu-Tuple{Any}"><code>BetaML.Utils.celu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>celu(x; α=1) </p><p>https://arxiv.org/pdf/1704.07483.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L18-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.classCounts-Tuple{Any}" href="#BetaML.Utils.classCounts-Tuple{Any}"><code>BetaML.Utils.classCounts</code></a> — <span class="docstring-category">Method</span></header><section><div><p>classCounts(x;classes=nothing)</p><p>Return a (unsorted) vector with the counts of each unique item (element or rows) in a dataset.</p><p>If order is important or not all classes are present in the data, a preset vectors of classes can be given in the parameter <code>classes</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L535-L542">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.classCountsWithLabels-Tuple{Any}" href="#BetaML.Utils.classCountsWithLabels-Tuple{Any}"><code>BetaML.Utils.classCountsWithLabels</code></a> — <span class="docstring-category">Method</span></header><section><div><p>classCountsWithLabels(x)</p><p>Return a dictionary that counts the number of each unique item (rows) in a dataset.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L502-L507">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.colsWithMissing-Tuple{Any}" href="#BetaML.Utils.colsWithMissing-Tuple{Any}"><code>BetaML.Utils.colsWithMissing</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">colsWithMissing(x)</code></pre><p>Retuyrn an array with the ids of the columns where there is at least a missing value.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L413-L417">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.cosine_distance-Tuple{Any, Any}" href="#BetaML.Utils.cosine_distance-Tuple{Any, Any}"><code>BetaML.Utils.cosine_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Cosine distance</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.crossEntropy-Tuple{Any, Any}" href="#BetaML.Utils.crossEntropy-Tuple{Any, Any}"><code>BetaML.Utils.crossEntropy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>crossEntropy(ŷ, y; weight)</p><p>Compute the (weighted) cross-entropy between the predicted and the sampled probability distributions.</p><p>To be used in classification problems.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L25-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.crossValidation" href="#BetaML.Utils.crossValidation"><code>BetaML.Utils.crossValidation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">crossValidation(f,data,sampler;dims,verbosity,returnStatistics)</code></pre><p>Perform crossValidation according to <code>sampler</code> rule by calling the function f and collecting its output</p><p><strong>Parameters</strong></p><ul><li><code>f</code>: The user-defined function that consume the specific train and validation data and return somehting (often the associated validation error). See later</li><li><code>data</code>: A single n-dimenasional array or a vector of them (e.g. X,Y), depending on the tasks required by <code>f</code>.</li><li>sampler: An istance of a <code>AbstractDataSampler</code>, defining the &quot;rules&quot; for sampling at each iteration. [def: <code>KFold(nSplits=5,nRepeats=1,shuffle=true,rng=Random.GLOBAL_RNG)</code> ]</li><li><code>dims</code>: The dimension over performing the crossValidation i.e. the dimension containing the observations [def: <code>1</code>]</li><li><code>verbosity</code>: The verbosity to print information during each iteration (this can also be printed in the <code>f</code> function) [def: <code>STD</code>]</li><li><code>returnStatistics</code>: Wheter crossValidation should return the statistics of the output of <code>f</code> (mean and standard deviation) or the whole outputs [def: <code>true</code>].</li></ul><p><strong>Notes</strong></p><p>crossValidation works by calling the function <code>f</code>, defined by the user, passing to it the tuple <code>trainData</code>, <code>valData</code> and <code>rng</code> and collecting the result of the function f. The specific method for which <code>trainData</code>, and <code>valData</code> are selected at each iteration depends on the specific <code>sampler</code>, whith a single 5 k-fold rule being the default.</p><p>This approach is very flexible because the specific model to employ or the metric to use is left within the user-provided function. The only thing that crossValidation does is provide the model defined in the function <code>f</code> with the opportune data (and the random number generator).</p><p><strong>Input of the user-provided function</strong> <code>trainData</code> and <code>valData</code> are both themselves tuples. In supervised models, crossValidations <code>data</code> should be a tuple of (X,Y) and <code>trainData</code> and <code>valData</code> will be equivalent to (xtrain, ytrain) and (xval, yval). In unsupervised models <code>data</code> is a single array, but the training and validation data should still need to be accessed as  <code>trainData[1]</code> and <code>valData[1]</code>. <strong>Output of the user-provided function</strong> The user-defined function can return whatever. However, if <code>returnStatistics</code> is left on its default <code>true</code> value the user-defined function must return a single scalar (e.g. some error measure) so that the mean and the standard deviation are returned.</p><p>Note that <code>crossValidation</code> can beconveniently be employed using the <code>do</code> syntax, as Julia automatically rewrite <code>crossValidation(data,...) trainData,valData,rng  ...user defined body... end</code> as <code>crossValidation(f(trainData,valData,rng ), data,...)</code></p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">julia&gt; X = [11:19 21:29 31:39 41:49 51:59 61:69];
julia&gt; Y = [1:9;];
julia&gt; sampler = KFold(nSplits=3);
julia&gt; (μ,σ) = crossValidation([X,Y],sampler) do trainData,valData,rng
                 (xtrain,ytrain) = trainData; (xval,yval) = valData
                 trainedModel    = buildForest(xtrain,ytrain,30)
                 predictions     = predict(trainedModel,xval)
                 ϵ               = meanRelError(predictions,yval,normRec=false)
                 return ϵ
               end
(0.3202242202242202, 0.04307662219315022)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L432-L474">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.dcelu-Tuple{Any}" href="#BetaML.Utils.dcelu-Tuple{Any}"><code>BetaML.Utils.dcelu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dcelu(x; α=1) </p><p>https://arxiv.org/pdf/1704.07483.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L21-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.delu-Tuple{Any}" href="#BetaML.Utils.delu-Tuple{Any}"><code>BetaML.Utils.delu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>delu(x; α=1) with α &gt; 0 </p><p>https://arxiv.org/pdf/1511.07289.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L16-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.dmish-Tuple{Any}" href="#BetaML.Utils.dmish-Tuple{Any}"><code>BetaML.Utils.dmish</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dmish(x) </p><p>https://arxiv.org/pdf/1908.08681v1.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L75-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.dplu-Tuple{Any}" href="#BetaML.Utils.dplu-Tuple{Any}"><code>BetaML.Utils.dplu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dplu(x;α=0.1,c=1) </p><p>Piecewise Linear Unit derivative </p><p>https://arxiv.org/pdf/1809.09534.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L25-L30">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.drelu-Tuple{Any}" href="#BetaML.Utils.drelu-Tuple{Any}"><code>BetaML.Utils.drelu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>drelu(x) </p><p>Rectified Linear Unit </p><p>https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L12-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.dsigmoid-Tuple{Any}" href="#BetaML.Utils.dsigmoid-Tuple{Any}"><code>BetaML.Utils.dsigmoid</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dsigmoid(x)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.dsoftmax-Tuple{Any}" href="#BetaML.Utils.dsoftmax-Tuple{Any}"><code>BetaML.Utils.dsoftmax</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dsoftmax(x; β=1) </p><p>Derivative of the softmax function </p><p>https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L50-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.dsoftplus-Tuple{Any}" href="#BetaML.Utils.dsoftplus-Tuple{Any}"><code>BetaML.Utils.dsoftplus</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dsoftplus(x) </p><p>https://en.wikipedia.org/wiki/Rectifier<em>(neural</em>networks)#Softplus</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L71-L74">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.dtanh-Tuple{Any}" href="#BetaML.Utils.dtanh-Tuple{Any}"><code>BetaML.Utils.dtanh</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dtanh(x)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.elu-Tuple{Any}" href="#BetaML.Utils.elu-Tuple{Any}"><code>BetaML.Utils.elu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>elu(x; α=1) with α &gt; 0 </p><p>https://arxiv.org/pdf/1511.07289.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L14-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.entropy-Tuple{Any}" href="#BetaML.Utils.entropy-Tuple{Any}"><code>BetaML.Utils.entropy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>entropy(x)</p><p>Calculate the entropy for a list of items (or rows).</p><p>See: https://en.wikipedia.org/wiki/Decision<em>tree</em>learning#Gini_impurity</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L142-L148">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.generateParallelRngs-Tuple{Random.AbstractRNG, Integer}" href="#BetaML.Utils.generateParallelRngs-Tuple{Random.AbstractRNG, Integer}"><code>BetaML.Utils.generateParallelRngs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">generateParallelRngs(rng::AbstractRNG, n::Integer;reSeed=false)</code></pre><p>For multi-threaded models, return n independent random number generators (one per thread) to be used in threaded computations.</p><p>Note that each ring is a <em>copy</em> of the original random ring. This means that code that <em>use</em> these RNGs will not change the original RNG state.</p><p>Use it with <code>rngs = generateParallelRngs(rng,Threads.nthreads())</code> to have a separate rng per thread. By default the function doesn&#39;t re-seed the RNG, as you may want to have a loop index based re-seeding strategy rather than a threadid-based one (to guarantee the same result independently of the number of threads). If you prefer, you can instead re-seed the RNG here (using the parameter <code>reSeed=true</code>), such that each thread has a different seed. Be aware however that the stream  of number generated will depend from the number of threads at run time.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Stochasticity.jl#L9-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.getPermutations-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T" href="#BetaML.Utils.getPermutations-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T"><code>BetaML.Utils.getPermutations</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">getPermutations(v::AbstractArray{T,1};keepStructure=false)</code></pre><p>Return a vector of either (a) all possible permutations (uncollected) or (b) just those based on the unique values of the vector</p><p>Useful to measure accuracy where you don&#39;t care about the actual name of the labels, like in unsupervised classifications (e.g. clustering)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L25-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.getScaleFactors-Tuple{Any}" href="#BetaML.Utils.getScaleFactors-Tuple{Any}"><code>BetaML.Utils.getScaleFactors</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">getScaleFactors(x;skip)</code></pre><p>Return the scale factors (for each dimensions) in order to scale a matrix X (n,d) such that each dimension has mean 0 and variance 1. Note that missing values are skipped.</p><p><strong>Parameters</strong></p><ul><li><code>x</code>: the (n × d) dimension matrix to scale on each dimension d</li><li><code>skip</code>: an array of dimension index to skip the scaling [def: <code>[]</code>]</li></ul><p><strong>Return</strong></p><ul><li>A touple whose first elmement is the shift and the second the multiplicative</li></ul><p>term to make the scale.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L269-L282">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.gini-Tuple{Any}" href="#BetaML.Utils.gini-Tuple{Any}"><code>BetaML.Utils.gini</code></a> — <span class="docstring-category">Method</span></header><section><div><p>gini(x)</p><p>Calculate the Gini Impurity for a list of items (or rows).</p><p>See: https://en.wikipedia.org/wiki/Decision<em>tree</em>learning#Information_gain</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L113-L119">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.integerDecoder-Union{Tuple{T}, Tuple{Any, AbstractVector{T}}} where T" href="#BetaML.Utils.integerDecoder-Union{Tuple{T}, Tuple{Any, AbstractVector{T}}} where T"><code>BetaML.Utils.integerDecoder</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">integerDecoder(x,factors::AbstractVector{T};unique)</code></pre><p>Decode an array of integers to an array of T corresponding to the elements of <code>factors</code></p><p><strong>Parameters:</strong></p><ul><li><code>x</code>: The vector to decode</li><li><code>factors</code>: The vector of elements to use for the encoding</li><li><code>unique</code>: Wether <code>factors</code> is already made of unique elements [def: <code>true</code>]</li></ul><p><strong>Return:</strong></p><ul><li>A vector of length(x) elements corresponding to the (unique) <code>factors</code> elements at the position x</li></ul><p><strong>Example:</strong></p><pre><code class="nohighlight hljs">julia&gt; integerDecoder([1, 2, 2, 3, 2, 1],[&quot;aa&quot;,&quot;cc&quot;,&quot;bb&quot;]) # out: [&quot;aa&quot;,&quot;cc&quot;,&quot;cc&quot;,&quot;bb&quot;,&quot;cc&quot;,&quot;aa&quot;]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L186-L201">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.integerEncoder-Tuple{AbstractVector{T} where T}" href="#BetaML.Utils.integerEncoder-Tuple{AbstractVector{T} where T}"><code>BetaML.Utils.integerEncoder</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">integerEncoder(x;factors=unique(x))</code></pre><p>Encode an array of T to an array of integers using the their position in <code>factor</code> vector (default to the unique vector of the input array)</p><p><strong>Parameters:</strong></p><ul><li><code>x</code>: The vector to encode</li><li><code>factors</code>: The vector of factors whose position is the result of the encoding [def: <code>unique(x)</code>]</li></ul><p><strong>Return:</strong></p><ul><li>A vector of [1,length(x)] integers corresponding to the position of each element in the <code>factors</code> vector`</li></ul><p><strong>Note:</strong></p><ul><li>Attention that while this function creates a ordered (and sortable) set, it is up to the user to be sure that this &quot;property&quot; is not indeed used in his code if the unencoded data is indeed unordered.</li></ul><p><strong>Example:</strong></p><pre><code class="nohighlight hljs">julia&gt; integerEncoder([&quot;a&quot;,&quot;e&quot;,&quot;b&quot;,&quot;e&quot;],factors=[&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;]) # out: [1,5,2,5]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L164-L180">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.issortable-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T, N}" href="#BetaML.Utils.issortable-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T, N}"><code>BetaML.Utils.issortable</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Return wheather an array is sortable, i.e. has methos issort defined</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.l1_distance-Tuple{Any, Any}" href="#BetaML.Utils.l1_distance-Tuple{Any, Any}"><code>BetaML.Utils.l1_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>L1 norm distance (aka <em>Manhattan Distance</em>)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.l2_distance-Tuple{Any, Any}" href="#BetaML.Utils.l2_distance-Tuple{Any, Any}"><code>BetaML.Utils.l2_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Euclidean (L2) distance</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.l2²_distance-Tuple{Any, Any}" href="#BetaML.Utils.l2²_distance-Tuple{Any, Any}"><code>BetaML.Utils.l2²_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Squared Euclidean (L2) distance</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.lse-Tuple{Any}" href="#BetaML.Utils.lse-Tuple{Any}"><code>BetaML.Utils.lse</code></a> — <span class="docstring-category">Method</span></header><section><div><p>LogSumExp for efficiently computing log(sum(exp.(x))) </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L645">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.makeMatrix-Tuple{AbstractArray}" href="#BetaML.Utils.makeMatrix-Tuple{AbstractArray}"><code>BetaML.Utils.makeMatrix</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Transform an Array{T,1} in an Array{T,2} and leave unchanged Array{T,2}.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.meanDicts-Tuple{Any}" href="#BetaML.Utils.meanDicts-Tuple{Any}"><code>BetaML.Utils.meanDicts</code></a> — <span class="docstring-category">Method</span></header><section><div><p>meanDicts(dicts)</p><p>Compute the mean of the values of an array of dictionaries.</p><p>Given <code>dicts</code> an array of dictionaries, <code>meanDicts</code> first compute the union of the keys and then average the values. If the original valueas are probabilities (non-negative items summing to 1), the result is also a probability distribution.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L611-L619">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.meanRelError-Tuple{Any, Any}" href="#BetaML.Utils.meanRelError-Tuple{Any, Any}"><code>BetaML.Utils.meanRelError</code></a> — <span class="docstring-category">Method</span></header><section><div><p>meanRelError(ŷ,y;normDim=true,normRec=true,p=1)</p><p>Compute the mean relative error (l-1 based by default) between ŷ and y.</p><p>There are many ways to compute a mean relative error. In particular, if normRec (normDim) is set to true, the records (dimensions) are normalised, in the sense that it doesn&#39;t matter if a record (dimension) is bigger or smaller than the others, the relative error is first computed for each record (dimension) and then it is averaged. With both <code>normDim</code> and <code>normRec</code> set to <code>false</code> the function returns the relative mean error; with both set to <code>true</code> (default) it returns the mean relative error (i.e. with p=1 the &quot;<a href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error">mean absolute percentage error (MAPE)</a>&quot;) The parameter <code>p</code> [def: <code>1</code>] controls the p-norm used to define the error.</p><p>The <em>mean relative error</em> enfatises the relativeness of the error, i.e. all observations and dimensions weigth the same, wether large or small. Conversly, in the <em>relative mean error</em> the same relative error on larger observations (or dimensions) weights more.</p><p>For example, given <code>y = [1,44,3]</code> and <code>ŷ = [2,45,2]</code>, the <em>mean relative error</em> <code>meanRelError(ŷ,y)</code> is <code>0.452</code>, while the <em>relative mean error</em> <code>meanRelError(ŷ,y, normRec=false)</code> is &quot;only&quot; <code>0.0625</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L335-L348">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.mish-Tuple{Any}" href="#BetaML.Utils.mish-Tuple{Any}"><code>BetaML.Utils.mish</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mish(x) </p><p>https://arxiv.org/pdf/1908.08681v1.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L73-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.mode-Union{Tuple{AbstractArray{Dict{T, Float64}, N} where N}, Tuple{T}} where T" href="#BetaML.Utils.mode-Union{Tuple{AbstractArray{Dict{T, Float64}, N} where N}, Tuple{T}} where T"><code>BetaML.Utils.mode</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mode(elements,rng)</p><p>Given a vector of dictionaries whose key is numerical (e.g. probabilities), a vector of vectors or a matrix, it returns the mode of each element (dictionary, vector or row) in terms of the key or the position.</p><p>Use it to return a unique value from a multiclass classifier returning probabilities.</p><p><strong>Note:</strong></p><ul><li>If multiple classes have the highest mode, one is returned at random (use the parameter <code>rng</code> to fix the stochasticity)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L588-L598">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.mode-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Number" href="#BetaML.Utils.mode-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Number"><code>BetaML.Utils.mode</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mode(v::AbstractVector{T};rng)</p><p>Return the position with the highest value in an array, interpreted as mode (using rand in case of multimodal values)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L572-L577">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.mode-Union{Tuple{Dict{T, Float64}}, Tuple{T}} where T" href="#BetaML.Utils.mode-Union{Tuple{Dict{T, Float64}}, Tuple{T}} where T"><code>BetaML.Utils.mode</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mode(dict::Dict{T,Float64};rng)</p><p>Return the key with highest mode (using rand in case of multimodal values)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L557-L562">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.mse-Tuple{Any, Any}" href="#BetaML.Utils.mse-Tuple{Any, Any}"><code>BetaML.Utils.mse</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mse(ŷ,y)</code></pre><p>Compute the mean squared error (MSE) (aka mean squared deviation - MSD) between two vectors ŷ and y. Note that while the deviation is averaged by the length of <code>y</code> is is not scaled to give it a relative meaning.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L327-L332">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.oneHotDecoder-Tuple{Any}" href="#BetaML.Utils.oneHotDecoder-Tuple{Any}"><code>BetaML.Utils.oneHotDecoder</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">oneHotDecoder(x)</code></pre><p>Given a matrix of one-hot encoded values (e.g. [0 1 0; 1 0 0]) returns a vector of the integer positions (e.g. [2,1]).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L135-L140">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.oneHotEncoder-Union{Tuple{Union{AbstractVector{T}, T}}, Tuple{T}} where T" href="#BetaML.Utils.oneHotEncoder-Union{Tuple{Union{AbstractVector{T}, T}}, Tuple{T}} where T"><code>BetaML.Utils.oneHotEncoder</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">oneHotEncoder(x;d,factors,count)</code></pre><p>Encode arrays (or arrays of arrays) of categorical data as matrices of one column per factor.</p><p>The case of arrays of arrays is for when at each record you have more than one categorical output. You can then decide to encode just the presence of the factors or their counting</p><p><strong>Parameters:</strong></p><ul><li><code>x</code>: The data to convert (array or array of arrays)</li><li><code>d</code>: The number of dimensions in the output matrix [def: <code>maximum(x)</code> for integers and <code>length(factors)</code> otherwise]</li><li><code>factors</code>: The factors from which to encode [def: <code>1:d</code> for integer x or <code>unique(x)</code> otherwise]</li><li><code>count</code>: Wether to count multiple instances on the same dimension/record (<code>true</code>) or indicate just presence. [def: <code>false</code>]</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; oneHotEncoder([&quot;a&quot;,&quot;c&quot;,&quot;c&quot;],factors=[&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;])
3×4 Matrix{Int64}:
 1  0  0  0
 0  0  1  0
 0  0  1  0
julia&gt; oneHotEncoder([2,4,4])
3×4 Matrix{Int64}:
 0  1  0  0
 0  0  0  1
 0  0  0  1
 julia&gt; oneHotEncoder([[2,2,1],[2,4,4]],count=true)
2×4 Matrix{Int64}:
 1  2  0  0
 0  1  0  2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L77-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.pca-Tuple{Any}" href="#BetaML.Utils.pca-Tuple{Any}"><code>BetaML.Utils.pca</code></a> — <span class="docstring-category">Method</span></header><section><div><p>pca(X;K,error)</p><p>Perform Principal Component Analysis returning the matrix reprojected among the dimensions of maximum variance.</p><p><strong>Parameters:</strong></p><ul><li><code>X</code> : The (N,D) data to reproject</li><li><code>K</code> : The number of dimensions to maintain (with K&lt;=D) [def: <code>nothing</code>]</li><li><code>error</code>: The maximum approximation error that we are willing to accept [def: <code>0.05</code>]</li></ul><p><strong>Return:</strong></p><ul><li>A named tuple with:<ul><li><code>X</code>: The reprojected (NxK) matrix with the column dimensions organized in descending order of of the proportion of explained variance</li><li><code>K</code>: The number of dimensions retieved</li><li><code>error</code>: The actual proportion of variance not explained in the reprojected dimensions</li><li><code>P</code>: The (D,K) matrix of the eigenvectors associated to the K-largest eigenvalues used to reproject the data matrix</li><li><code>explVarByDim</code>: An array of dimensions D with the share of the cumulative variance explained by dimensions (the last element being always 1.0)</li></ul></li></ul><p><strong>Notes:</strong></p><ul><li>If <code>K</code> is provided, the parameter <code>error</code> has no effect.</li><li>If one doesn&#39;t know <em>a priori</em> the error that she/he is willling to accept, nor the wished number of dimensions, he/she can run this pca function with <code>out = pca(X,K=size(X,2))</code> (i.e. with K=D), analise the proportions of explained cumulative variance by dimensions in <code>out.explVarByDim</code>, choose the number of dimensions K according to his/her needs and finally pick from the reprojected matrix only the number of dimensions needed, i.e. <code>out.X[:,1:K]</code>.</li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; X = [1 10 100; 1.1 15 120; 0.95 23 90; 0.99 17 120; 1.05 8 90; 1.1 12 95]
6×3 Matrix{Float64}:
 1.0   10.0  100.0
 1.1   15.0  120.0
 0.95  23.0   90.0
 0.99  17.0  120.0
 1.05   8.0   90.0
 1.1   12.0   95.0
julia&gt; X = pca(X,error=0.05).X
6×2 Matrix{Float64}:
 100.449    3.1783
 120.743    6.80764
  91.3551  16.8275
 120.878    8.80372
  90.3363   1.86179
  95.5965   5.51254</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L337-L379">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.plu-Tuple{Any}" href="#BetaML.Utils.plu-Tuple{Any}"><code>BetaML.Utils.plu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>plu(x;α=0.1,c=1) </p><p>Piecewise Linear Unit </p><p>https://arxiv.org/pdf/1809.09534.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L23-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.polynomialKernel-Tuple{Any, Any}" href="#BetaML.Utils.polynomialKernel-Tuple{Any, Any}"><code>BetaML.Utils.polynomialKernel</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Polynomial kernel parametrised with <code>c=0</code> and <code>d=2</code> (i.e. a quadratic kernel). For other <code>cᵢ</code> and <code>dᵢ</code> use <code>K = (x,y) -&gt; polynomialKernel(x,y,c=cᵢ,d=dᵢ)</code> as kernel function in the supporting algorithms</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L176-L179">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.pool1d" href="#BetaML.Utils.pool1d"><code>BetaML.Utils.pool1d</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pool1d(x,poolSize=2;f=mean)</code></pre><p>Apply funtion <code>f</code> to a rolling poolSize contiguous (in 1d) neurons.</p><p>Applicable to <code>VectorFunctionLayer</code>, e.g. <code>layer2  = VectorFunctionLayer(nₗ,f=(x-&gt;pool1d(x,4,f=mean))</code> <strong>Attention</strong>: to apply this funciton as activation function in a neural network you will need Julia version &gt;= 1.6, otherwise you may experience a segmentation fault (see <a href="https://github.com/FluxML/Zygote.jl/issues/943">this bug report</a>)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L29-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.radialKernel-Tuple{Any, Any}" href="#BetaML.Utils.radialKernel-Tuple{Any, Any}"><code>BetaML.Utils.radialKernel</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Radial Kernel (aka <em>RBF kernel</em>) parametrised with γ=1/2. For other gammas γᵢ use <code>K = (x,y) -&gt; radialKernel(x,y,γ=γᵢ)</code> as kernel function in the supporting algorithms</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L173-L175">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.relu-Tuple{Any}" href="#BetaML.Utils.relu-Tuple{Any}"><code>BetaML.Utils.relu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>relu(x) </p><p>Rectified Linear Unit </p><p>https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L10-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.scale" href="#BetaML.Utils.scale"><code>BetaML.Utils.scale</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">scale(x,scaleFactors;rev)</code></pre><p>Perform a linear scaling of x using scaling factors <code>scaleFactors</code>.</p><p><strong>Parameters</strong></p><ul><li><code>x</code>: The (n × d) dimension matrix to scale on each dimension d</li><li><code>scalingFactors</code>: A tuple of the constant and multiplicative scaling factor</li></ul><p>respectively [def: the scaling factors needed to scale x to mean 0 and variance 1]</p><ul><li><code>rev</code>: Whether to invert the scaling [def: <code>false</code>]</li></ul><p><strong>Return</strong></p><ul><li>The scaled matrix</li></ul><p><strong>Notes:</strong></p><ul><li>Also available <a href="@ref"><code>scale!(x,scaleFactors)</code></a> for in-place scaling</li><li>Retrieve the scale factors with the <a href="Utils.html#BetaML.Utils.getScaleFactors-Tuple{Any}"><code>getScaleFactors()</code></a> function</li><li>Note that missing values are skipped</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L295-L313">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.sigmoid-Tuple{Any}" href="#BetaML.Utils.sigmoid-Tuple{Any}"><code>BetaML.Utils.sigmoid</code></a> — <span class="docstring-category">Method</span></header><section><div><p>sigmoid(x)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L43">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.singleUnique-Union{Tuple{Union{AbstractArray{T, N} where N, T}}, Tuple{T}} where T" href="#BetaML.Utils.singleUnique-Union{Tuple{Union{AbstractArray{T, N} where N, T}}, Tuple{T}} where T"><code>BetaML.Utils.singleUnique</code></a> — <span class="docstring-category">Method</span></header><section><div><p>singleUnique(x) Return the unique values of x whether x is an array of arrays, an array or a scalar</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.softmax-Tuple{Any}" href="#BetaML.Utils.softmax-Tuple{Any}"><code>BetaML.Utils.softmax</code></a> — <span class="docstring-category">Method</span></header><section><div><p>softmax (x; β=1) </p><p>The input x is a vector. Return a PMF</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L47-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.softplus-Tuple{Any}" href="#BetaML.Utils.softplus-Tuple{Any}"><code>BetaML.Utils.softplus</code></a> — <span class="docstring-category">Method</span></header><section><div><p>softplus(x) </p><p>https://en.wikipedia.org/wiki/Rectifier<em>(neural</em>networks)#Softplus</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L69-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.squaredCost-Tuple{Any, Any}" href="#BetaML.Utils.squaredCost-Tuple{Any, Any}"><code>BetaML.Utils.squaredCost</code></a> — <span class="docstring-category">Method</span></header><section><div><p>squaredCost(ŷ,y)</p><p>Compute the squared costs between a vector of prediction and one of observations as (1/2)*norm(y - ŷ)^2.</p><p>Aside the 1/2 term, it correspond to the squared l-2 norm distance and when it is averaged on multiple datapoints corresponds to the Mean Squared Error (<a href="https://en.wikipedia.org/wiki/Mean_squared_error">MSE</a>). It is mostly used for regression problems.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Measures.jl#L317-L324">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.sterling-Tuple{BigInt, BigInt}" href="#BetaML.Utils.sterling-Tuple{BigInt, BigInt}"><code>BetaML.Utils.sterling</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Sterling number: number of partitions of a set of n elements in k sets </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Processing.jl#L647">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.variance-Tuple{Any}" href="#BetaML.Utils.variance-Tuple{Any}"><code>BetaML.Utils.variance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>variance(x) - population variance</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Transformers.jl#L160">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Random.shuffle-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:AbstractArray" href="#Random.shuffle-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:AbstractArray"><code>Random.shuffle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">shuffle(data;dims,rng)</code></pre><p>Shuffle a vector of n-dimensional arrays across dimension <code>dims</code> keeping the same order between the arrays</p><p><strong>Parameters</strong></p><ul><li><code>data</code>: The vector of arrays to shuffle</li><li><code>dims</code>: The dimension over to apply the shuffle [def: <code>1</code>]</li><li><code>rng</code>:  An <code>AbstractRNG</code> to apply for the shuffle</li></ul><p><strong>Notes</strong></p><ul><li>All the arrays must have the same size for the dimension to shuffle</li></ul><p><strong>Example</strong></p><p><code>julia&gt; a = [1 2 30; 10 20 30]; b = [100 200 300]; julia&gt; (aShuffled, bShuffled) = shuffle([a,b],dims=2) 2-element Vector{Matrix{Int64}}:  [1 30 2; 10 30 20]  [100 300 200]</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Stochasticity.jl#L34-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="BetaML.Utils.@codeLocation-Tuple{}" href="#BetaML.Utils.@codeLocation-Tuple{}"><code>BetaML.Utils.@codeLocation</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@codeLocation()</code></pre><p>Helper macro to print during runtime an info message concerning the code being executed position</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/a7b27a0642a7b2a5fcf49947fc5468432222181e/src/Utils/Logging_utils.jl#L6-L11">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="Imputation.html">« Imputation</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Thursday 18 August 2022 10:43">Thursday 18 August 2022</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
