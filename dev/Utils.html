<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Utils · BetaML.jl Documentation</title><meta name="title" content="Utils · BetaML.jl Documentation"/><meta property="og:title" content="Utils · BetaML.jl Documentation"/><meta property="twitter:title" content="Utils · BetaML.jl Documentation"/><meta name="description" content="Documentation for BetaML.jl Documentation."/><meta property="og:description" content="Documentation for BetaML.jl Documentation."/><meta property="twitter:description" content="Documentation for BetaML.jl Documentation."/><script async src="https://www.googletagmanager.com/gtag/js?id=G-JYKX8QY5JW"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-JYKX8QY5JW', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">BetaML.jl Documentation</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Index</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="tutorials/Betaml_tutorial_getting_started.html">Getting started</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Classification - cars</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Classification - cars/betaml_tutorial_classification_cars.html">A classification task when labels are known - determining the country of origin of cars given the cars characteristics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Regression - bike sharing</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Regression - bike sharing/betaml_tutorial_regression_sharingBikes.html">A regression task: the prediction of  bike  sharing demand</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Clustering - Iris</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Clustering - Iris/betaml_tutorial_cluster_iris.html">A clustering task: the prediction of  plant species from floreal measures (the iris dataset)</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-5" type="checkbox"/><label class="tocitem" for="menuitem-2-5"><span class="docs-label">Multi-branch neural network</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="tutorials/Multi-branch neural network/betaml_tutorial_multibranch_nn.html">A deep neural network with multi-branch architecture</a></li></ul></li></ul></li><li><span class="tocitem">API (Reference manual)</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">API V2 (current)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Api_v2_user.html">Introduction for user</a></li><li><input class="collapse-toggle" id="menuitem-3-1-2" type="checkbox"/><label class="tocitem" for="menuitem-3-1-2"><span class="docs-label">For developers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Api_v2_developer.html">API implementation</a></li><li><a class="tocitem" href="StyleGuide_templates.html">Style guide</a></li></ul></li><li><a class="tocitem" href="Api.html">The Api module</a></li></ul></li><li><a class="tocitem" href="Perceptron.html">Perceptron</a></li><li><a class="tocitem" href="Trees.html">Trees</a></li><li><a class="tocitem" href="Nn.html">Nn</a></li><li><a class="tocitem" href="Clustering.html">Clustering</a></li><li><a class="tocitem" href="GMM.html">GMM</a></li><li><a class="tocitem" href="Imputation.html">Imputation</a></li><li class="is-active"><a class="tocitem" href="Utils.html">Utils</a><ul class="internal"><li><a class="tocitem" href="#Module-Index"><span>Module Index</span></a></li><li><a class="tocitem" href="#Detailed-API"><span>Detailed API</span></a></li></ul></li><li><a class="tocitem" href="MLJ_interface.html">MLJ interface</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API (Reference manual)</a></li><li class="is-active"><a href="Utils.html">Utils</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="Utils.html">Utils</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sylvaticus/BetaML.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/sylvaticus/BetaML.jl/blob/master/docs/src/Utils.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="utils_module"><a class="docs-heading-anchor" href="#utils_module">The BetaML.Utils Module</a><a id="utils_module-1"></a><a class="docs-heading-anchor-permalink" href="#utils_module" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils" href="#BetaML.Utils"><code>BetaML.Utils</code></a> — <span class="docstring-category">Module</span></header><section><div><pre><code class="language-julia hljs">Utils module</code></pre><p>Provide shared utility functions and/or models for various machine learning algorithms.</p><p>For the complete list of functions provided see below. The main ones are:</p><p><strong>Helper functions for logging</strong></p><ul><li>Most BetaML functions accept a parameter <code>verbosity</code> (choose between  <code>NONE</code>, <code>LOW</code>, <code>STD</code>, <code>HIGH</code> or <code>FULL</code>)</li><li>Writing complex code and need to find where something is executed ? Use the macro <a href="Utils.html#BetaML.Utils.@codelocation-Tuple{}"><code>@codelocation</code></a></li></ul><p><strong>Stochasticity management</strong></p><ul><li>Utils provide [<code>FIXEDSEED</code>], [<code>FIXEDRNG</code>] and <a href="Utils.html#BetaML.Utils.generate_parallel_rngs-Tuple{Random.AbstractRNG, Integer}"><code>generate_parallel_rngs</code></a>. All stochastic functions and models accept a <code>rng</code> parameter. See the &quot;Getting started&quot; section in the tutorial for details.</li></ul><p><strong>Data processing</strong></p><ul><li>Various small and large utilities for helping processing the data, expecially before running a ML algorithm</li><li>Includes <a href="Utils.html#BetaML.Utils.getpermutations-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T"><code>getpermutations</code></a>, <a href="Utils.html#BetaML.Utils.OneHotEncoder"><code>OneHotEncoder</code></a>, <a href="Utils.html#BetaML.Utils.OrdinalEncoder"><code>OrdinalEncoder</code></a>, <a href="Utils.html#BetaML.Utils.partition-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{Float64}}} where T&lt;:AbstractArray"><code>partition</code></a>, <a href="Utils.html#BetaML.Utils.Scaler"><code>Scaler</code></a>, <a href="Utils.html#BetaML.Utils.PCAEncoder"><code>PCAEncoder</code></a>, <a href="Utils.html#BetaML.Utils.AutoEncoder"><code>AutoEncoder</code></a>, <a href="Utils.html#BetaML.Utils.cross_validation"><code>cross_validation</code></a>.</li><li>Auto-tuning of hyperparameters is implemented in the supported models by specifying <code>autotune=true</code> and optionally overriding the <code>tunemethod</code> parameters (e.g. for different hyperparameters ranges or different resources available for the tuning). Autotuning is then implemented in the (first) <code>fit!</code> call. Provided autotuning methods:  <a href="Utils.html#BetaML.Utils.SuccessiveHalvingSearch"><code>SuccessiveHalvingSearch</code></a> (default), <a href="Utils.html#BetaML.Utils.GridSearch"><code>GridSearch</code></a></li></ul><p><strong>Samplers</strong></p><ul><li>Utilities to sample from data (e.g. for neural network training or for cross-validation)</li><li>Include the &quot;generic&quot; type <a href="Utils.html#BetaML.Utils.SamplerWithData"><code>SamplerWithData</code></a>, together with the sampler implementation <a href="Utils.html#BetaML.Utils.KFold"><code>KFold</code></a> and the function <a href="Utils.html#BetaML.Utils.batch-Tuple{Integer, Integer}"><code>batch</code></a></li></ul><p><strong>Transformers</strong></p><ul><li>Funtions that &quot;transform&quot; a single input (that can be also a vector or a matrix)</li><li>Includes varios NN &quot;activation&quot; functions (<a href="Utils.html#BetaML.Utils.relu-Tuple{Any}"><code>relu</code></a>, <a href="Utils.html#BetaML.Utils.celu-Tuple{Any}"><code>celu</code></a>, <a href="Utils.html#BetaML.Utils.sigmoid-Tuple{Any}"><code>sigmoid</code></a>, <a href="Utils.html#BetaML.Utils.softmax-Tuple{Any}"><code>softmax</code></a>, <a href="Utils.html#BetaML.Utils.pool1d"><code>pool1d</code></a>) and their derivatives (<code>d[FunctionName]</code>), but also <a href="Utils.html#BetaML.Utils.gini-Tuple{Any}"><code>gini</code></a>, <a href="Utils.html#BetaML.Utils.entropy-Tuple{Any}"><code>entropy</code></a>, <a href="Utils.html#BetaML.Utils.variance-Tuple{Any}"><code>variance</code></a>, <a href="Utils.html#BetaML.Utils.bic-Tuple{Any, Any, Any}"><code>BIC</code></a>, <a href="Utils.html#BetaML.Utils.aic-Tuple{Any, Any}"><code>AIC</code></a></li></ul><p><strong>Measures</strong></p><ul><li>Several functions of a pair of parameters (often <code>y</code> and <code>ŷ</code>) to measure the goodness of <code>ŷ</code>, the distance between the two elements of the pair, ...</li><li>Includes &quot;classical&quot; distance functions (<a href="Utils.html#BetaML.Utils.l1_distance-Tuple{Any, Any}"><code>l1_distance</code></a>, <a href="Utils.html#BetaML.Utils.l2_distance-Tuple{Any, Any}"><code>l2_distance</code></a>, <a href="Utils.html#BetaML.Utils.l2squared_distance-Tuple{Any, Any}"><code>l2squared_distance</code></a> <a href="Utils.html#BetaML.Utils.cosine_distance-Tuple{Any, Any}"><code>cosine_distance</code></a>), &quot;cost&quot; functions for continuous variables (<a href="Utils.html#BetaML.Utils.squared_cost-Tuple{Any, Any}"><code>squared_cost</code></a>, <a href="Utils.html#BetaML.Utils.relative_mean_error-Tuple{Any, Any}"><code>relative_mean_error</code></a>) and comparision functions for multi-class variables (<a href="Utils.html#BetaML.Utils.crossentropy-Tuple{Any, Any}"><code>crossentropy</code></a>, <a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{Int64}, AbstractMatrix{T}}} where T&lt;:Number"><code>accuracy</code></a>, <a href="Utils.html#BetaML.Utils.ConfusionMatrix"><code>ConfusionMatrix</code></a>, <a href="Utils.html#BetaML.Utils.silhouette-Tuple{Any, Any}"><code>silhouette</code></a>)</li><li>Distances can be used to compute a pairwise distance matrix using the function <a href="Utils.html#BetaML.Utils.pairwise-Tuple{AbstractArray}"><code>pairwise</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Utils.jl#L3-L35">source</a></section></article><h2 id="Module-Index"><a class="docs-heading-anchor" href="#Module-Index">Module Index</a><a id="Module-Index-1"></a><a class="docs-heading-anchor-permalink" href="#Module-Index" title="Permalink"></a></h2><ul><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Int64, AbstractVector{T}}} where T&lt;:Number"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{T, AbstractDict{T, Float64}}} where T"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{Int64}, AbstractMatrix{T}}} where T&lt;:Number"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractArray{Dict{T, Float64}, 1}}} where T"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T"><code>BetaML.Utils.accuracy</code></a></li><li><a href="Utils.html#BetaML.Utils.aic-Tuple{Any, Any}"><code>BetaML.Utils.aic</code></a></li><li><a href="Utils.html#BetaML.Utils.autojacobian-Tuple{Any, Any}"><code>BetaML.Utils.autojacobian</code></a></li><li><a href="Utils.html#BetaML.Utils.autotune!-Tuple{Any, Any}"><code>BetaML.Utils.autotune!</code></a></li><li><a href="Utils.html#BetaML.Utils.batch-Tuple{Integer, Integer}"><code>BetaML.Utils.batch</code></a></li><li><a href="Utils.html#BetaML.Utils.bic-Tuple{Any, Any, Any}"><code>BetaML.Utils.bic</code></a></li><li><a href="Utils.html#BetaML.Utils.celu-Tuple{Any}"><code>BetaML.Utils.celu</code></a></li><li><a href="Utils.html#BetaML.Utils.class_counts-Tuple{Any}"><code>BetaML.Utils.class_counts</code></a></li><li><a href="Utils.html#BetaML.Utils.class_counts_with_labels-Tuple{Any}"><code>BetaML.Utils.class_counts_with_labels</code></a></li><li><a href="Utils.html#BetaML.Utils.cols_with_missing-Tuple{Any}"><code>BetaML.Utils.cols_with_missing</code></a></li><li><a href="Utils.html#BetaML.Utils.consistent_shuffle-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T"><code>BetaML.Utils.consistent_shuffle</code></a></li><li><a href="Utils.html#BetaML.Utils.cosine_distance-Tuple{Any, Any}"><code>BetaML.Utils.cosine_distance</code></a></li><li><a href="Utils.html#BetaML.Utils.cross_validation"><code>BetaML.Utils.cross_validation</code></a></li><li><a href="Utils.html#BetaML.Utils.crossentropy-Tuple{Any, Any}"><code>BetaML.Utils.crossentropy</code></a></li><li><a href="Utils.html#BetaML.Utils.dcelu-Tuple{Any}"><code>BetaML.Utils.dcelu</code></a></li><li><a href="Utils.html#BetaML.Utils.delu-Tuple{Any}"><code>BetaML.Utils.delu</code></a></li><li><a href="Utils.html#BetaML.Utils.dmaximum-Tuple{Any}"><code>BetaML.Utils.dmaximum</code></a></li><li><a href="Utils.html#BetaML.Utils.dmish-Tuple{Any}"><code>BetaML.Utils.dmish</code></a></li><li><a href="Utils.html#BetaML.Utils.dplu-Tuple{Any}"><code>BetaML.Utils.dplu</code></a></li><li><a href="Utils.html#BetaML.Utils.drelu-Tuple{Any}"><code>BetaML.Utils.drelu</code></a></li><li><a href="Utils.html#BetaML.Utils.dsigmoid-Tuple{Any}"><code>BetaML.Utils.dsigmoid</code></a></li><li><a href="Utils.html#BetaML.Utils.dsoftmax-Tuple{Any}"><code>BetaML.Utils.dsoftmax</code></a></li><li><a href="Utils.html#BetaML.Utils.dsoftplus-Tuple{Any}"><code>BetaML.Utils.dsoftplus</code></a></li><li><a href="Utils.html#BetaML.Utils.dtanh-Tuple{Any}"><code>BetaML.Utils.dtanh</code></a></li><li><a href="Utils.html#BetaML.Utils.elu-Tuple{Any}"><code>BetaML.Utils.elu</code></a></li><li><a href="Utils.html#BetaML.Utils.entropy-Tuple{Any}"><code>BetaML.Utils.entropy</code></a></li><li><a href="Utils.html#BetaML.Utils.generate_parallel_rngs-Tuple{Random.AbstractRNG, Integer}"><code>BetaML.Utils.generate_parallel_rngs</code></a></li><li><a href="Utils.html#BetaML.Utils.getpermutations-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T"><code>BetaML.Utils.getpermutations</code></a></li><li><a href="Utils.html#BetaML.Utils.gini-Tuple{Any}"><code>BetaML.Utils.gini</code></a></li><li><a href="Utils.html#BetaML.Utils.issortable-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T, N}"><code>BetaML.Utils.issortable</code></a></li><li><a href="Utils.html#BetaML.Utils.l1_distance-Tuple{Any, Any}"><code>BetaML.Utils.l1_distance</code></a></li><li><a href="Utils.html#BetaML.Utils.l2_distance-Tuple{Any, Any}"><code>BetaML.Utils.l2_distance</code></a></li><li><a href="Utils.html#BetaML.Utils.l2loss_by_cv-Tuple{Any, Any}"><code>BetaML.Utils.l2loss_by_cv</code></a></li><li><a href="Utils.html#BetaML.Utils.l2squared_distance-Tuple{Any, Any}"><code>BetaML.Utils.l2squared_distance</code></a></li><li><a href="Utils.html#BetaML.Utils.lse-Tuple{Any}"><code>BetaML.Utils.lse</code></a></li><li><a href="Utils.html#BetaML.Utils.makematrix-Tuple{AbstractVector{T} where T}"><code>BetaML.Utils.makematrix</code></a></li><li><a href="Utils.html#BetaML.Utils.mean_dicts-Tuple{Any}"><code>BetaML.Utils.mean_dicts</code></a></li><li><a href="Utils.html#BetaML.Utils.mish-Tuple{Any}"><code>BetaML.Utils.mish</code></a></li><li><a href="Utils.html#BetaML.Utils.mode-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Number"><code>BetaML.Utils.mode</code></a></li><li><a href="Utils.html#BetaML.Utils.mode-Union{Tuple{AbstractArray{Dict{T, Float64}, N} where N}, Tuple{T}} where T"><code>BetaML.Utils.mode</code></a></li><li><a href="Utils.html#BetaML.Utils.mode-Union{Tuple{Dict{T, Float64}}, Tuple{T}} where T"><code>BetaML.Utils.mode</code></a></li><li><a href="Utils.html#BetaML.Utils.mse-Tuple{Any, Any}"><code>BetaML.Utils.mse</code></a></li><li><a href="Utils.html#BetaML.Utils.pairwise-Tuple{AbstractArray}"><code>BetaML.Utils.pairwise</code></a></li><li><a href="Utils.html#BetaML.Utils.partition-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{Float64}}} where T&lt;:AbstractArray"><code>BetaML.Utils.partition</code></a></li><li><a href="Utils.html#BetaML.Utils.plu-Tuple{Any}"><code>BetaML.Utils.plu</code></a></li><li><a href="Utils.html#BetaML.Utils.polynomial_kernel-Tuple{Any, Any}"><code>BetaML.Utils.polynomial_kernel</code></a></li><li><a href="Utils.html#BetaML.Utils.pool1d"><code>BetaML.Utils.pool1d</code></a></li><li><a href="Utils.html#BetaML.Utils.radial_kernel-Tuple{Any, Any}"><code>BetaML.Utils.radial_kernel</code></a></li><li><a href="Utils.html#BetaML.Utils.relative_mean_error-Tuple{Any, Any}"><code>BetaML.Utils.relative_mean_error</code></a></li><li><a href="Utils.html#BetaML.Utils.relu-Tuple{Any}"><code>BetaML.Utils.relu</code></a></li><li><a href="Utils.html#BetaML.Utils.sigmoid-Tuple{Any}"><code>BetaML.Utils.sigmoid</code></a></li><li><a href="Utils.html#BetaML.Utils.silhouette-Tuple{Any, Any}"><code>BetaML.Utils.silhouette</code></a></li><li><a href="Utils.html#BetaML.Utils.softmax-Tuple{Any}"><code>BetaML.Utils.softmax</code></a></li><li><a href="Utils.html#BetaML.Utils.softplus-Tuple{Any}"><code>BetaML.Utils.softplus</code></a></li><li><a href="Utils.html#BetaML.Utils.squared_cost-Tuple{Any, Any}"><code>BetaML.Utils.squared_cost</code></a></li><li><a href="Utils.html#BetaML.Utils.sterling-Tuple{BigInt, BigInt}"><code>BetaML.Utils.sterling</code></a></li><li><a href="Utils.html#BetaML.Utils.variance-Tuple{Any}"><code>BetaML.Utils.variance</code></a></li><li><a href="Utils.html#BetaML.Utils.xavier_init"><code>BetaML.Utils.xavier_init</code></a></li><li><a href="Utils.html#BetaML.Utils.AutoE_hp"><code>BetaML.Utils.AutoE_hp</code></a></li><li><a href="Utils.html#BetaML.Utils.AutoEncoder"><code>BetaML.Utils.AutoEncoder</code></a></li><li><a href="Utils.html#BetaML.Utils.ConfusionMatrix"><code>BetaML.Utils.ConfusionMatrix</code></a></li><li><a href="Utils.html#BetaML.Utils.ConfusionMatrix_hp"><code>BetaML.Utils.ConfusionMatrix_hp</code></a></li><li><a href="Utils.html#BetaML.Utils.GridSearch"><code>BetaML.Utils.GridSearch</code></a></li><li><a href="Utils.html#BetaML.Utils.KFold"><code>BetaML.Utils.KFold</code></a></li><li><a href="Utils.html#BetaML.Utils.MinMaxScaler"><code>BetaML.Utils.MinMaxScaler</code></a></li><li><a href="Utils.html#BetaML.Utils.OneHotE_hp"><code>BetaML.Utils.OneHotE_hp</code></a></li><li><a href="Utils.html#BetaML.Utils.OneHotEncoder"><code>BetaML.Utils.OneHotEncoder</code></a></li><li><a href="Utils.html#BetaML.Utils.OrdinalEncoder"><code>BetaML.Utils.OrdinalEncoder</code></a></li><li><a href="Utils.html#BetaML.Utils.PCAE_hp"><code>BetaML.Utils.PCAE_hp</code></a></li><li><a href="Utils.html#BetaML.Utils.PCAEncoder"><code>BetaML.Utils.PCAEncoder</code></a></li><li><a href="Utils.html#BetaML.Utils.SamplerWithData"><code>BetaML.Utils.SamplerWithData</code></a></li><li><a href="Utils.html#BetaML.Utils.Scaler"><code>BetaML.Utils.Scaler</code></a></li><li><a href="Utils.html#BetaML.Utils.Scaler_hp"><code>BetaML.Utils.Scaler_hp</code></a></li><li><a href="Utils.html#BetaML.Utils.StandardScaler"><code>BetaML.Utils.StandardScaler</code></a></li><li><a href="Utils.html#BetaML.Utils.SuccessiveHalvingSearch"><code>BetaML.Utils.SuccessiveHalvingSearch</code></a></li><li><a href="Utils.html#BetaML.Utils.@codelocation-Tuple{}"><code>BetaML.Utils.@codelocation</code></a></li><li><a href="Utils.html#BetaML.Utils.@threadsif-Tuple{Any, Any}"><code>BetaML.Utils.@threadsif</code></a></li></ul><h2 id="Detailed-API"><a class="docs-heading-anchor" href="#Detailed-API">Detailed API</a><a id="Detailed-API-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.AutoE_hp" href="#BetaML.Utils.AutoE_hp"><code>BetaML.Utils.AutoE_hp</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct AutoE_hp &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for the AutoEncoder transformer</p><p><strong>Parameters</strong></p><ul><li><p><code>e_layers</code>: The layers (vector of <code>AbstractLayer</code>s) responsable of the encoding of the data [def: <code>nothing</code>, i.e. two dense layers with the inner one of <code>layers_size</code>]</p></li><li><p><code>d_layers</code>: The layers (vector of <code>AbstractLayer</code>s) responsable of the decoding of the data [def: <code>nothing</code>, i.e. two dense layers with the inner one of <code>layers_size</code>]</p></li><li><p><code>encoded_size</code>: The desired size of the encoded data, that is the number of dimensions in output or the size of the latent space. This is the number of neurons of the layer sitting between the econding and decoding layers. If the value is a float it is considered a percentual (to be rounded) of the dimensionality of the data [def: <code>0.33</code>]</p></li><li><p><code>layers_size</code>: Inner layers dimension (i.e. number of neurons). If the value is a float it is considered a percentual (to be rounded) of the dimensionality of the data [def: <code>nothing</code> that applies a specific heuristic]. Consider that the underlying neural network is trying to predict multiple values at the same times. Normally this requires many more neurons than a scalar prediction. If <code>e_layers</code> or <code>d_layers</code> are specified, this parameter is ignored for the respective part.</p></li><li><p><code>loss</code>: Loss (cost) function [def: <code>squared_cost</code>] It must always assume y and ŷ as (n x d) matrices, eventually using <code>dropdims</code> inside.</p></li></ul><ul><li><p><code>dloss</code>: Derivative of the loss function [def: <code>dsquared_cost</code> if <code>loss==squared_cost</code>, <code>nothing</code> otherwise, i.e. use the derivative of the squared cost or autodiff]</p></li><li><p><code>epochs</code>: Number of epochs, i.e. passages trough the whole training sample [def: <code>200</code>]</p></li><li><p><code>batch_size</code>: Size of each individual batch [def: <code>8</code>]</p></li><li><p><code>opt_alg</code>: The optimisation algorithm to update the gradient at each batch [def: <code>ADAM()</code>]</p></li><li><p><code>shuffle</code>: Whether to randomly shuffle the data at each iteration (epoch) [def: <code>true</code>]</p></li><li><p><code>tunemethod</code>: The method - and its parameters - to employ for hyperparameters autotuning. See <a href="Utils.html#BetaML.Utils.SuccessiveHalvingSearch"><code>SuccessiveHalvingSearch</code></a> for the default method. To implement automatic hyperparameter tuning during the (first) <code>fit!</code> call simply set <code>autotune=true</code> and eventually change the default <code>tunemethod</code> options (including the parameter ranges, the resources to employ and the loss function to adopt).</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Utils_extra.jl#L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.AutoEncoder" href="#BetaML.Utils.AutoEncoder"><code>BetaML.Utils.AutoEncoder</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct AutoEncoder &lt;: BetaMLUnsupervisedModel</code></pre><p>Perform a (possibly-non linear) transformation (&quot;encoding&quot;) of the data into a different space, e.g. for dimensionality reduction using neural network trained to replicate the input data.</p><p>A neural network is trained to first transform the data (ofter &quot;compress&quot;) to a subspace (the output of an inner layer) and then retransform (subsequent layers) to the original data.</p><p><code>predict(mod::AutoEncoder,x)</code> returns the encoded data, <code>inverse_predict(mod::AutoEncoder,xtransformed)</code> performs the decoding.</p><p>For the parameters see <a href="Utils.html#BetaML.Utils.AutoE_hp"><code>AutoE_hp</code></a> and <a href="Api.html#BetaML.Api.BML_options"><code>BML_options</code></a> </p><p><strong>Notes:</strong></p><ul><li>AutoEncoder doesn&#39;t automatically scale the data. It is suggested to apply the <a href="Utils.html#BetaML.Utils.Scaler"><code>Scaler</code></a> model before running it. </li><li>Missing data are not supported. Impute them first, see the <a href="Imputation.html#BetaML.Imputation"><code>Imputation</code></a> module.</li><li>Decoding layers can be optinally choosen (parameter <code>d_layers</code>) in order to suit the kind of data, e.g. a <code>relu</code> activation function for nonegative data</li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; x = [0.12 0.31 0.29 3.21 0.21;
            0.22 0.61 0.58 6.43 0.42;
            0.51 1.47 1.46 16.12 0.99;
            0.35 0.93 0.91 10.04 0.71;
            0.44 1.21 1.18 13.54 0.85];

julia&gt; m    = AutoEncoder(encoded_size=1,epochs=400)
A AutoEncoder BetaMLModel (unfitted)

julia&gt; x_reduced = fit!(m,x)
***
*** Training  for 400 epochs with algorithm ADAM.
Training..       avg loss on epoch 1 (1):        60.27802763757111
Training..       avg loss on epoch 200 (200):    0.08970099870421573
Training..       avg loss on epoch 400 (400):    0.013138484118673664
Training of 400 epoch completed. Final epoch error: 0.013138484118673664.
5×1 Matrix{Float64}:
  -3.5483740608901186
  -6.90396890458868
 -17.06296512222304
 -10.688936344498398
 -14.35734756603212

julia&gt; x̂ = inverse_predict(m,x_reduced)
5×5 Matrix{Float64}:
 0.0982406  0.110294  0.264047   3.35501  0.327228
 0.205628   0.470884  0.558655   6.51042  0.487416
 0.529785   1.56431   1.45762   16.067    0.971123
 0.3264     0.878264  0.893584  10.0709   0.667632
 0.443453   1.2731    1.2182    13.5218   0.842298

julia&gt; info(m)[&quot;rme&quot;]
0.020858783340281222

julia&gt; hcat(x,x̂)
5×10 Matrix{Float64}:
 0.12  0.31  0.29   3.21  0.21  0.0982406  0.110294  0.264047   3.35501  0.327228
 0.22  0.61  0.58   6.43  0.42  0.205628   0.470884  0.558655   6.51042  0.487416
 0.51  1.47  1.46  16.12  0.99  0.529785   1.56431   1.45762   16.067    0.971123
 0.35  0.93  0.91  10.04  0.71  0.3264     0.878264  0.893584  10.0709   0.667632
 0.44  1.21  1.18  13.54  0.85  0.443453   1.2731    1.2182    13.5218   0.842298</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Utils_extra.jl#L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.ConfusionMatrix" href="#BetaML.Utils.ConfusionMatrix"><code>BetaML.Utils.ConfusionMatrix</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct ConfusionMatrix &lt;: BetaMLUnsupervisedModel</code></pre><p>Compute a confusion matrix detailing the mismatch between observations and predictions of a categorical variable</p><p>For the parameters see <a href="Utils.html#BetaML.Utils.ConfusionMatrix_hp"><code>ConfusionMatrix_hp</code></a> and <a href="Api.html#BetaML.Api.BML_options"><code>BML_options</code></a>.</p><p>The &quot;predicted&quot; values are either the scores or the normalised scores (depending on the parameter <code>normalise_scores</code> [def: <code>true</code>]).</p><p><strong>Notes:</strong></p><ul><li><p>The Confusion matrix report can be printed (i.e. <code>print(cm_model)</code>. If you plan to print the Confusion Matrix report, be sure that the type of the data in <code>y</code> and <code>ŷ</code> can be converted to <code>String</code>.</p></li><li><p>Information in a structured way is available trought the <code>info(cm)</code> function that returns the following dictionary:</p><ul><li><code>accuracy</code>:           Oveall accuracy rate</li><li><code>misclassification</code>:  Overall misclassification rate</li><li><code>actual_count</code>:       Array of counts per lebel in the actual data</li><li><code>predicted_count</code>:    Array of counts per label in the predicted data</li><li><code>scores</code>:             Matrix actual (rows) vs predicted (columns)</li><li><code>normalised_scores</code>:  Normalised scores</li><li><code>tp</code>:                 True positive (by class)</li><li><code>tn</code>:                 True negative (by class)</li><li><code>fp</code>:                 False positive (by class)</li><li><code>fn</code>:                 False negative (by class)</li><li><code>precision</code>:          True class i over predicted class i (by class)</li><li><code>recall</code>:             Predicted class i over true class i (by class)</li><li><code>specificity</code>:        Predicted not class i over true not class i (by class)</li><li><code>f1score</code>:            Harmonic mean of precision and recall</li><li><code>mean_precision</code>:     Mean by class, respectively unweighted and weighted by actual_count</li><li><code>mean_recall</code>:        Mean by class, respectively unweighted and weighted by actual_count</li><li><code>mean_specificity</code>:   Mean by class, respectively unweighted and weighted by actual_count</li><li><code>mean_f1score</code>:       Mean by class, respectively unweighted and weighted by actual_count</li><li><code>categories</code>:         The categories considered</li><li><code>fitted_records</code>:     Number of records considered</li><li><code>n_categories</code>:       Number of categories considered</li></ul></li></ul><p><strong>Example:</strong></p><p>The confusion matrix can also be plotted, e.g.:</p><pre><code class="language-julia hljs">julia&gt; using Plots, BetaML

julia&gt; y  = [&quot;apple&quot;,&quot;mandarin&quot;,&quot;clementine&quot;,&quot;clementine&quot;,&quot;mandarin&quot;,&quot;apple&quot;,&quot;clementine&quot;,&quot;clementine&quot;,&quot;apple&quot;,&quot;mandarin&quot;,&quot;clementine&quot;];

julia&gt; ŷ  = [&quot;apple&quot;,&quot;mandarin&quot;,&quot;clementine&quot;,&quot;mandarin&quot;,&quot;mandarin&quot;,&quot;apple&quot;,&quot;clementine&quot;,&quot;clementine&quot;,missing,&quot;clementine&quot;,&quot;clementine&quot;];

julia&gt; cm = ConfusionMatrix(handle_missing=&quot;drop&quot;)
A ConfusionMatrix BetaMLModel (unfitted)

julia&gt; normalised_scores = fit!(cm,y,ŷ)
3×3 Matrix{Float64}:
 1.0  0.0       0.0
 0.0  0.666667  0.333333
 0.0  0.2       0.8

julia&gt; println(cm)
A ConfusionMatrix BetaMLModel (fitted)

-----------------------------------------------------------------

*** CONFUSION MATRIX ***

Scores actual (rows) vs predicted (columns):

4×4 Matrix{Any}:
 &quot;Labels&quot;       &quot;apple&quot;   &quot;mandarin&quot;   &quot;clementine&quot;
 &quot;apple&quot;       2         0            0
 &quot;mandarin&quot;    0         2            1
 &quot;clementine&quot;  0         1            4
Normalised scores actual (rows) vs predicted (columns):

4×4 Matrix{Any}:
 &quot;Labels&quot;       &quot;apple&quot;   &quot;mandarin&quot;   &quot;clementine&quot;
 &quot;apple&quot;       1.0       0.0          0.0
 &quot;mandarin&quot;    0.0       0.666667     0.333333
 &quot;clementine&quot;  0.0       0.2          0.8

 *** CONFUSION REPORT ***

- Accuracy:               0.8
- Misclassification rate: 0.19999999999999996
- Number of classes:      3

  N Class      precision   recall  specificity  f1score  actual_count  predicted_count
                             TPR       TNR                 support                  

  1 apple          1.000    1.000        1.000    1.000            2               2
  2 mandarin       0.667    0.667        0.857    0.667            3               3
  3 clementine     0.800    0.800        0.800    0.800            5               5

- Simple   avg.    0.822    0.822        0.886    0.822
- Weigthed avg.    0.800    0.800        0.857    0.800

-----------------------------------------------------------------
Output of `info(cm)`:
- mean_precision:       (0.8222222222222223, 0.8)
- fitted_records:       10
- specificity:  [1.0, 0.8571428571428571, 0.8]
- precision:    [1.0, 0.6666666666666666, 0.8]
- misclassification:    0.19999999999999996
- mean_recall:  (0.8222222222222223, 0.8)
- n_categories: 3
- normalised_scores:    [1.0 0.0 0.0; 0.0 0.6666666666666666 0.3333333333333333; 0.0 0.2 0.8]
- tn:   [8, 6, 4]
- mean_f1score: (0.8222222222222223, 0.8)
- actual_count: [2, 3, 5]
- accuracy:     0.8
- recall:       [1.0, 0.6666666666666666, 0.8]
- f1score:      [1.0, 0.6666666666666666, 0.8]
- mean_specificity:     (0.8857142857142858, 0.8571428571428571)
- predicted_count:      [2, 3, 5]
- scores:       [2 0 0; 0 2 1; 0 1 4]
- tp:   [2, 2, 4]
- fn:   [0, 1, 1]
- categories:   [&quot;apple&quot;, &quot;mandarin&quot;, &quot;clementine&quot;]
- fp:   [0, 1, 1]

julia&gt; res = info(cm);

julia&gt; heatmap(string.(res[&quot;categories&quot;]),string.(res[&quot;categories&quot;]),res[&quot;normalised_scores&quot;],seriescolor=cgrad([:white,:blue]),xlabel=&quot;Predicted&quot;,ylabel=&quot;Actual&quot;, title=&quot;Confusion Matrix (normalised scores)&quot;)</code></pre><p><img src="assets/cmClementines.png" alt="CM plot"/> </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L328">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.ConfusionMatrix_hp" href="#BetaML.Utils.ConfusionMatrix_hp"><code>BetaML.Utils.ConfusionMatrix_hp</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct ConfusionMatrix_hp &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for <a href="Utils.html#BetaML.Utils.ConfusionMatrix"><code>ConfusionMatrix</code></a></p><p><strong>Parameters:</strong></p><ul><li><p><code>categories</code>: The categories (aka &quot;levels&quot;) to represent. [def: <code>nothing</code>, i.e. unique ground true values].</p></li><li><p><code>handle_unknown</code>: How to handle categories not seen in the ground true values or not present in the provided <code>categories</code> array? &quot;error&quot; (default) rises an error, &quot;infrequent&quot; adds a specific category for these values.</p></li><li><p><code>handle_missing</code>: How to handle missing values in either ground true or predicted values ? &quot;error&quot; [default] will rise an error, &quot;drop&quot; will drop the record</p></li><li><p><code>other_categories_name</code>: Which value to assign to the &quot;other&quot; category (i.e. categories not seen in the gound truth or not present in the provided <code>categories</code> array? [def: <code>nothing</code>, i.e. typemax(Int64) for integer vectors and &quot;other&quot; for other types]. This setting is active only if <code>handle_unknown=&quot;infrequent&quot;</code> and in that case it MUST be specified if the vector to one-hot encode is neither integer or strings</p></li><li><p><code>categories_names</code>: A dictionary to map categories to some custom names. Useful for example if categories are integers, or you want to use shorter names [def: <code>Dict()</code>, i.e. not used]. This option isn&#39;t currently compatible with missing values or when some record has a value not in this provided dictionary.</p></li><li><p><code>normalise_scores</code>: Wether <code>predict</code> should return the normalised scores. Note that both unnormalised and normalised scores remain available using <code>info</code>. [def: <code>true</code>]</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L298">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.GridSearch" href="#BetaML.Utils.GridSearch"><code>BetaML.Utils.GridSearch</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct GridSearch &lt;: AutoTuneMethod</code></pre><p>Simple grid method for hyper-parameters validation of supervised models.</p><p>All parameters are tested using cross-validation and then the &quot;best&quot; combination is used. </p><p><strong>Notes:</strong></p><ul><li>the default loss is suitable for 1-dimensional output supervised models</li></ul><p><strong>Parameters:</strong></p><ul><li><p><code>loss::Function</code>: Loss function to use. [def: <a href="Utils.html#BetaML.Utils.l2loss_by_cv-Tuple{Any, Any}"><code>l2loss_by_cv</code></a><code>]. Any function that takes a model, data (a vector of arrays, even if we work only with X) and (using the</code>rng` keyword) a RNG and return a scalar loss.</p></li><li><p><code>res_share::Float64</code>: Share of the (data) resources to use for the autotuning [def: 0.1]. With <code>res_share=1</code> all the dataset is used for autotuning, it can be very time consuming!</p></li><li><p><code>hpranges::Dict{String, Any}</code>: Dictionary of parameter names (String) and associated vector of values to test. Note that you can easily sample these values from a distribution with rand(distr<em>object,n</em>values). The number of points you provide for a given parameter can be interpreted as proportional to the prior you have on the importance of that parameter for the algorithm quality.</p></li><li><p><code>multithreads::Bool</code>: Use multithreads in the search for the best hyperparameters [def: <code>false</code>]</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1106">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.KFold" href="#BetaML.Utils.KFold"><code>BetaML.Utils.KFold</code></a> — <span class="docstring-category">Type</span></header><section><div><p>KFold(nsplits=5,nrepeats=1,shuffle=true,rng=Random.GLOBAL_RNG)</p><p>Iterator for k-fold cross_validation strategy.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Samplers.jl#L35-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.MinMaxScaler" href="#BetaML.Utils.MinMaxScaler"><code>BetaML.Utils.MinMaxScaler</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct MinMaxScaler &lt;: BetaML.Utils.AbstractScaler</code></pre><p>Scale the data to a given (def: unit) hypercube</p><p><strong>Parameters:</strong></p><ul><li><p><code>inputRange</code>: The range of the input. [def: (minimum,maximum)]. Both ranges are functions of the data. You can consider other relative of absolute ranges using e.g. <code>inputRange=(x-&gt;minimum(x)*0.8,x-&gt;100)</code></p></li><li><p><code>outputRange</code>: The range of the scaled output [def: (0,1)]</p></li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; x       = [[4000,1000,2000,3000] [&quot;a&quot;, &quot;categorical&quot;, &quot;variable&quot;, &quot;not to scale&quot;] [4,1,2,3] [0.4, 0.1, 0.2, 0.3]]
4×4 Matrix{Any}:
 4000  &quot;a&quot;             4  0.4
 1000  &quot;categorical&quot;   1  0.1
 2000  &quot;variable&quot;      2  0.2
 3000  &quot;not to scale&quot;  3  0.3

julia&gt; mod     = Scaler(MinMaxScaler(outputRange=(0,10)), skip=[2])
A Scaler BetaMLModel (unfitted)

julia&gt; xscaled = fit!(mod,x)
4×4 Matrix{Any}:
 10.0      &quot;a&quot;             10.0      10.0
  0.0      &quot;categorical&quot;    0.0       0.0
  3.33333  &quot;variable&quot;       3.33333   3.33333
  6.66667  &quot;not to scale&quot;   6.66667   6.66667

julia&gt; xback   = inverse_predict(mod, xscaled)
4×4 Matrix{Any}:
 4000.0  &quot;a&quot;             4.0  0.4
 1000.0  &quot;categorical&quot;   1.0  0.1
 2000.0  &quot;variable&quot;      2.0  0.2
 3000.0  &quot;not to scale&quot;  3.0  0.3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L521">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.OneHotE_hp" href="#BetaML.Utils.OneHotE_hp"><code>BetaML.Utils.OneHotE_hp</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct OneHotE_hp &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for both <a href="Utils.html#BetaML.Utils.OneHotEncoder"><code>OneHotEncoder</code></a> and <a href="Utils.html#BetaML.Utils.OrdinalEncoder"><code>OrdinalEncoder</code></a></p><p><strong>Parameters:</strong></p><ul><li><p><code>categories</code>: The categories to represent as columns. [def: <code>nothing</code>, i.e. unique training values or range for integers]. Do not include <code>missing</code> in this list.</p></li><li><p><code>handle_unknown</code>: How to handle categories not seen in training or not present in the provided <code>categories</code> array? &quot;error&quot; (default) rises an error, &quot;missing&quot; labels the whole output with missing values, &quot;infrequent&quot; adds a specific column for these categories in one-hot encoding or a single new category for ordinal one.</p></li><li><p><code>other_categories_name</code>: Which value during inverse transformation to assign to the &quot;other&quot; category (i.e. categories not seen on training or not present in the provided <code>categories</code> array? [def: <code>nothing</code>, i.e. typemax(Int64) for integer vectors and &quot;other&quot; for other types]. This setting is active only if <code>handle_unknown=&quot;infrequent&quot;</code> and in that case it MUST be specified if the vector to one-hot encode is neither integer or strings</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L79">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.OneHotEncoder" href="#BetaML.Utils.OneHotEncoder"><code>BetaML.Utils.OneHotEncoder</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct OneHotEncoder &lt;: BetaMLUnsupervisedModel</code></pre><p>Encode a vector of categorical values as one-hot columns.</p><p>The algorithm distinguishes between <em>missing</em> values, for which it returns a one-hot encoded row of missing values, and <em>other</em> categories not in the provided list or not seen during training that are handled according to the <code>handle_unknown</code> parameter. </p><p>For the parameters see <a href="Utils.html#BetaML.Utils.OneHotE_hp"><code>OneHotE_hp</code></a> and <a href="Api.html#BetaML.Api.BML_options"><code>BML_options</code></a>.  This model supports <code>inverse_predict</code>.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; x       = [&quot;a&quot;,&quot;d&quot;,&quot;e&quot;,&quot;c&quot;,&quot;d&quot;];

julia&gt; mod     = OneHotEncoder(handle_unknown=&quot;infrequent&quot;,other_categories_name=&quot;zz&quot;)
A OneHotEncoder BetaMLModel (unfitted)

julia&gt; x_oh    = fit!(mod,x)  # last col is for the &quot;infrequent&quot; category
5×5 Matrix{Bool}:
 1  0  0  0  0
 0  1  0  0  0
 0  0  1  0  0
 0  0  0  1  0
 0  1  0  0  0

julia&gt; x2      = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;];

julia&gt; x2_oh   = predict(mod,x2)
3×5 Matrix{Bool}:
 1  0  0  0  0
 0  0  0  0  1
 0  0  0  1  0

julia&gt; x2_back = inverse_predict(mod,x2_oh)
3-element Vector{String}:
 &quot;a&quot;
 &quot;zz&quot;
 &quot;c&quot;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L102">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.OrdinalEncoder" href="#BetaML.Utils.OrdinalEncoder"><code>BetaML.Utils.OrdinalEncoder</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct OrdinalEncoder &lt;: BetaMLUnsupervisedModel</code></pre><p>Encode a vector of categorical values as integers.</p><p>The algorithm distinguishes between <em>missing</em> values, for which it propagate the missing, and <em>other</em> categories not in the provided list or not seen during training that are handled according to the <code>handle_unknown</code> parameter. </p><p>For the parameters see <a href="Utils.html#BetaML.Utils.OneHotE_hp"><code>OneHotE_hp</code></a> and <a href="Api.html#BetaML.Api.BML_options"><code>BML_options</code></a>. This model supports <code>inverse_predict</code>.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; x       = [&quot;a&quot;,&quot;d&quot;,&quot;e&quot;,&quot;c&quot;,&quot;d&quot;];

julia&gt; mod     = OrdinalEncoder(handle_unknown=&quot;infrequent&quot;,other_categories_name=&quot;zz&quot;)
A OrdinalEncoder BetaMLModel (unfitted)

julia&gt; x_int   = fit!(mod,x)
5-element Vector{Int64}:
 1
 2
 3
 4
 2

julia&gt; x2      = [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;g&quot;];

julia&gt; x2_int  = predict(mod,x2) # 5 is for the &quot;infrequent&quot; category
4-element Vector{Int64}:
 1
 5
 4
 5

julia&gt; x2_back = inverse_predict(mod,x2_oh)
4-element Vector{String}:
 &quot;a&quot;
 &quot;zz&quot;
 &quot;c&quot;
 &quot;zz&quot;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L153">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.PCAE_hp" href="#BetaML.Utils.PCAE_hp"><code>BetaML.Utils.PCAE_hp</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct PCAE_hp &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for the PCAEncoder transformer</p><p><strong>Parameters</strong></p><ul><li><p><code>encoded_size</code>: The size, that is the number of dimensions, to maintain (with <code>encoded_size &lt;= size(X,2)</code> ) [def: <code>nothing</code>, i.e. the number of output dimensions is determined from the parameter <code>max_unexplained_var</code>]</p></li><li><p><code>max_unexplained_var</code>: The maximum proportion of variance that we are willing to accept when reducing the number of dimensions in our data [def: 0.05]. It doesn&#39;t have any effect when the output number of dimensions is explicitly chosen with the parameter <code>encoded_size</code></p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L879">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.PCAEncoder" href="#BetaML.Utils.PCAEncoder"><code>BetaML.Utils.PCAEncoder</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct PCAEncoder &lt;: BetaMLUnsupervisedModel</code></pre><p>Perform a Principal Component Analysis, a dimensionality reduction tecnique employing a linear trasformation of the original matrix by the eigenvectors of the covariance matrix.</p><p>PCAEncoder returns the matrix reprojected among the dimensions of maximum variance.</p><p>For the parameters see <a href="Utils.html#BetaML.Utils.PCAE_hp"><code>PCAE_hp</code></a> and <a href="Api.html#BetaML.Api.BML_options"><code>BML_options</code></a> </p><p><strong>Notes:</strong></p><ul><li>PCAEncoder doesn&#39;t automatically scale the data. It is suggested to apply the <a href="Utils.html#BetaML.Utils.Scaler"><code>Scaler</code></a> model before running it. </li><li>Missing data are not supported. Impute them first, see the <a href="Imputation.html#BetaML.Imputation"><code>Imputation</code></a> module.</li><li>If one doesn&#39;t know <em>a priori</em> the maximum unexplained variance that he is willling to accept, nor the wished number of dimensions, he can run the model with all the dimensions in output (i.e. with <code>encoded_size=size(X,2)</code>), analise the proportions of explained cumulative variance by dimensions in <code>info(mod,&quot;&quot;explained_var_by_dim&quot;)</code>, choose the number of dimensions K according to his needs and finally pick from the reprojected matrix only the number of dimensions required, i.e. <code>out.X[:,1:K]</code>.</li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; xtrain        = [1 10 100; 1.1 15 120; 0.95 23 90; 0.99 17 120; 1.05 8 90; 1.1 12 95];

julia&gt; mod           = PCAEncoder(max_unexplained_var=0.05)
A PCAEncoder BetaMLModel (unfitted)

julia&gt; xtrain_reproj = fit!(mod,xtrain)
6×2 Matrix{Float64}:
 100.449    3.1783
 120.743    6.80764
  91.3551  16.8275
 120.878    8.80372
  90.3363   1.86179
  95.5965   5.51254

julia&gt; info(mod)
Dict{String, Any} with 5 entries:
  &quot;explained_var_by_dim&quot; =&gt; [0.873992, 0.999989, 1.0]
  &quot;fitted_records&quot;       =&gt; 6
  &quot;prop_explained_var&quot;   =&gt; 0.999989
  &quot;retained_dims&quot;        =&gt; 2
  &quot;xndims&quot;               =&gt; 3

julia&gt; xtest         = [2 20 200];

julia&gt; xtest_reproj  = predict(mod,xtest)
1×2 Matrix{Float64}:
 200.898  6.3566</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L900">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.SamplerWithData" href="#BetaML.Utils.SamplerWithData"><code>BetaML.Utils.SamplerWithData</code></a> — <span class="docstring-category">Type</span></header><section><div><p>SamplerWithData{Tsampler}</p><p>Associate an instance of an AbstractDataSampler with the actual data to sample.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Samplers.jl#L6-L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.Scaler" href="#BetaML.Utils.Scaler"><code>BetaML.Utils.Scaler</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct Scaler &lt;: BetaMLUnsupervisedModel</code></pre><p>Scale the data according to the specific chosen method (def: <code>StandardScaler</code>) </p><p>For the parameters see <a href="Utils.html#BetaML.Utils.Scaler_hp"><code>Scaler_hp</code></a> and <a href="Api.html#BetaML.Api.BML_options"><code>BML_options</code></a> </p><p><strong>Examples:</strong></p><ul><li>Standard scaler (default)...</li></ul><pre><code class="language-julia hljs">julia&gt; using BetaML, Statistics

julia&gt; x         = [[4000,1000,2000,3000] [400,100,200,300] [4,1,2,3] [0.4, 0.1, 0.2, 0.3]]
4×4 Matrix{Float64}:
 4000.0  400.0  4.0  0.4
 1000.0  100.0  1.0  0.1
 2000.0  200.0  2.0  0.2
 3000.0  300.0  3.0  0.3

julia&gt; mod       = Scaler() # equiv to `Scaler(StandardScaler(scale=true, center=true))`
A Scaler BetaMLModel (unfitted)

julia&gt; xscaled   = fit!(mod,x)
4×4 Matrix{Float64}:
  1.34164    1.34164    1.34164    1.34164
 -1.34164   -1.34164   -1.34164   -1.34164
 -0.447214  -0.447214  -0.447214  -0.447214
  0.447214   0.447214   0.447214   0.447214

julia&gt; col_means = mean(xscaled, dims=1)
1×4 Matrix{Float64}:
 0.0  0.0  0.0  5.55112e-17

julia&gt; col_var   = var(xscaled, dims=1, corrected=false)
1×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0

julia&gt; xback     = inverse_predict(mod, xscaled)
4×4 Matrix{Float64}:
 4000.0  400.0  4.0  0.4
 1000.0  100.0  1.0  0.1
 2000.0  200.0  2.0  0.2
 3000.0  300.0  3.0  0.3</code></pre><ul><li>Min-max scaler...</li></ul><pre><code class="language-julia hljs">julia&gt; using BetaML

julia&gt; x       = [[4000,1000,2000,3000] [&quot;a&quot;, &quot;categorical&quot;, &quot;variable&quot;, &quot;not to scale&quot;] [4,1,2,3] [0.4, 0.1, 0.2, 0.3]]
4×4 Matrix{Any}:
 4000  &quot;a&quot;             4  0.4
 1000  &quot;categorical&quot;   1  0.1
 2000  &quot;variable&quot;      2  0.2
 3000  &quot;not to scale&quot;  3  0.3

julia&gt; mod     = Scaler(MinMaxScaler(outputRange=(0,10)),skip=[2])
A Scaler BetaMLModel (unfitted)

julia&gt; xscaled = fit!(mod,x)
4×4 Matrix{Any}:
 10.0      &quot;a&quot;             10.0      10.0
  0.0      &quot;categorical&quot;    0.0       0.0
  3.33333  &quot;variable&quot;       3.33333   3.33333
  6.66667  &quot;not to scale&quot;   6.66667   6.66667

julia&gt; xback   = inverse_predict(mod,xscaled)
4×4 Matrix{Any}:
 4000.0  &quot;a&quot;             4.0  0.4
 1000.0  &quot;categorical&quot;   1.0  0.1
 2000.0  &quot;variable&quot;      2.0  0.2
 3000.0  &quot;not to scale&quot;  3.0  0.3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L730">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.Scaler_hp" href="#BetaML.Utils.Scaler_hp"><code>BetaML.Utils.Scaler_hp</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct Scaler_hp &lt;: BetaMLHyperParametersSet</code></pre><p>Hyperparameters for the Scaler transformer</p><p><strong>Parameters</strong></p><ul><li><p><code>method</code>: The specific scaler method to employ with its own parameters. See <a href="Utils.html#BetaML.Utils.StandardScaler"><code>StandardScaler</code></a> [def] or <a href="Utils.html#BetaML.Utils.MinMaxScaler"><code>MinMaxScaler</code></a>.</p></li><li><p><code>skip</code>: The positional ids of the columns to skip scaling (eg. categorical columns, dummies,...) [def: <code>[]</code>]</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L711">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.StandardScaler" href="#BetaML.Utils.StandardScaler"><code>BetaML.Utils.StandardScaler</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct StandardScaler &lt;: BetaML.Utils.AbstractScaler</code></pre><p>Standardise the input to zero mean and unit standard deviation, aka &quot;Z-score&quot;.  Note that missing values are skipped.</p><p><strong>Parameters:</strong></p><ul><li><p><code>scale</code>: Scale to unit variance [def: true]</p></li><li><p><code>center</code>: Center to zero mean [def: true]</p></li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; using BetaML, Statistics

julia&gt; x         = [[4000,1000,2000,3000] [400,100,200,300] [4,1,2,3] [0.4, 0.1, 0.2, 0.3]]
4×4 Matrix{Float64}:
 4000.0  400.0  4.0  0.4
 1000.0  100.0  1.0  0.1
 2000.0  200.0  2.0  0.2
 3000.0  300.0  3.0  0.3

julia&gt; mod       = Scaler() # equiv to `Scaler(StandardScaler(scale=true, center=true))`
A Scaler BetaMLModel (unfitted)

julia&gt; xscaled   = fit!(mod,x)
4×4 Matrix{Float64}:
  1.34164    1.34164    1.34164    1.34164
 -1.34164   -1.34164   -1.34164   -1.34164
 -0.447214  -0.447214  -0.447214  -0.447214
  0.447214   0.447214   0.447214   0.447214

julia&gt; col_means = mean(xscaled, dims=1)
1×4 Matrix{Float64}:
 0.0  0.0  0.0  5.55112e-17

julia&gt; col_var   = var(xscaled, dims=1, corrected=false)
1×4 Matrix{Float64}:
 1.0  1.0  1.0  1.0

julia&gt; xback     = inverse_predict(mod, xscaled)
4×4 Matrix{Float64}:
 4000.0  400.0  4.0  0.4
 1000.0  100.0  1.0  0.1
 2000.0  200.0  2.0  0.2
 3000.0  300.0  3.0  0.3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L570">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.SuccessiveHalvingSearch" href="#BetaML.Utils.SuccessiveHalvingSearch"><code>BetaML.Utils.SuccessiveHalvingSearch</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct SuccessiveHalvingSearch &lt;: AutoTuneMethod</code></pre><p>Hyper-parameters validation of supervised models that search the parameters space trouth successive halving</p><p>All parameters are tested on a small sub-sample, then the &quot;best&quot; combinations are kept for a second round that use more samples and so on untill only one hyperparameter combination is left.</p><p><strong>Notes:</strong></p><ul><li>the default loss is suitable for 1-dimensional output supervised models, and applies itself cross-validation. Any function that accepts a model, some data and return a scalar loss can be used</li><li>the rate at which the potential candidate combinations of hyperparameters shrink is controlled by the number of data shares defined in <code>res_shared</code> (i.e. the epochs): more epochs are choosen, lower the &quot;shrink&quot; coefficient</li></ul><p><strong>Parameters:</strong></p><ul><li><p><code>loss::Function</code>: Loss function to use. [def: <a href="Utils.html#BetaML.Utils.l2loss_by_cv-Tuple{Any, Any}"><code>l2loss_by_cv</code></a><code>]. Any function that takes a model, data (a vector of arrays, even if we work only with X) and (using the</code>rng` keyword) a RNG and return a scalar loss.</p></li><li><p><code>res_shares::Vector{Float64}</code>: Shares of the (data) resources to use for the autotuning in the successive iterations [def: <code>[0.05, 0.2, 0.3]</code>]. With <code>res_share=1</code> all the dataset is used for autotuning, it can be very time consuming! The number of models is reduced of the same share in order to arrive with a single model. Increase the number of <code>res_shares</code> in order to increase the number of models kept at each iteration.</p></li></ul><ul><li><p><code>hpranges::Dict{String, Any}</code>: Dictionary of parameter names (String) and associated vector of values to test. Note that you can easily sample these values from a distribution with rand(distr<em>object,n</em>values). The number of points you provide for a given parameter can be interpreted as proportional to the prior you have on the importance of that parameter for the algorithm quality.</p></li><li><p><code>multithreads::Bool</code>: Use multiple threads in the search for the best hyperparameters [def: <code>false</code>]</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1132">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.error-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T" href="#Base.error-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T"><code>Base.error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>error(y,ŷ;ignorelabels=false) - Categorical error (T vs T)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L96">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.error-Union{Tuple{T}, Tuple{Int64, Vector{T}}} where T&lt;:Number" href="#Base.error-Union{Tuple{T}, Tuple{Int64, Vector{T}}} where T&lt;:Number"><code>Base.error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>error(y,ŷ) - Categorical error with probabilistic prediction of a single datapoint (Int vs PMF). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L222">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.error-Union{Tuple{T}, Tuple{Vector{Int64}, Matrix{T}}} where T&lt;:Number" href="#Base.error-Union{Tuple{T}, Tuple{Vector{Int64}, Matrix{T}}} where T&lt;:Number"><code>Base.error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>error(y,ŷ) - Categorical error with probabilistic predictions of a dataset (Int vs PMF). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L224">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.error-Union{Tuple{T}, Tuple{Vector{T}, Array{Dict{T, Float64}, 1}}} where T" href="#Base.error-Union{Tuple{T}, Tuple{Vector{T}, Array{Dict{T, Float64}, 1}}} where T"><code>Base.error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>error(y,ŷ) - Categorical error with with probabilistic predictions of a dataset given in terms of a dictionary of probabilities (T vs Dict{T,Float64}). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L226">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Base.reshape-Union{Tuple{T}, Tuple{T, Vararg{Any, N} where N}} where T&lt;:Number" href="#Base.reshape-Union{Tuple{T}, Tuple{T, Vararg{Any, N} where N}} where T&lt;:Number"><code>Base.reshape</code></a> — <span class="docstring-category">Method</span></header><section><div><p>reshape(myNumber, dims..) - Reshape a number as a n dimensional Array </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{Int64}, AbstractMatrix{T}}} where T&lt;:Number" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{Int64}, AbstractMatrix{T}}} where T&lt;:Number"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>accuracy(y,ŷ;tol,ignorelabels)</p><p>Categorical accuracy with probabilistic predictions of a dataset (PMF vs Int).</p><p><strong>Parameters:</strong></p><ul><li><code>y</code>: The N array with the correct category for each point <span>$n$</span>.</li><li><code>ŷ</code>: An (N,K) matrix of probabilities that each <span>$\hat y_n$</span> record with <span>$n \in 1,....,N$</span>  being of category <span>$k$</span> with <span>$k \in 1,...,K$</span>.</li><li><code>tol</code>: The tollerance to the prediction, i.e. if considering &quot;correct&quot; only a prediction where the value with highest probability is the true value (<code>tol</code> = 1), or consider instead the set of <code>tol</code> maximum values [def: <code>1</code>].</li><li><code>ignorelabels</code>: Whether to ignore the specific label order in y. Useful for unsupervised learning algorithms where the specific label order don&#39;t make sense [def: false]</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L136-L147">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractArray{Dict{T, Float64}, 1}}} where T" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractArray{Dict{T, Float64}, 1}}} where T"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>accuracy(y,ŷ;tol)</p><p>Categorical accuracy with probabilistic predictions of a dataset given in terms of a dictionary of probabilities (Dict{T,Float64} vs T).</p><p><strong>Parameters:</strong></p><ul><li><code>ŷ</code>: An array where each item is the estimated probability mass function in terms of a Dictionary(Item1 =&gt; Prob1, Item2 =&gt; Prob2, ...)</li><li><code>y</code>: The N array with the correct category for each point <span>$n$</span>.</li><li><code>tol</code>: The tollerance to the prediction, i.e. if considering &quot;correct&quot; only a prediction where the value with highest probability is the true value (<code>tol</code> = 1), or consider instead the set of <code>tol</code> maximum values [def: <code>1</code>].</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L162-L172">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>accuracy(ŷ,y;ignorelabels=false) - Categorical accuracy between two vectors (T vs T). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L72">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Int64, AbstractVector{T}}} where T&lt;:Number" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{Int64, AbstractVector{T}}} where T&lt;:Number"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">accuracy(y,ŷ;tol)</code></pre><p>Categorical accuracy with probabilistic prediction of a single datapoint (PMF vs Int).</p><p>Use the parameter tol [def: <code>1</code>] to determine the tollerance of the prediction, i.e. if considering &quot;correct&quot; only a prediction where the value with highest probability is the true value (<code>tol</code> = 1), or consider instead the set of <code>tol</code> maximum values.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L100-L105">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{T, AbstractDict{T, Float64}}} where T" href="#BetaML.Utils.accuracy-Union{Tuple{T}, Tuple{T, AbstractDict{T, Float64}}} where T"><code>BetaML.Utils.accuracy</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">accuracy(y,ŷ;tol)</code></pre><p>Categorical accuracy with probabilistic prediction of a single datapoint given in terms of a dictionary of probabilities (Dict{T,Float64} vs T).</p><p><strong>Parameters:</strong></p><ul><li><code>ŷ</code>: The returned probability mass function in terms of a Dictionary(Item1 =&gt; Prob1, Item2 =&gt; Prob2, ...)</li><li><code>tol</code>: The tollerance to the prediction, i.e. if considering &quot;correct&quot; only a prediction where the value with highest probability is the true value (<code>tol</code> = 1), or consider instead the set of <code>tol</code> maximum values [def: <code>1</code>].</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L119-L127">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.aic-Tuple{Any, Any}" href="#BetaML.Utils.aic-Tuple{Any, Any}"><code>BetaML.Utils.aic</code></a> — <span class="docstring-category">Method</span></header><section><div><p>aic(lL,k) -  Akaike information criterion (lower is better)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L230">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.autojacobian-Tuple{Any, Any}" href="#BetaML.Utils.autojacobian-Tuple{Any, Any}"><code>BetaML.Utils.autojacobian</code></a> — <span class="docstring-category">Method</span></header><section><div><p>autojacobian(f,x;nY)</p><p>Evaluate the Jacobian using AD in the form of a (nY,nX) matrix of first derivatives</p><p><strong>Parameters:</strong></p><ul><li><code>f</code>: The function to compute the Jacobian</li><li><code>x</code>: The input to the function where the jacobian has to be computed</li><li><code>nY</code>: The number of outputs of the function <code>f</code> [def: <code>length(f(x))</code>]</li></ul><p><strong>Return values:</strong></p><ul><li>An <code>Array{Float64,2}</code> of the locally evaluated Jacobian</li></ul><p><strong>Notes:</strong></p><ul><li>The <code>nY</code> parameter is optional. If provided it avoids having to compute <code>f(x)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L89-L104">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.autotune!-Tuple{Any, Any}" href="#BetaML.Utils.autotune!-Tuple{Any, Any}"><code>BetaML.Utils.autotune!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">autotune!(m, data) -&gt; Any
</code></pre><p>Hyperparameter autotuning.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1289">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.batch-Tuple{Integer, Integer}" href="#BetaML.Utils.batch-Tuple{Integer, Integer}"><code>BetaML.Utils.batch</code></a> — <span class="docstring-category">Method</span></header><section><div><p>batch(n,bsize;sequential=false,rng)</p><p>Return a vector of <code>bsize</code> vectors of indeces from <code>1</code> to <code>n</code>. Randomly unless the optional parameter <code>sequential</code> is used.</p><p><strong>Example:</strong></p><p><code>julia julia&gt; Utils.batch(6,2,sequential=true) 3-element Array{Array{Int64,1},1}:  [1, 2]  [3, 4]  [5, 6]</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Samplers.jl#L98-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.bic-Tuple{Any, Any, Any}" href="#BetaML.Utils.bic-Tuple{Any, Any, Any}"><code>BetaML.Utils.bic</code></a> — <span class="docstring-category">Method</span></header><section><div><p>bic(lL,k,n) -  Bayesian information criterion (lower is better)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L228">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.celu-Tuple{Any}" href="#BetaML.Utils.celu-Tuple{Any}"><code>BetaML.Utils.celu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>celu(x; α=1) </p><p>https://arxiv.org/pdf/1704.07483.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L19-L22">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.class_counts-Tuple{Any}" href="#BetaML.Utils.class_counts-Tuple{Any}"><code>BetaML.Utils.class_counts</code></a> — <span class="docstring-category">Method</span></header><section><div><p>class_counts(x;classes=nothing)</p><p>Return a (unsorted) vector with the counts of each unique item (element or rows) in a dataset.</p><p>If order is important or not all classes are present in the data, a preset vectors of classes can be given in the parameter <code>classes</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1343-L1350">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.class_counts_with_labels-Tuple{Any}" href="#BetaML.Utils.class_counts_with_labels-Tuple{Any}"><code>BetaML.Utils.class_counts_with_labels</code></a> — <span class="docstring-category">Method</span></header><section><div><p>class<em>counts</em>with_labels(x)</p><p>Return a dictionary that counts the number of each unique item (rows) in a dataset.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1309-L1314">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.cols_with_missing-Tuple{Any}" href="#BetaML.Utils.cols_with_missing-Tuple{Any}"><code>BetaML.Utils.cols_with_missing</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">cols_with_missing(x)</code></pre><p>Retuyrn an array with the ids of the columns where there is at least a missing value.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1032-L1036">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.consistent_shuffle-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T" href="#BetaML.Utils.consistent_shuffle-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T"><code>BetaML.Utils.consistent_shuffle</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">consistent_shuffle(data;dims,rng)</code></pre><p>Shuffle a vector of n-dimensional arrays across dimension <code>dims</code> keeping the same order between the arrays</p><p><strong>Parameters</strong></p><ul><li><code>data</code>: The vector of arrays to shuffle</li><li><code>dims</code>: The dimension over to apply the shuffle [def: <code>1</code>]</li><li><code>rng</code>:  An <code>AbstractRNG</code> to apply for the shuffle</li></ul><p><strong>Notes</strong></p><ul><li>All the arrays must have the same size for the dimension to shuffle</li></ul><p><strong>Example</strong></p><p><code>julia&gt; a = [1 2 30; 10 20 30]; b = [100 200 300]; julia&gt; (aShuffled, bShuffled) = consistent_shuffle([a,b],dims=2) 2-element Vector{Matrix{Int64}}:  [1 30 2; 10 30 20]  [100 300 200]</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Stochasticity.jl#L36-L57">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.cosine_distance-Tuple{Any, Any}" href="#BetaML.Utils.cosine_distance-Tuple{Any, Any}"><code>BetaML.Utils.cosine_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Cosine distance</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.cross_validation" href="#BetaML.Utils.cross_validation"><code>BetaML.Utils.cross_validation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">cross_validation(
    f,
    data
) -&gt; Union{Tuple{Any, Any}, Vector{Any}}
cross_validation(
    f,
    data,
    sampler;
    dims,
    verbosity,
    return_statistics
) -&gt; Union{Tuple{Any, Any}, Vector{Any}}
</code></pre><p>Perform cross_validation according to <code>sampler</code> rule by calling the function f and collecting its output</p><p><strong>Parameters</strong></p><ul><li><code>f</code>: The user-defined function that consume the specific train and validation data and return somehting (often the associated validation error). See later</li><li><code>data</code>: A single n-dimenasional array or a vector of them (e.g. X,Y), depending on the tasks required by <code>f</code>.</li><li>sampler: An istance of a <code>AbstractDataSampler</code>, defining the &quot;rules&quot; for sampling at each iteration. [def: <code>KFold(nsplits=5,nrepeats=1,shuffle=true,rng=Random.GLOBAL_RNG)</code> ]. Note that the RNG passed to the <code>f</code> function is the <code>RNG</code> passed to the sampler</li><li><code>dims</code>: The dimension over performing the cross_validation i.e. the dimension containing the observations [def: <code>1</code>]</li><li><code>verbosity</code>: The verbosity to print information during each iteration (this can also be printed in the <code>f</code> function) [def: <code>STD</code>]</li><li><code>return_statistics</code>: Wheter cross_validation should return the statistics of the output of <code>f</code> (mean and standard deviation) or the whole outputs [def: <code>true</code>].</li></ul><p><strong>Notes</strong></p><p>cross_validation works by calling the function <code>f</code>, defined by the user, passing to it the tuple <code>trainData</code>, <code>valData</code> and <code>rng</code> and collecting the result of the function f. The specific method for which <code>trainData</code>, and <code>valData</code> are selected at each iteration depends on the specific <code>sampler</code>, whith a single 5 k-fold rule being the default.</p><p>This approach is very flexible because the specific model to employ or the metric to use is left within the user-provided function. The only thing that cross_validation does is provide the model defined in the function <code>f</code> with the opportune data (and the random number generator).</p><p><strong>Input of the user-provided function</strong> <code>trainData</code> and <code>valData</code> are both themselves tuples. In supervised models, cross<em>validations <code>data</code> should be a tuple of (X,Y) and <code>trainData</code> and <code>valData</code> will be equivalent to (xtrain, ytrain) and (xval, yval). In unsupervised models <code>data</code> is a single array, but the training and validation data should still need to be accessed as  <code>trainData[1]</code> and <code>valData[1]</code>. <strong>Output of the user-provided function</strong> The user-defined function can return whatever. However, if `return</em>statistics<code>is left on its default</code>true` value the user-defined function must return a single scalar (e.g. some error measure) so that the mean and the standard deviation are returned.</p><p>Note that <code>cross_validation</code> can beconveniently be employed using the <code>do</code> syntax, as Julia automatically rewrite <code>cross_validation(data,...) trainData,valData,rng  ...user defined body... end</code> as <code>cross_validation(f(trainData,valData,rng ), data,...)</code></p><p><strong>Example</strong></p><pre><code class="language-julia hljs">julia&gt; X = [11:19 21:29 31:39 41:49 51:59 61:69];
julia&gt; Y = [1:9;];
julia&gt; sampler = KFold(nsplits=3);
julia&gt; (μ,σ) = cross_validation([X,Y],sampler) do trainData,valData,rng
                 (xtrain,ytrain) = trainData; (xval,yval) = valData
                 trainedModel    = buildForest(xtrain,ytrain,30)
                 ŷval            = predict(trainedModel,xval)
                 ϵ               = relative_mean_error(yval,ŷval,normrec=false)
                 return ϵ
               end
(0.3202242202242202, 0.04307662219315022)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1051">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.crossentropy-Tuple{Any, Any}" href="#BetaML.Utils.crossentropy-Tuple{Any, Any}"><code>BetaML.Utils.crossentropy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>crossentropy(y,ŷ; weight)</p><p>Compute the (weighted) cross-entropy between the predicted and the sampled probability distributions.</p><p>To be used in classification problems.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L60-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.dcelu-Tuple{Any}" href="#BetaML.Utils.dcelu-Tuple{Any}"><code>BetaML.Utils.dcelu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dcelu(x; α=1) </p><p>https://arxiv.org/pdf/1704.07483.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L22-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.delu-Tuple{Any}" href="#BetaML.Utils.delu-Tuple{Any}"><code>BetaML.Utils.delu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>delu(x; α=1) with α &gt; 0 </p><p>https://arxiv.org/pdf/1511.07289.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L17-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.dmaximum-Tuple{Any}" href="#BetaML.Utils.dmaximum-Tuple{Any}"><code>BetaML.Utils.dmaximum</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dmaximum(x) </p><p>Multidimensional verison of the derivative of <code>maximum</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L79-L82">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.dmish-Tuple{Any}" href="#BetaML.Utils.dmish-Tuple{Any}"><code>BetaML.Utils.dmish</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dmish(x) </p><p>https://arxiv.org/pdf/1908.08681v1.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L76-L79">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.dplu-Tuple{Any}" href="#BetaML.Utils.dplu-Tuple{Any}"><code>BetaML.Utils.dplu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dplu(x;α=0.1,c=1) </p><p>Piecewise Linear Unit derivative </p><p>https://arxiv.org/pdf/1809.09534.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L26-L31">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.drelu-Tuple{Any}" href="#BetaML.Utils.drelu-Tuple{Any}"><code>BetaML.Utils.drelu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>drelu(x) </p><p>Rectified Linear Unit </p><p>https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L13-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.dsigmoid-Tuple{Any}" href="#BetaML.Utils.dsigmoid-Tuple{Any}"><code>BetaML.Utils.dsigmoid</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dsigmoid(x)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L46">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.dsoftmax-Tuple{Any}" href="#BetaML.Utils.dsoftmax-Tuple{Any}"><code>BetaML.Utils.dsoftmax</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dsoftmax(x; β=1) </p><p>Derivative of the softmax function </p><p>https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L51-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.dsoftplus-Tuple{Any}" href="#BetaML.Utils.dsoftplus-Tuple{Any}"><code>BetaML.Utils.dsoftplus</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dsoftplus(x) </p><p>https://en.wikipedia.org/wiki/Rectifier<em>(neural</em>networks)#Softplus</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L72-L75">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.dtanh-Tuple{Any}" href="#BetaML.Utils.dtanh-Tuple{Any}"><code>BetaML.Utils.dtanh</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dtanh(x)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.elu-Tuple{Any}" href="#BetaML.Utils.elu-Tuple{Any}"><code>BetaML.Utils.elu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>elu(x; α=1) with α &gt; 0 </p><p>https://arxiv.org/pdf/1511.07289.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L15-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.entropy-Tuple{Any}" href="#BetaML.Utils.entropy-Tuple{Any}"><code>BetaML.Utils.entropy</code></a> — <span class="docstring-category">Method</span></header><section><div><p>entropy(x)</p><p>Calculate the entropy for a list of items (or rows).</p><p>See: https://en.wikipedia.org/wiki/Decision<em>tree</em>learning#Gini_impurity</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L204-L210">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.generate_parallel_rngs-Tuple{Random.AbstractRNG, Integer}" href="#BetaML.Utils.generate_parallel_rngs-Tuple{Random.AbstractRNG, Integer}"><code>BetaML.Utils.generate_parallel_rngs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">generate_parallel_rngs(rng::AbstractRNG, n::Integer;reSeed=false)</code></pre><p>For multi-threaded models, return n independent random number generators (one per thread) to be used in threaded computations.</p><p>Note that each ring is a <em>copy</em> of the original random ring. This means that code that <em>use</em> these RNGs will not change the original RNG state.</p><p>Use it with <code>rngs = generate_parallel_rngs(rng,Threads.nthreads())</code> to have a separate rng per thread. By default the function doesn&#39;t re-seed the RNG, as you may want to have a loop index based re-seeding strategy rather than a threadid-based one (to guarantee the same result independently of the number of threads). If you prefer, you can instead re-seed the RNG here (using the parameter <code>reSeed=true</code>), such that each thread has a different seed. Be aware however that the stream  of number generated will depend from the number of threads at run time.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Stochasticity.jl#L11-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.getpermutations-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T" href="#BetaML.Utils.getpermutations-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T"><code>BetaML.Utils.getpermutations</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">getpermutations(v::AbstractArray{T,1};keepStructure=false)</code></pre><p>Return a vector of either (a) all possible permutations (uncollected) or (b) just those based on the unique values of the vector</p><p>Useful to measure accuracy where you don&#39;t care about the actual name of the labels, like in unsupervised classifications (e.g. clustering)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L30-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.gini-Tuple{Any}" href="#BetaML.Utils.gini-Tuple{Any}"><code>BetaML.Utils.gini</code></a> — <span class="docstring-category">Method</span></header><section><div><p>gini(x)</p><p>Calculate the Gini Impurity for a list of items (or rows).</p><p>See: https://en.wikipedia.org/wiki/Decision<em>tree</em>learning#Information_gain</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L175-L181">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.issortable-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T, N}" href="#BetaML.Utils.issortable-Union{Tuple{AbstractArray{T, N}}, Tuple{N}, Tuple{T}} where {T, N}"><code>BetaML.Utils.issortable</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Return wheather an array is sortable, i.e. has methos issort defined</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.l1_distance-Tuple{Any, Any}" href="#BetaML.Utils.l1_distance-Tuple{Any, Any}"><code>BetaML.Utils.l1_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>L1 norm distance (aka <em>Manhattan Distance</em>)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.l2_distance-Tuple{Any, Any}" href="#BetaML.Utils.l2_distance-Tuple{Any, Any}"><code>BetaML.Utils.l2_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Euclidean (L2) distance</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L11">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.l2loss_by_cv-Tuple{Any, Any}" href="#BetaML.Utils.l2loss_by_cv-Tuple{Any, Any}"><code>BetaML.Utils.l2loss_by_cv</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Compute the loss of a given model over a given (x,y) dataset running cross-validation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L179">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.l2squared_distance-Tuple{Any, Any}" href="#BetaML.Utils.l2squared_distance-Tuple{Any, Any}"><code>BetaML.Utils.l2squared_distance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Squared Euclidean (L2) distance</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.lse-Tuple{Any}" href="#BetaML.Utils.lse-Tuple{Any}"><code>BetaML.Utils.lse</code></a> — <span class="docstring-category">Method</span></header><section><div><p>LogSumExp for efficiently computing log(sum(exp.(x))) </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1454">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.makematrix-Tuple{AbstractVector{T} where T}" href="#BetaML.Utils.makematrix-Tuple{AbstractVector{T} where T}"><code>BetaML.Utils.makematrix</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Transform an Array{T,1} in an Array{T,2} and leave unchanged Array{T,2}.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.mean_dicts-Tuple{Any}" href="#BetaML.Utils.mean_dicts-Tuple{Any}"><code>BetaML.Utils.mean_dicts</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mean_dicts(dicts)</p><p>Compute the mean of the values of an array of dictionaries.</p><p>Given <code>dicts</code> an array of dictionaries, <code>mean_dicts</code> first compute the union of the keys and then average the values. If the original valueas are probabilities (non-negative items summing to 1), the result is also a probability distribution.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1420-L1428">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.mish-Tuple{Any}" href="#BetaML.Utils.mish-Tuple{Any}"><code>BetaML.Utils.mish</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mish(x) </p><p>https://arxiv.org/pdf/1908.08681v1.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L74-L77">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.mode-Union{Tuple{AbstractArray{Dict{T, Float64}, N} where N}, Tuple{T}} where T" href="#BetaML.Utils.mode-Union{Tuple{AbstractArray{Dict{T, Float64}, N} where N}, Tuple{T}} where T"><code>BetaML.Utils.mode</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mode(elements,rng)</p><p>Given a vector of dictionaries whose key is numerical (e.g. probabilities), a vector of vectors or a matrix, it returns the mode of each element (dictionary, vector or row) in terms of the key or the position.</p><p>Use it to return a unique value from a multiclass classifier returning probabilities.</p><p><strong>Note:</strong></p><ul><li>If multiple classes have the highest mode, one is returned at random (use the parameter <code>rng</code> to fix the stochasticity)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1397-L1407">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.mode-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Number" href="#BetaML.Utils.mode-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T&lt;:Number"><code>BetaML.Utils.mode</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mode(v::AbstractVector{T};rng)</p><p>Return the position with the highest value in an array, interpreted as mode (using rand in case of multimodal values)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1381-L1386">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.mode-Union{Tuple{Dict{T, Float64}}, Tuple{T}} where T" href="#BetaML.Utils.mode-Union{Tuple{Dict{T, Float64}}, Tuple{T}} where T"><code>BetaML.Utils.mode</code></a> — <span class="docstring-category">Method</span></header><section><div><p>mode(dict::Dict{T,Float64};rng)</p><p>Return the key with highest mode (using rand in case of multimodal values)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1366-L1371">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.mse-Tuple{Any, Any}" href="#BetaML.Utils.mse-Tuple{Any, Any}"><code>BetaML.Utils.mse</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mse(y,ŷ)</code></pre><p>Compute the mean squared error (MSE) (aka mean squared deviation - MSD) between two vectors y and ŷ. Note that while the deviation is averaged by the length of <code>y</code> is is not scaled to give it a relative meaning.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L696-L701">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.pairwise-Tuple{AbstractArray}" href="#BetaML.Utils.pairwise-Tuple{AbstractArray}"><code>BetaML.Utils.pairwise</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">pairwise(x::AbstractArray; distance, dims) -&gt; Any
</code></pre><p>Compute pairwise distance matrix between elements of an array identified across dimension <code>dims</code>.</p><p><strong>Parameters:</strong></p><ul><li><code>x</code>: the data array </li><li>distance: a distance measure [def: <code>l2_distance</code>]</li><li>dims: the dimension of the observations [def: <code>1</code>, i.e. records on rows]</li></ul><p><strong>Returns:</strong></p><ul><li>a n<em>records by n</em>records simmetric matrix of the pairwise distances</li></ul><p><strong>Notes:</strong></p><ul><li>if performances matters, you can use something like <code>Distances.pairwise(Distances.euclidean,x,dims=1)</code> from the <a href="https://github.com/JuliaStats/Distances.jl"><code>Distances</code></a> package.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.partition-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{Float64}}} where T&lt;:AbstractArray" href="#BetaML.Utils.partition-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{Float64}}} where T&lt;:AbstractArray"><code>BetaML.Utils.partition</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">partition(data,parts;shuffle,dims,rng)</code></pre><p>Partition (by rows) one or more matrices according to the shares in <code>parts</code>.</p><p><strong>Parameters</strong></p><ul><li><code>data</code>: A matrix/vector or a vector of matrices/vectors</li><li><code>parts</code>: A vector of the required shares (must sum to 1)</li><li><code>shufle</code>: Whether to randomly shuffle the matrices (preserving the relative order between matrices)</li><li><code>dims</code>: The dimension for which to partition [def: <code>1</code>]</li><li><code>copy</code>: Wheter to <em>copy</em> the actual data or only create a reference [def: <code>true</code>]</li><li><code>rng</code>: Random Number Generator (see <a href="Api.html#BetaML.Api.FIXEDSEED"><code>FIXEDSEED</code></a>) [deafult: <code>Random.GLOBAL_RNG</code>]</li></ul><p><strong>Notes:</strong></p><ul><li>The sum of parts must be equal to 1</li><li>The number of elements in the specified dimension must be the same for all the arrays in <code>data</code></li></ul><p><strong>Example:</strong></p><p><code>julia julia&gt; x = [1:10 11:20] julia&gt; y = collect(31:40) julia&gt; ((xtrain,xtest),(ytrain,ytest)) = partition([x,y],[0.7,0.3])</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L457-L480">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.plu-Tuple{Any}" href="#BetaML.Utils.plu-Tuple{Any}"><code>BetaML.Utils.plu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>plu(x;α=0.1,c=1) </p><p>Piecewise Linear Unit </p><p>https://arxiv.org/pdf/1809.09534.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L24-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.polynomial_kernel-Tuple{Any, Any}" href="#BetaML.Utils.polynomial_kernel-Tuple{Any, Any}"><code>BetaML.Utils.polynomial_kernel</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Polynomial kernel parametrised with <code>constant=0</code> and <code>degree=2</code> (i.e. a quadratic kernel). For other <code>cᵢ</code> and <code>dᵢ</code> use <code>K = (x,y) -&gt; polynomial_kernel(x,y,c=cᵢ,d=dᵢ)</code> as kernel function in the supporting algorithms</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L238-L241">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.pool1d" href="#BetaML.Utils.pool1d"><code>BetaML.Utils.pool1d</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pool1d(x,poolsize=2;f=mean)</code></pre><p>Apply funtion <code>f</code> to a rolling poolsize contiguous (in 1d) neurons.</p><p>Applicable to <code>VectorFunctionLayer</code>, e.g. <code>layer2  = VectorFunctionLayer(nₗ,f=(x-&gt;pool1d(x,4,f=mean))</code> <strong>Attention</strong>: to apply this function as activation function in a neural network you will need Julia version &gt;= 1.6, otherwise you may experience a segmentation fault (see <a href="https://github.com/FluxML/Zygote.jl/issues/943">this bug report</a>)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L30-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.radial_kernel-Tuple{Any, Any}" href="#BetaML.Utils.radial_kernel-Tuple{Any, Any}"><code>BetaML.Utils.radial_kernel</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Radial Kernel (aka <em>RBF kernel</em>) parametrised with γ=1/2. For other gammas γᵢ use <code>K = (x,y) -&gt; radial_kernel(x,y,γ=γᵢ)</code> as kernel function in the supporting algorithms</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L235-L237">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.relative_mean_error-Tuple{Any, Any}" href="#BetaML.Utils.relative_mean_error-Tuple{Any, Any}"><code>BetaML.Utils.relative_mean_error</code></a> — <span class="docstring-category">Method</span></header><section><div><p>relative<em>mean</em>error(y, ŷ;normdim=false,normrec=false,p=1)</p><p>Compute the relative mean error (l-1 based by default) between y and ŷ.</p><p>There are many ways to compute a relative mean error. In particular, if normrec (normdim) is set to true, the records (dimensions) are normalised, in the sense that it doesn&#39;t matter if a record (dimension) is bigger or smaller than the others, the relative error is first computed for each record (dimension) and then it is averaged. With both <code>normdim</code> and <code>normrec</code> set to <code>false</code> (default) the function returns the relative mean error; with both set to <code>true</code> it returns the mean relative error (i.e. with p=1 the &quot;<a href="https://en.wikipedia.org/wiki/Mean_absolute_percentage_error">mean absolute percentage error (MAPE)</a>&quot;) The parameter <code>p</code> [def: <code>1</code>] controls the p-norm used to define the error.</p><p>The <em>mean relative error</em> enfatises the relativeness of the error, i.e. all observations and dimensions weigth the same, wether large or small. Conversly, in the <em>relative mean error</em> the same relative error on larger observations (or dimensions) weights more.</p><p>For example, given <code>y = [1,44,3]</code> and <code>ŷ = [2,45,2]</code>, the <em>mean relative error</em> <code>mean_relative_error(y,ŷ,normrec=true)</code> is <code>0.452</code>, while the <em>relative mean error</em> <code>relative_mean_error(y,ŷ, normrec=false)</code> is &quot;only&quot; <code>0.0625</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L704-L717">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.relu-Tuple{Any}" href="#BetaML.Utils.relu-Tuple{Any}"><code>BetaML.Utils.relu</code></a> — <span class="docstring-category">Method</span></header><section><div><p>relu(x) </p><p>Rectified Linear Unit </p><p>https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L11-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.sigmoid-Tuple{Any}" href="#BetaML.Utils.sigmoid-Tuple{Any}"><code>BetaML.Utils.sigmoid</code></a> — <span class="docstring-category">Method</span></header><section><div><p>sigmoid(x)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L44">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.silhouette-Tuple{Any, Any}" href="#BetaML.Utils.silhouette-Tuple{Any, Any}"><code>BetaML.Utils.silhouette</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">silhouette(distances, classes) -&gt; Any
</code></pre><p>Provide Silhouette scoring for cluster outputs</p><p><strong>Parameters:</strong></p><ul><li><code>distances</code>: the nrecords by nrecords pairwise distance matrix</li><li><code>classes</code>: the vector of assigned classes to each record</li></ul><p><strong>Notes:</strong></p><ul><li>the matrix of pairwise distances can be obtained with the function <a href="Utils.html#BetaML.Utils.pairwise-Tuple{AbstractArray}"><code>pairwise</code></a></li><li>this function doesn&#39;t sample. Eventually sample before</li><li>to get the score for the cluster simply compute the <code>mean</code></li><li>see also the <a href="https://en.wikipedia.org/wiki/Silhouette_(clustering)">Wikipedia article</a></li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; x  = [1 2 3 3; 1.2 3 3.1 3.2; 2 4 6 6.2; 2.1 3.5 5.9 6.3];

julia&gt; s_scores = silhouette(pairwise(x),[1,2,2,2])
4-element Vector{Float64}:
  0.0
 -0.7590778795827623
  0.5030093571833065
  0.4936350560759424</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L229">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.softmax-Tuple{Any}" href="#BetaML.Utils.softmax-Tuple{Any}"><code>BetaML.Utils.softmax</code></a> — <span class="docstring-category">Method</span></header><section><div><p>softmax (x; β=1) </p><p>The input x is a vector. Return a PMF</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L48-L51">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.softplus-Tuple{Any}" href="#BetaML.Utils.softplus-Tuple{Any}"><code>BetaML.Utils.softplus</code></a> — <span class="docstring-category">Method</span></header><section><div><p>softplus(x) </p><p>https://en.wikipedia.org/wiki/Rectifier<em>(neural</em>networks)#Softplus</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L70-L73">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.squared_cost-Tuple{Any, Any}" href="#BetaML.Utils.squared_cost-Tuple{Any, Any}"><code>BetaML.Utils.squared_cost</code></a> — <span class="docstring-category">Method</span></header><section><div><p>squared_cost(y,ŷ)</p><p>Compute the squared costs between a vector of observations and one of prediction as (1/2)*norm(y - ŷ)^2.</p><p>Aside the 1/2 term, it correspond to the squared l-2 norm distance and when it is averaged on multiple datapoints corresponds to the Mean Squared Error (<a href="https://en.wikipedia.org/wiki/Mean_squared_error">MSE</a>). It is mostly used for regression problems.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Measures.jl#L686-L693">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.sterling-Tuple{BigInt, BigInt}" href="#BetaML.Utils.sterling-Tuple{BigInt, BigInt}"><code>BetaML.Utils.sterling</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Sterling number: number of partitions of a set of n elements in k sets </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Processing.jl#L1456">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.variance-Tuple{Any}" href="#BetaML.Utils.variance-Tuple{Any}"><code>BetaML.Utils.variance</code></a> — <span class="docstring-category">Method</span></header><section><div><p>variance(x) - population variance</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Transformers.jl#L222">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.xavier_init" href="#BetaML.Utils.xavier_init"><code>BetaML.Utils.xavier_init</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">xavier_init(previous_npar, this_npar) -&gt; Matrix{Float64}
xavier_init(
    previous_npar,
    this_npar,
    outsize;
    rng,
    eltype
) -&gt; Any
</code></pre><p>PErform a Xavier initialisation of the weigths</p><p><strong>Parameters:</strong></p><ul><li><code>previous_npar</code>: number of parameters of the previous layer</li><li><code>this_npar</code>: number of parameters of this layer</li><li><code>outsize</code>: tuple with the size of the weigths [def: <code>(this_npar,previous_npar)</code>]</li><li><code>rng</code> : random number generator [def: <code>Random.GLOBAL_RNG</code>]</li><li><code>eltype</code>: eltype of the weigth array [def: <code>Float64</code>]</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Samplers.jl#L127">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.@codelocation-Tuple{}" href="#BetaML.Utils.@codelocation-Tuple{}"><code>BetaML.Utils.@codelocation</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@codelocation()</code></pre><p>Helper macro to print during runtime an info message concerning the code being executed position</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Logging_utils.jl#L8-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="BetaML.Utils.@threadsif-Tuple{Any, Any}" href="#BetaML.Utils.@threadsif-Tuple{Any, Any}"><code>BetaML.Utils.@threadsif</code></a> — <span class="docstring-category">Macro</span></header><section><div><p>Conditionally apply multi-threading to <code>for</code> loops. This is a variation on <code>Base.Threads.@threads</code> that adds a run-time boolean flag to enable or disable threading. </p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">function optimize(objectives; use_threads=true)
    @threadsif use_threads for k = 1:length(objectives)
    # ...
    end
end

# Notes:
- Borrowed from https://github.com/JuliaQuantumControl/QuantumControlBase.jl/blob/master/src/conditionalthreads.jl</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/sylvaticus/BetaML.jl/blob/7ea70ed7ba8482e67203c607c936bb71f7238486/src/Utils/Miscellaneous.jl#L14">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="Imputation.html">« Imputation</a><a class="docs-footer-nextpage" href="MLJ_interface.html">MLJ interface »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Friday 26 January 2024 10:00">Friday 26 January 2024</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
