<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting started · BetaML.jl Documentation</title><meta name="title" content="Getting started · BetaML.jl Documentation"/><meta property="og:title" content="Getting started · BetaML.jl Documentation"/><meta property="twitter:title" content="Getting started · BetaML.jl Documentation"/><meta name="description" content="Documentation for BetaML.jl Documentation."/><meta property="og:description" content="Documentation for BetaML.jl Documentation."/><meta property="twitter:description" content="Documentation for BetaML.jl Documentation."/><script async src="https://www.googletagmanager.com/gtag/js?id=G-JYKX8QY5JW"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-JYKX8QY5JW', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../index.html"><img src="../assets/logo.png" alt="BetaML.jl Documentation logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">BetaML.jl Documentation</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Index</a></li><li><span class="tocitem">Tutorial</span><ul><li class="is-active"><a class="tocitem" href="Betaml_tutorial_getting_started.html">Getting started</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#using_betaml_from_other_languages"><span>Using BetaML from other programming languages</span></a></li><li><a class="tocitem" href="#stochasticity_reproducibility"><span>Dealing with stochasticity and reproducibility</span></a></li><li><a class="tocitem" href="#Saving-and-loading-trained-models"><span>Saving and loading trained models</span></a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Classification - cars</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Classification - cars/betaml_tutorial_classification_cars.html">A classification task when labels are known - determining the country of origin of cars given the cars characteristics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Regression - bike sharing</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Regression - bike sharing/betaml_tutorial_regression_sharingBikes.html">A regression task: the prediction of  bike  sharing demand</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Clustering - Iris</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Clustering - Iris/betaml_tutorial_cluster_iris.html">A clustering task: the prediction of  plant species from floreal measures (the iris dataset)</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-5" type="checkbox"/><label class="tocitem" for="menuitem-2-5"><span class="docs-label">Multi-branch neural network</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Multi-branch neural network/betaml_tutorial_multibranch_nn.html">A deep neural network with multi-branch architecture</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-6" type="checkbox"/><label class="tocitem" for="menuitem-2-6"><span class="docs-label">Feature importance</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="Feature importance/Feature_importance.html">Understanding variable importance in black-box machine learning models</a></li></ul></li></ul></li><li><span class="tocitem">API (Reference manual)</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">API V2 (current)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../Api_v2_user.html">Introduction for user</a></li><li><input class="collapse-toggle" id="menuitem-3-1-2" type="checkbox"/><label class="tocitem" for="menuitem-3-1-2"><span class="docs-label">For developers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../Api_v2_developer.html">API implementation</a></li><li><a class="tocitem" href="../StyleGuide_templates.html">Style guide</a></li></ul></li><li><a class="tocitem" href="../Api.html">The Api module</a></li></ul></li><li><a class="tocitem" href="../Perceptron.html">Perceptron</a></li><li><a class="tocitem" href="../Trees.html">Trees</a></li><li><a class="tocitem" href="../Nn.html">Nn</a></li><li><a class="tocitem" href="../Clustering.html">Clustering</a></li><li><a class="tocitem" href="../GMM.html">GMM</a></li><li><a class="tocitem" href="../Imputation.html">Imputation</a></li><li><a class="tocitem" href="../Utils.html">Utils</a></li></ul></li><li><a class="tocitem" href="../MLJ_interface.html">MLJ interface</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorial</a></li><li class="is-active"><a href="Betaml_tutorial_getting_started.html">Getting started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="Betaml_tutorial_getting_started.html">Getting started</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sylvaticus/BetaML.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/sylvaticus/BetaML.jl/blob/master/docs/src/tutorials/Betaml_tutorial_getting_started.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="getting_started"><a class="docs-heading-anchor" href="#getting_started">Getting started</a><a id="getting_started-1"></a><a class="docs-heading-anchor-permalink" href="#getting_started" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>This &quot;tutorial&quot; part of the documentation presents a step-by-step guide to the main algorithms and utility functions provided by BetaML and comparisons with the leading packages in each field. Aside this page, the tutorial is divided in the following sections:</p><ul><li><a href="Classification - cars/betaml_tutorial_classification_cars.html#classification_tutorial">Classification tutorial</a> - Topics: <em>Decision trees and random forests, neural networks (softmax), dealing with stochasticity, loading data from internet</em></li><li><a href="Regression - bike sharing/betaml_tutorial_regression_sharingBikes.html#regression_tutorial">Regression tutorial</a> - Topics: <em>Decision trees, Random forests, neural networks, hyper-parameters autotuning, one-hot encoding, continuous error measures</em></li><li><a href="Clustering - Iris/betaml_tutorial_cluster_iris.html#clustering_tutorial">Clustering tutorial</a> - Topics: <em>k-means, kmedoids, generative (gaussian) mixture models (gmm), cross-validation, ordinal encoding</em></li><li><a href="Multi-branch neural network/betaml_tutorial_multibranch_nn.html#multibranch_nn_tutorial">Multi-branch neural network</a> - Topics: <em>neural networks regression, multi-branch neural network</em></li><li><a href="Feature importance/Feature_importance.html#variable_importance_tutorial">Feature importance</a> - Topics: <em>feature importance, Sobol indices, mean decrease accuracy (mda), Shapley values</em></li></ul><p>Detailed usage instructions on each algorithm can be found on each model struct (listed <a href="../index.html#models_list">here</a>), while theoretical notes describing most of them can be found at the companion repository <a href="https://github.com/sylvaticus/MITx_6.86x">https://github.com/sylvaticus/MITx_6.86x</a>.</p><p>The overall &quot;philosophy&quot; of BetaML is to support simple machine learning tasks easily and make complex tasks possible. An the most basic level, the majority of  algorithms have default parameters suitable for a basic analysis. A great level of flexibility can be already achieved by just employing the full set of model parameters, for example changing the distance function in <code>KMedoidsClusterer</code> to <code>l1_distance</code> (aka &quot;Manhattan distance&quot;). Finally, the greatest flexibility can be obtained by customising BetaML and writing, for example, its own neural network layer type (by subclassing <code>AbstractLayer</code>), its own sampler (by subclassing <code>AbstractDataSampler</code>) or its own mixture component (by subclassing <code>AbstractMixture</code>), In such a cases, while not required by any means, please consider to give it back to the community and open a pull request to integrate your work in BetaML.</p><p>If you are looking for an introductory book on Julia, you could consider &quot;<a href="https://www.julia-book.com/">Julia Quick Syntax Reference</a>&quot; (Apress,2019) or the online course &quot;<a href="https://sylvaticus.github.io/SPMLJ/stable/">Introduction to Scientific Programming and Machine Learning with Julia</a>&quot;.</p><p>A few conventions applied across the library:</p><ul><li>Type names use the so-called &quot;CamelCase&quot; convention, where the words are separated by a capital letter rather than <code>_</code> ,while function names use lower letters only, with words eventually separated (but only when really neeed for readibility) by an <code>_</code>;</li><li>While some functions provide a <code>dims</code> parameter, most BetaML algorithms expect the input data layout with observations organised by rows and fields/features by columns. Almost everywhere in the code and documentation we refer with <code>N</code> the number of observations/records, <code>D</code> the number of dimensions and <code>K</code> the number of classes/categories;</li><li>While some algorithms accept as input DataFrames, the usage of standard arrays is encourages (if the data is passed to the function as dataframe, it may be converted to standard arrays somewhere inside inner loops, leading to great inefficiencies)</li><li>The accuracy/error/loss measures expect the ground true <code>y</code> and then the estimated <code>ŷ</code> (in this order)</li></ul><h2 id="using_betaml_from_other_languages"><a class="docs-heading-anchor" href="#using_betaml_from_other_languages">Using BetaML from other programming languages</a><a id="using_betaml_from_other_languages-1"></a><a class="docs-heading-anchor-permalink" href="#using_betaml_from_other_languages" title="Permalink"></a></h2><p>In this section we provide two examples of using <code>BetaML</code> directly in Python or R (with automatic object conversion). Click <code>Details</code> for a more extended explanation of these examples. While I have no experience with, the same approach can be used to access <code>BetaML</code> from any language with a binding to Julia, like Matlab or Javascript. </p><h3 id="Use-BetaML-in-Python"><a class="docs-heading-anchor" href="#Use-BetaML-in-Python">Use BetaML in Python</a><a id="Use-BetaML-in-Python-1"></a><a class="docs-heading-anchor-permalink" href="#Use-BetaML-in-Python" title="Permalink"></a></h3><pre><code class="nohighlight hljs">$ python3 -m pip install --user juliacall</code></pre><pre><code class="language-python hljs">&gt;&gt;&gt; from juliacall import Main as jl
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn import datasets
&gt;&gt;&gt; jl.seval(&#39;using Pkg; Pkg.add(&quot;BetaML&quot;)&#39;) # Only once 
&gt;&gt;&gt; jl.seval(&quot;using BetaML&quot;)
&gt;&gt;&gt; bml     = jl.BetaML
&gt;&gt;&gt; iris    = datasets.load_iris()
&gt;&gt;&gt; X       = iris.data[:, :4]
&gt;&gt;&gt; y       = iris.target + 1 # Julia arrays start from 1 not 0
&gt;&gt;&gt; (Xs,ys) = bml.consistent_shuffle([X,y])
&gt;&gt;&gt; m       = bml.KMeansClusterer(n_classes=3)
&gt;&gt;&gt; yhat    = bml.fit_ex(m,Xs) # Python doesn&#39;t allow exclamation marks in function names, so we use `fit_ex(⋅)` instead of `fit!(⋅)` (the original function name)
&gt;&gt;&gt; m._jl_display() # force a &quot;Julian&quot; way of displaying of Julia objects
&gt;&gt;&gt; acc     = bml.accuracy(ys,yhat,ignorelabels=True)
&gt;&gt;&gt; acc
 0.8933333333333333</code></pre><details><summary>Details</summary><p>We show for Python two separate &quot;Julia from Python&quot; interfaces, <a href="https://github.com/JuliaPy/pyjulia">PyJulia</a> and <a href="https://github.com/cjdoris/PythonCall.jl">JuliaCall</a> with the second one being the most recent one.</p><h4 id="With-the-classical-pyjulia-package"><a class="docs-heading-anchor" href="#With-the-classical-pyjulia-package">With the classical <code>pyjulia</code> package</a><a id="With-the-classical-pyjulia-package-1"></a><a class="docs-heading-anchor-permalink" href="#With-the-classical-pyjulia-package" title="Permalink"></a></h4><p><a href="https://github.com/JuliaPy/pyjulia">PyJulia</a> is a relativelly old method to use Julia code and libraries in Python. It works great but it requires that you already have a Julia working installation on your PC, so we need first to download and install the Julia binaries for our operating system from <a href="https://julialang.org/">JuliaLang.org</a>. Be sure that Julia is working by opening the Julia terminal and e.g. typing <code>println(&quot;hello world&quot;)</code></p><p>Install <code>PyJulia</code> with: </p><pre><code class="nohighlight hljs">$ python3 -m pip install --user julia   # the name of the package in `pip` is `julia`, not `PyJulia`</code></pre><p>For the sake of this tutorial, let&#39;s also install in Python a package that contains the dataset that we will use:</p><pre><code class="nohighlight hljs">$ python3 -m pip install --user sklearn # only for retrieving the dataset in the python way</code></pre><p>We can now open a Python terminal and, to obtain an interface to Julia, just run:</p><pre><code class="language-python hljs">&gt;&gt;&gt; import julia
&gt;&gt;&gt; julia.install() # Only once to set-up in julia the julia packages required by PyJulia
&gt;&gt;&gt; jl = julia.Julia(compiled_modules=False)</code></pre><p>If we have multiple Julia versions, we can specify the one to use in Python passing <code>julia=&quot;/path/to/julia/binary/executable&quot;</code> (e.g. <code>julia = &quot;/home/myUser/lib/julia-1.8.0/bin/julia&quot;</code>) to the <code>install()</code> function.</p><p>The <code>compiled_module=False</code> in the Julia constructor is a workaround to the common situation when the Python interpreter is statically linked to <code>libpython</code>, but it will slow down the interactive experience, as it will disable Julia packages pre-compilation, and every time we will use a module for the first time, this will need to be compiled first. Other, more efficient but also more complicate, workarounds are given in the package documentation, under the https://pyjulia.readthedocs.io/en/stable/troubleshooting.html[Troubleshooting section].</p><p>Let&#39;s now add to Julia the BetaML package. We can surely do it from within Julia, but we can also do it while remaining in Python:</p><pre><code class="language-python hljs">&gt;&gt;&gt; jl.eval(&#39;using Pkg; Pkg.add(&quot;BetaML&quot;)&#39;) # Only once to install BetaML</code></pre><p>While <code>jl.eval(&#39;some Julia code&#39;)</code> evaluates any arbitrary Julia code (see below), most of the time we can use Julia in a more direct way. Let&#39;s start by importing the BetaML Julia package as a submodule of the Python Julia module:</p><pre><code class="language-python hljs">&gt;&gt;&gt; from julia import BetaML
&gt;&gt;&gt; jl.eval(&#39;using BetaML&#39;)</code></pre><p>As you can see, it is no different than importing any other Python module.</p><p>For the data, let&#39;s load it &quot;Python side&quot;:</p><pre><code class="language-python hljs">&gt;&gt;&gt; from sklearn import datasets
&gt;&gt;&gt; iris = datasets.load_iris()
&gt;&gt;&gt; X    = iris.data[:, :4]
&gt;&gt;&gt; y    = iris.target + 1 # Julia arrays start from 1 not 0</code></pre><p>Note that <code>X</code> and <code>y</code> are Numpy arrays.</p><p>We can now call BetaML functions as we would do for any other Python library functions. In particular, we can pass to the functions (and retrieve) complex data types without worrying too much about the conversion between Python and Julia types, as these are converted automatically:</p><pre><code class="language-python hljs">&gt;&gt;&gt; (Xs,ys) = BetaML.consistent_shuffle([X,y]) # X and y are first converted to julia arrays and then the returned julia arrays are converted back to python Numpy arrays
&gt;&gt;&gt; m       = BetaML.KMeansClusterer(n_classes=3)
&gt;&gt;&gt; yhat    = BetaML.fit_ex(m,Xs) # Python doesn&#39;t allow exclamation marks in function names, so we use `fit_ex(⋅)` instead of `fit!(⋅)`
&gt;&gt;&gt; acc     = BetaML.accuracy(ys,yhat,ignorelabels=True)
&gt;&gt;&gt; acc
 0.8933333333333333</code></pre><p>Note: If we are using the <code>jl.eval()</code> interface, the objects we use must be already known to julia. To pass objects from Python to Julia, import the julia <code>Main</code> module (the root module in julia) and assign the needed variables, e.g.</p><pre><code class="language-python hljs">&gt;&gt;&gt; X_python = [1,2,3,2,4]
&gt;&gt;&gt; from julia import Main
&gt;&gt;&gt; Main.X_julia = X_python
&gt;&gt;&gt; jl.eval(&#39;BetaML.gini(X_julia)&#39;)
0.7199999999999999</code></pre><p>Another alternative is to &quot;eval&quot; only the function name and pass the (python) objects in the function call:</p><pre><code class="language-python hljs">&gt;&gt;&gt; jl.eval(&#39;BetaML.gini&#39;)(X_python)
0.7199999999999999</code></pre><h4 id="With-the-newer-JuliaCall-python-package"><a class="docs-heading-anchor" href="#With-the-newer-JuliaCall-python-package">With the newer <code>JuliaCall</code> python package</a><a id="With-the-newer-JuliaCall-python-package-1"></a><a class="docs-heading-anchor-permalink" href="#With-the-newer-JuliaCall-python-package" title="Permalink"></a></h4><p><a href="https://github.com/cjdoris/PythonCall.jl">JuliaCall</a> is a newer way to use Julia in Python that doesn&#39;t require separate installation of Julia.</p><p>Istall it in Python using <code>pip</code> as well:</p><pre><code class="nohighlight hljs">$ python3 -m pip install --user juliacall</code></pre><p>We can now open a Python terminal and, to obtain an interface to Julia, just run:</p><pre><code class="language-python hljs">&gt;&gt;&gt; from juliacall import Main as jl</code></pre><p>If you have <code>julia</code> on PATH, it will use that version, otherwise it will automatically download and install a private version for <code>JuliaCall</code></p><p>If we have multiple Julia versions, we can specify the one to use in Python passing <code>julia=&quot;/path/to/julia/binary/executable&quot;</code> (e.g. <code>julia = &quot;/home/myUser/lib/julia-1.8.0/bin/julia&quot;</code>) to the <code>install()</code> function.</p><p>To add <code>BetaML</code> to the JuliaCall private version we evaluate the julia package manager <code>add</code> function:</p><pre><code class="language-python hljs">&gt;&gt;&gt; jl.seval(&#39;using Pkg; Pkg.add(&quot;BetaML&quot;)&#39;)# Only once to install BetaML</code></pre><p>As with <code>PyJulia</code> we can evaluate arbitrary Julia code either using <code>jl.seval(&#39;some Julia code&#39;)</code> and by direct call, but let&#39;s first import <code>BetaML</code>:</p><pre><code class="language-python hljs">&gt;&gt;&gt; jl.seval(&quot;using BetaML&quot;)
&gt;&gt;&gt; bml = jl.BetaML</code></pre><p>For the data, we reuse the <code>X</code> and <code>y</code> Numpy arrays we loaded earlier.</p><p>We can now call BetaML functions as we would do for any other Python library functions. In particular, we can pass to the functions (and retrieve) complex data types without worrying too much about the conversion between Python and Julia types, as these are converted automatically:</p><pre><code class="language-python hljs">&gt;&gt;&gt; (Xs,ys) = bml.consistent_shuffle([X,y])
&gt;&gt;&gt; m       = bml.KMeansClusterer(n_classes=3)
&gt;&gt;&gt; yhat    = bml.fit_ex(m,Xs)
&gt;&gt;&gt; m._jl_display() # force a &quot;Julian&quot; way of displaying of Julia objects
&gt;&gt;&gt; acc     = bml.accuracy(ys,yhat,ignorelabels=True)
&gt;&gt;&gt; acc
 0.8933333333333333</code></pre><p>Note: If we are using the <code>jl.eval()</code> interface, the objects we use must be already known to julia. To pass objects from Python to Julia, we can write a small Julia <em>macro</em>:</p><pre><code class="language-python hljs">&gt;&gt;&gt; X_python = [1,2,3,2,4]
&gt;&gt;&gt; jlstore = jl.seval(&quot;(k, v) -&gt; (@eval $(Symbol(k)) = $v; return)&quot;)
&gt;&gt;&gt; jlstore(&quot;X_julia&quot;,X_python)
&gt;&gt;&gt; jl.seval(&quot;BetaML.gini(X_julia)&quot;)
0.7199999999999999</code></pre><p>Another alternative is to &quot;eval&quot; only the function name and pass the (python) objects in the function call:</p><pre><code class="language-python hljs">&gt;&gt;&gt; X_python = [1,2,3,2,4]
&gt;&gt;&gt; jl.seval(&#39;BetaML.gini&#39;)(X_python)
0.7199999999999999</code></pre><h4 id="Conclusions-about-using-BetaML-in-Python"><a class="docs-heading-anchor" href="#Conclusions-about-using-BetaML-in-Python">Conclusions about using BetaML in Python</a><a id="Conclusions-about-using-BetaML-in-Python-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusions-about-using-BetaML-in-Python" title="Permalink"></a></h4><p>Using either the direct call or the <code>eval</code> function, wheter in <code>Pyjulia</code> or <code>JuliaCall</code>, we should be able to use all the BetaML functionalities directly from Python. If you run into problems using BetaML from Python, <a href="https://github.com/sylvaticus/BetaML.jl/issues/new">open an issue</a> specifying your set-up.</p></details><h3 id="Use-BetaML-in-R"><a class="docs-heading-anchor" href="#Use-BetaML-in-R">Use BetaML in R</a><a id="Use-BetaML-in-R-1"></a><a class="docs-heading-anchor-permalink" href="#Use-BetaML-in-R" title="Permalink"></a></h3><pre><code class="language- hljs">&gt; install.packages(&quot;JuliaCall&quot;) # only once
&gt; library(JuliaCall)
&gt; library(datasets)
&gt; julia_setup(installJulia = TRUE) # use installJulia = TRUE to let R download and install a private copy of julia, FALSE to use an existing Julia local installation
&gt; julia_eval(&#39;using Pkg; Pkg.add(&quot;BetaML&quot;)&#39;) # only once
&gt; julia_eval(&quot;using BetaML&quot;)
&gt; X        &lt;- as.matrix(sapply(iris[,1:4], as.numeric))
&gt; y        &lt;- sapply(iris[,5], as.integer)
&gt; xsize    &lt;- dim(X)
&gt; shuffled &lt;- julia_call(&quot;consistent_shuffle&quot;,list(X,y))
&gt; Xs       &lt;- matrix(sapply(shuffled[1],as.numeric), nrow=xsize[1])
&gt; ys       &lt;- as.vector(sapply(shuffled[2], as.integer))
&gt; m        &lt;- julia_eval(&#39;KMeansClusterer(n_classes=3)&#39;)
&gt; yhat     &lt;- julia_call(&quot;fit_ex&quot;,m,Xs)
&gt; acc      &lt;- julia_call(&quot;accuracy&quot;,yhat,ys,ignorelabels=TRUE)
&gt; acc
[1] 0.8933333</code></pre><details><summary>Details</summary><p>For R, we show how to access <code>BetaML</code> functionalities using the <a href="https://github.com/Non-Contradiction/JuliaCall">JuliaCall</a> R package (no relations with the homonymous Python package).</p><p>Let&#39;s start by installing <a href="https://cran.r-project.org/web/packages/JuliaCall/index.html"><code>JuliaCall</code></a> in R:</p><pre><code class="language- hljs">&gt; install.packages(&quot;JuliaCall&quot;)
&gt; library(JuliaCall)
&gt; julia_setup(installJulia = TRUE) # use installJulia = TRUE to let R download and install a private copy of julia, FALSE to use an existing Julia local installation</code></pre><p>Note that, differently than <code>PyJulia</code>, the &quot;setup&quot; function needs to be called every time we start a new R section, not just when we install the <code>JuliaCall</code> package. If we don&#39;t have <code>julia</code> in the path of our system, or if we have multiple versions and we want to specify the one to work with, we can pass the <code>JULIA_HOME = &quot;/path/to/julia/binary/executable/directory&quot;</code> (e.g. <code>JULIA_HOME = &quot;/home/myUser/lib/julia-1.1.0/bin&quot;</code>) parameter to the <code>julia_setup</code> call. Or just let <code>JuliaCall</code> automatically download and install a private copy of julia.</p><p><code>JuliaCall</code> depends for some things (like object conversion between Julia and R) from the Julia <code>RCall</code> package. If we don&#39;t already have it installed in Julia, it will try to install it automatically.</p><p>As in Python, let&#39;s start from the data loaded from R and do some work with them in Julia:</p><pre><code class="language- hljs">&gt; library(datasets)
&gt; X     &lt;- as.matrix(sapply(iris[,1:4], as.numeric))
&gt; y     &lt;- sapply(iris[,5], as.integer)
&gt; xsize &lt;- dim(X)</code></pre><p>Let&#39;s install BetaML. As we did in Python, we can install a Julia package from Julia itself or from within R:</p><pre><code class="language- hljs">&gt; julia_eval(&#39;using Pkg; Pkg.add(&quot;BetaML&quot;)&#39;)</code></pre><p>We can now &quot;import&quot; the BetaML julia package (in julia a &quot;Package&quot; is basically a module plus some metadata that facilitate its discovery and integration with other packages, like the reuired set) and call its functions with the <code>julia_call(&quot;juliaFunction&quot;,args)</code> R function:</p><pre><code class="language- hljs">&gt; julia_eval(&quot;using BetaML&quot;)
&gt; shuffled &lt;- julia_call(&quot;consistent_shuffle&quot;,list(X,y))
&gt; Xs       &lt;- matrix(sapply(shuffled[1],as.numeric), nrow=xsize[1])
&gt; ys       &lt;- as.vector(sapply(shuffled[2], as.integer))
&gt; m        &lt;- julia_eval(&#39;KMeansClusterer(n_classes=3)&#39;)
&gt; yhat     &lt;- julia_call(&quot;fit_ex&quot;,m,Xs)
&gt; acc      &lt;- julia_call(&quot;accuracy&quot;,yhat,ys,ignorelabels=TRUE)
&gt; acc
[1] 0.8933333</code></pre><p>As alternative, we can embed Julia code directly in R using the <code>julia_eval()</code> function:</p><pre><code class="language- hljs">kMeansR  &lt;- julia_eval(&#39;
  function accFromKmeans(x,k,y)
    m    = KMeansClusterer(n_classes=Int(k))
    yhat = fit!(m,x)
    acc  = accuracy(yhat,y,ignorelabels=true)
    return acc
  end
&#39;)</code></pre><p>We can then call the above function in R in one of the following three ways:</p><ol><li><code>kMeansR(Xs,3,ys)</code></li><li><code>julia_assign(&quot;Xs_julia&quot;, Xs); julia_assign(&quot;ys_julia&quot;, ys); julia_eval(&quot;accFromKmeans(Xs_julia,3,ys_julia)&quot;)</code></li><li><code>julia_call(&quot;accFromKmeans&quot;,Xs,3,ys)</code></li></ol><p>While other &quot;convenience&quot; functions are provided by the package, using  <code>julia_call</code>, or <code>julia_assign</code> followed by <code>julia_eval</code>, should suffix to use <code>BetaML</code> from R. If you run into problems using BetaML from R, <a href="https://github.com/sylvaticus/BetaML.jl/issues/new">open an issue</a> specifying your set-up.</p></details><h2 id="stochasticity_reproducibility"><a class="docs-heading-anchor" href="#stochasticity_reproducibility">Dealing with stochasticity and reproducibility</a><a id="stochasticity_reproducibility-1"></a><a class="docs-heading-anchor-permalink" href="#stochasticity_reproducibility" title="Permalink"></a></h2><p>Machine Learning workflows include stochastic components in several steps: in the data sampling, in the model initialisation and often in the models&#39;s own algorithms (and sometimes also in the prediction step). All BetaML models with a stochastic components support a <code>rng</code> parameter, standing for <em>Random Number Generator</em>. A RNG is a &quot;machine&quot; that streams a flow of random numbers. The flow itself however is deterministically determined for each &quot;seed&quot; (an integer number) that the RNG has been told to use. Normally this seed changes at each running of the script/model, so that stochastic models are indeed stochastic and their output differs at each run.</p><p>If we want to obtain reproductible results we can fix the seed at the very beginning of our model with <code>Random.seed!([AnInteger])</code>. Now our model or script will pick up a specific flow of random numbers, but this flow will always be the same, so that its results will always be the same.</p><p>However the default Julia RNG guarantee to provide the same flow of random numbers, conditional to the seed, only within minor versions of Julia. If we want to &quot;guarantee&quot; reproducibility of the results with different versions of Julia, or &quot;fix&quot; only some parts of our script, we can call the individual functions passing <a href="../Api.html#BetaML.Api.FIXEDRNG"><code>FIXEDRNG</code></a>, an instance of <code>StableRNG(FIXEDSEED)</code> provided by <code>BetaML</code>, to the <code>rng</code> parameter. Use it with:</p><ul><li><code>MyModel(;rng=FIXEDRNG)</code>               : always produce the same sequence of results on each run of the script (&quot;pulling&quot; from the same rng object on different calls)</li><li><code>MyModel(;rng=StableRNG(SOMEINTEGER))</code> : always produce the same result (new identical rng object on each call)</li></ul><p>This is very convenient expecially during model development, as a model that use <code>(...,rng=StableRNG(an_integer))</code> will provides stochastic results that are isolated (i.e. they don&#39;t depend from the consumption of the random stream from other parts of the model).</p><p>In particular, use <code>rng=StableRNG(FIXEDSEED)</code> or <code>rng=copy(FIXEDRNG)</code> with <a href="../Api.html#BetaML.Api.FIXEDSEED"><code>FIXEDSEED</code></a>  to retrieve the exact output as in the documentation or in the unit tests.</p><p>Most of the stochasticity appears in <em>training</em> a model. However in few cases (e.g. decision trees with missing values) some stochasticity appears also in <em>predicting</em> new data using a trained model. In such cases the model doesn&#39;t restrict the random seed, so that you can choose at <em>predict</em> time to use a fixed or a variable random seed.</p><p>Finally, if you plan to use multiple threads and want to provide the same stochastic output independent to the number of threads used, have a look at <a href="../Utils.html#BetaML.Utils.generate_parallel_rngs-Tuple{Random.AbstractRNG, Integer}"><code>generate_parallel_rngs</code></a>.</p><p>&quot;Reproducible stochasticity&quot; is only one of the elements needed for a reproductible output. The other two are (a) the inputs the workflow uses and (b) the code that is evaluated. Concerning the second point Julia has a very modern package system that guarantee reproducible code evaluation (with a few exception linked to using external libraries, but BetaML models are all implemented in Julia itself). Without going in detail, you can use a pattern like this at the beginning of your machine learning workflows:</p><pre><code class="nohighlight hljs">using Pkg  
cd(@__DIR__)            
Pkg.activate(&quot;.&quot;)  # Activate a &quot;local&quot; environment, specific to this folder
Pkg.instantiate()  # Download and install the required packages if not already available </code></pre><p>This will tell Julia to load the exact version of dependent packages, and recursively of their dependencies, from a <code>Manifest.toml</code> file that is automatically created in the script&#39;s folder, and automatically updated, when you add or update a package in your workflow. Note that these locals &quot;environments&quot; are very &quot;cheap&quot; (packages are not actually copied to each environment on your system, only referenced) and the environment doen&#39;t need to be in the same script folder as in this example, can be any folder you want to &quot;activate&quot;.</p><h2 id="Saving-and-loading-trained-models"><a class="docs-heading-anchor" href="#Saving-and-loading-trained-models">Saving and loading trained models</a><a id="Saving-and-loading-trained-models-1"></a><a class="docs-heading-anchor-permalink" href="#Saving-and-loading-trained-models" title="Permalink"></a></h2><p>Trained models can be saved on disk using the <a href="../Api.html#BetaML.Api.model_save"><code>model_save</code></a> function, and retrieved with <a href="../Api.html#BetaML.Api.model_load"><code>model_load</code></a>. The advantage over the serialization functionality in Julia core is that the two functions are actually wrappers around equivalent <a href="https://juliaio.github.io/JLD2.jl/stable/">JLD2</a> package functions, and should maintain compatibility across different Julia versions. </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../index.html">« Index</a><a class="docs-footer-nextpage" href="Classification - cars/betaml_tutorial_classification_cars.html">A classification task when labels are known - determining the country of origin of cars given the cars characteristics »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 16 September 2025 14:11">Tuesday 16 September 2025</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
